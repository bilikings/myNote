# 终面

## 1、hashmap

​                               

一、HashMap原理

**1.1 HashMap特性？**

HashMap存储键值对，实现快速存取数据；允许null键/值；非同步；不保证有序(比如插入的顺序)。实现map接口。

**1.2 HashMap的原理，内部数据结构？**

HashMap是基于hashing的原理，底层使用哈希表（数组 + 链表）实现。里边最重要的两个方法put、get，使用put(key, value)存储对象到HashMap中，使用get(key)从HashMap中获取对象。

存储对象时，我们将K/V传给put方法时，它调用hashCode计算hash从而得到bucket位置，进一步存储，HashMap会根据当前bucket的占用情况自动调整容量(超过Load Facotr则resize为原来的2倍)。获取对象时，我们将K传给get，它调用hashCode计算hash从而得到bucket位置，并进一步调用equals()方法确定键值对。如果发生碰撞的时候，Hashmap通过链表将产生碰撞冲突的元素组织起来，在Java 8中，如果一个bucket中碰撞冲突的元素超过某个限制(默认是8)，则使用**红黑树来替换链表**，从而提高速度。

 

**1.3 讲一下 HashMap 中 put 方法过程？**

1.对key的hashCode做hash操作，然后再计算在bucket中的index（1.5 HashMap的哈希函数）； 

2.如果没碰撞直接放到bucket里；

3.如果碰撞了，以链表的形式存在buckets后（头插法）；

4.如果节点已经存在就替换old value(保证key的唯一性) 

5.如果bucket满了(超过阈值，阈值=loadfactor*current capacity，load factor默认0.75)，就要resize。

 

**1.4 get()方法的工作原理？**

通过对key的hashCode()进行hashing，并计算下标( n-1 & hash)，从而获得buckets的位置。如果产生碰撞，则利用key.equals()方法去链表中查找对应的节点。

 

**1.5 HashMap中hash函数怎么是是实现的？还有哪些 hash 的实现方式？**

1.对key的hashCode做hash操作（高16bit不变，低16bit和高16bit做了一个异或）； 

\2. h & (length-1); //通过位操作得到下标index。

还有数字分析法、平方取中法、分段叠加法、除留余数法、伪随机数法。

 

**1.6 HashMap怎样解决冲突？**

HashMap中处理冲突的方法实际就是**链地址法**。

 

**1.6.1 扩展问题1：当两个对象的hashcode相同会发生什么？**

因为两个对象的Hashcode相同，所以它们的bucket位置相同，会发生“碰撞”。HashMap使用链表存储对象，这个Entry(包含有键值对的Map.Entry对象)会存储在链表中。

**1.6.2 扩展问题2：抛开 HashMap，hash 冲突有那些解决办法？**

开放定址法、链地址法、再哈希法。

**1.7 如果两个键的hashcode相同，你如何获取值对象？**

重点在于理解hashCode()与equals()。

通过对key的hashCode()进行hashing，并计算下标( n-1 & hash)，从而获得buckets的位置。两个键的hashcode相同会产生碰撞，则利用key.equals()方法去链表或树（java1.8）中去查找对应的节点。

**1.8 针对 HashMap 中某个 Entry 链太长，查找的时间复杂度可能达到 O(n)，怎么优化？**

**将链表转为红黑树，实现 O(logn) 时间复杂度内查找。**

 

**1.9 如果HashMap的大小超过了负载因子(load factor)定义的容量，怎么办？**

扩容。这个过程也叫作rehashing，因为它重建内部数据结构，并调用hash方法找到新的bucket位置。

大致分两步：

1.扩容：容量扩充为原来的两倍（2 * table.length）； 

2.移动：对每个节点重新计算哈希值，重新计算每个元素在数组中的位置，将原来的元素移动到新的哈希表中。

补充： 

loadFactor：加载因子。默认值DEFAULT_LOAD_FACTOR = 0.75f； 

capacity：容量；

threshold：阈值=capacity*loadFactor。当HashMap中存储数据的数量达到threshold时，就需要将HashMap的容量加倍（capacity*2）； 

size：HashMap的大小，它是HashMap保存的键值对的数量。

 

 

二、HashMap与HashTable区别

Hashtable可以看做是线程安全版的HashMap，两者几乎“等价”（当然还是有很多不同）。Hashtable几乎在每个方法上都加上synchronized（同步锁），实现线程安全。

**2.1 区别**

1.HashMap继承于AbstractMap，而Hashtable继承于Dictionary； 

2.线程安全不同。Hashtable的几乎所有函数都是同步的，即它是线程安全的，支持多线程。而HashMap的函数则是非同步的，它不是线程安全的。若要在多线程中使用HashMap，需要我们额外的进行同步处理；

3.null值。HashMap的key、value都可以为null。Hashtable的key、value都不可以为null； 

4.迭代器(Iterator)。HashMap的迭代器(Iterator)是fail-fast迭代器，而Hashtable的enumerator迭代器不是fail-fast的。所以当有其它线程改变了HashMap的结构（增加或者移除元素），将会抛出ConcurrentModificationException。

5.容量的初始值和增加方式都不一样：HashMap默认的容量大小是16；增加容量时，每次将容量变为“原始容量x2”。Hashtable默认的容量大小是11；增加容量时，每次将容量变为“原始容量x2 + 1”； 

6.添加key-value时的hash值算法不同：HashMap添加元素时，是使用自定义的哈希算法。Hashtable没有自定义哈希算法，而直接采用的key的hashCode()。 

7.速度。由于Hashtable是线程安全的也是synchronized，所以在单线程环境下它比HashMap要慢。如果你不需要同步，只需要单一线程，那么使用HashMap性能要好过Hashtable。

**2.2 能否让HashMap同步？**

HashMap可以通过下面的语句进行同步：Map m = Collections.synchronizeMap(hashMap);

 

 

**为什么String, Interger这样的wrapper类适合作为键？**

String, Interger这样的wrapper类作为HashMap的键是再适合不过了，而且String最为常用。因为String是不可变的，也是final的，而且已经重写了equals()和hashCode()方法了。其他的wrapper类也有这个特点。不可变性是必要的，因为为了要计算hashCode()，就要防止键值改变，如果键值在放入时和获取时返回不同的hashcode的话，那么就不能从HashMap中找到你想要的对象。不可变性还有其他的优点如线程安全。如果你可以仅仅通过将某个field声明成final就能保证hashCode是不变的，那么请这么做吧。因为获取对象的时候要用到equals()和hashCode()方法，那么键对象正确的重写这两个方法是非常重要的。如果两个不相等的对象返回不同的hashcode的话，那么碰撞的几率就会小些，这样就能提高HashMap的性能。

 

**我们可以使用自定义的对象作为键吗？**

当然你可能使用任何对象作为键，只要它遵守了equals()和hashCode()方法的定义规则，并且当对象插入到Map中之后将不会再改变了。如果这个自定义对象时不可变的，那么它已经满足了作为键的条件，因为当它创建之后就已经不能改变了。

 

**我们可以使用CocurrentHashMap来代替HashTable吗？**

这是另外一个很热门的面试题，因为ConcurrentHashMap越来越多人用了。我们知道HashTable是synchronized的，但是ConcurrentHashMap同步性能更好，因为它仅仅根据同步级别对map的一部分进行上锁。ConcurrentHashMap当然可以代替HashTable，但是HashTable提供更强的线程安全性。看看这篇博客查看Hashtable和ConcurrentHashMap的区别。

 

**hashcode和equal这两者有什么区别？**

在Java中任何一个对象都具备equals(Object obj)和hashcode()这两个方法，因为他们是在Object类中定义的。

equals(Object obj)方法用来判断两个对象是否“相同”，如果“相同”则返回true，否则返回false。

hashcode()方法返回一个int数，在Object类中的默认实现是“将该对象的内部地址转换成一个整数返回”。

1、如果两个对象equals，Java运行时环境会认为他们的hashcode一定相等。

2、如果两个对象不equals，他们的hashcode有可能相等。

3、如果两个对象hashcode相等，他们不一定equals。

4、如果两个对象hashcode不相等，他们一定不equals。

## 2、Threadlocal

 

 

 

## 3、一个页面从输入 URL 到页面加载显示完成，这个过程中都发生了什么？

DNS 53(TCP/UDP)  HTTP:80(TCP)  HTTPS:443

(1)浏览器查询DNS，获取域名对应的IP地址:具体过程包括浏览器搜索自身的DNS缓存、搜索操作系统的DNS缓存、读取本地的Host文件和向本地DNS服务器进行查询等。对于向本地DNS服务器进行查询，如果要查询的域名包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析(此解析具有权威性)；如果要查询的域名不由本地DNS服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个IP地址映射，完成域名解析（此解析不具有权威性）。如果本地域名服务器并未缓存该网址映射关系，那么将根据其设置发起递归查询或者迭代查询；

(2)浏览器获得域名对应的IP地址以后，浏览器向服务器请求建立链接，发起三次握手；

(3)TCP/IP链接建立起来后，浏览器向服务器发送HTTP请求；

(4)服务器接收到这个请求，并根据路径参数映射到特定的请求处理器进行处理，并将处理结果及相应的视图返回给浏览器；

(5)浏览器解析并渲染视图，若遇到对js文件、css文件及图片等静态资源的引用，则重复上述步骤并向服务器请求这些资源；

(6)浏览器根据其请求到的资源、数据渲染页面，最终向用户呈现一个完整的页面。

 

详细：

1.在浏览器端输入网站的url地址

只有知道了一个网站的url地址才能访问到这个网站

2.浏览器查找缓存

浏览器会查找浏览器缓存,系统缓存,路由缓存,如果没有的话 继续下一步,如果有的话,直接显示

注意:浏览器会把访问过得web网站资源(html 图片)缓存起来,而判断是否使用缓存的条件有以下几种:

是否有这个网站的缓存

这个网站的缓存是否过期,具体看Cache-Control 中缓存的有效时间

跟服务器进行协商是否使用缓存,如果上次缓存的时候有Last-modified 和 Etag 字段,本次请求就会加上If-Modified-Since(上次请求资源的时间)和If-None-Match(上次资源的修改时间)

3.通过DNS获取url对应的ip地址

现在本机的host文件中查找是否有这个url对应的ip,如果没有的话,就请求DNS进行ip地址的获取

4.建立TCP链接

http在工作之前,需要客户端和服务端建立链接,这个链接的建立是通过tcp(三次握手)来完成的,因为http是比tcp更高层的协议,在网络协议的建立中,不谈底层谈高层都是在耍流氓,所以想要让http进行工作,需要tcp首先建立链接

5.浏览器向web服务器发送请求

一旦链接已经建立,浏览器就可以给web服务器发送请求命令,比如 : GET/deom/hello.jsp HTTP/1.1

6.浏览器给web服务器发送请求头信息

浏览器在发送了请求后,还要给web服务器请求头信息,比如accept-charset(浏览器端指定的字符集),最后发送一个空的请求头代表请求发送完毕,注意:如果是post提交,则会继续提交请求体

7.web服务器进行应答

应答的第一部分是http版本号,第二部分是协议的状态码,比如:HTTP/1.1 200 OK

8.web服务器发送应答头消息

web服务器给浏览器发送应答头消息,也就是关于web服务器自己的信息,最后发送一个空白行代表应答结束

9.web服务器发送数据

以应答头里面的content-type所描述的格式发送数据

10.web服务器关闭链接

web服务器向浏览器发送了应答数据之后,就要关闭tcp链接(tcp四次握手关闭链接),如果添加了connection:keep-alive,那么就还会保持链接状态

## 4、MYSQL分页关键字LIMIT

 

 

 

 

## 5、进程 线程 协程

 

 

## 6、进程间的通信的几种方式

1）管道（pipe）及命名管道（named pipe）：管道可用于具有亲缘关系的父子进程间的通信，有名管道除了具有管道所具有的功能外，它还允许无亲缘关系进程间的通信；

2）信号（signal）：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生；

3）消息队列：消息队列是消息的链接表，它克服了上两种通信方式中信号量有限的缺点，具有写权限得进程可以按照一定得规则向消息队列中添加新信息；对消息队列有读权限得进程则可以从消息队列中读取信息；

4）共享内存：可以说这是最有用的进程间通信方式。它使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据得更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等；

5）信号量：主要作为进程之间及同一种进程的不同线程之间得同步和互斥手段；

6）套接字：这是一种更为一般得进程间通信机制，它可用于网络中不同机器之间的进程间通信，应用非常广泛。

## 7、[线程池](https://www.cnblogs.com/sachen/p/7401959.html)

https://blog.csdn.net/weixin_40271838/article/details/79998327

newCachedThreadPool：

·     底层：返回ThreadPoolExecutor实例，corePoolSize为0；maximumPoolSize为Integer.MAX_VALUE；keepAliveTime为60L；unit为TimeUnit.SECONDS；workQueue为SynchronousQueue(同步队列)

·     通俗：当有新任务到来，则插入到SynchronousQueue中，由于SynchronousQueue是同步队列，因此会在池中寻找可用线程来执行，若有可以线程则执行，若没有可用线程则创建一个线程来执行该任务；若池中线程空闲时间超过指定大小，则该线程会被销毁。

·     适用：执行很多短期异步的小程序或者负载较轻的服务器

newFixedThreadPool：

·     底层：返回ThreadPoolExecutor实例，接收参数为所设定线程数量nThread，corePoolSize为nThread，maximumPoolSize为nThread；keepAliveTime为0L(不限时)；unit为：TimeUnit.MILLISECONDS；WorkQueue为：new LinkedBlockingQueue<Runnable>() 无解阻塞队列

·     通俗：创建可容纳固定数量线程的池子，每隔线程的存活时间是无限的，当池子满了就不在添加线程了；如果池中的所有线程均在繁忙状态，对于新任务会进入阻塞队列中(无界的阻塞队列)

·     适用：执行长期的任务，性能好很多

newSingleThreadExecutor:

·     底层：FinalizableDelegatedExecutorService包装的ThreadPoolExecutor实例，corePoolSize为1；maximumPoolSize为1；keepAliveTime为0L；unit为：TimeUnit.MILLISECONDS；workQueue为：new LinkedBlockingQueue<Runnable>() 无解阻塞队列

·     通俗：创建只有一个线程的线程池，且线程的存活时间是无限的；当该线程正繁忙时，对于新任务会进入阻塞队列中(无界的阻塞队列)

·     适用：一个任务一个任务执行的场景

NewScheduledThreadPool:

·     底层：创建ScheduledThreadPoolExecutor实例，corePoolSize为传递来的参数，maximumPoolSize为Integer.MAX_VALUE；keepAliveTime为0；unit为：TimeUnit.NANOSECONDS；workQueue为：new DelayedWorkQueue() 一个按超时时间升序排序的队列

·     通俗：创建一个固定大小的线程池，线程池内线程存活时间无限制，线程池可以支持定时及周期性任务执行，如果所有线程均处于繁忙状态，对于新任务会进入DelayedWorkQueue队列中，这是一种按照超时时间排序的队列结构

·     适用：周期性执行任务的场景

线程池任务执行流程：

\1.  当线程池小于corePoolSize时，新提交任务将创建一个新线程执行任务，即使此时线程池中存在空闲线程。

\2.  当线程池达到corePoolSize时，新提交任务将被放入workQueue中，等待线程池中任务调度执行

\3.  当workQueue已满，且maximumPoolSize>corePoolSize时，新提交任务会创建新线程执行任务

\4.  当提交任务数超过maximumPoolSize时，新提交任务由RejectedExecutionHandler处理

\5.  当线程池中超过corePoolSize线程，空闲时间达到keepAliveTime时，关闭空闲线程

\6.  当设置allowCoreThreadTimeOut(true)时，线程池中corePoolSize线程空闲时间达到keepAliveTime也将关闭

备注：

一般如果线程池任务队列采用LinkedBlockingQueue队列的话，那么不会拒绝任何任务（因为队列大小没有限制），这种情况下，ThreadPoolExecutor最多仅会按照最小线程数来创建线程，也就是说线程池大小被忽略了。

如果线程池任务队列采用ArrayBlockingQueue队列的话，那么ThreadPoolExecutor将会采取一个非常负责的算法，比如假定线程池的最小线程数为4，最大为8所用的ArrayBlockingQueue最大为10。随着任务到达并被放到队列中，线程池中最多运行4个线程（即最小线程数）。即使队列完全填满，也就是说有10个处于等待状态的任务，ThreadPoolExecutor也只会利用4个线程。如果队列已满，而又有新任务进来，此时才会启动一个新线程，这里不会因为队列已满而拒接该任务，相反会启动一个新线程。新线程会运行队列中的第一个任务，为新来的任务腾出空间。

这个算法背后的理念是：该池大部分时间仅使用核心线程（4个），即使有适量的任务在队列中等待运行。这时线程池就可以用作节流阀。如果挤压的请求变得非常多，这时该池就会尝试运行更多的线程来清理；这时第二个节流阀—最大线程数就起作用了。

 

线程池的好处：

https://blog.csdn.net/kavensu/article/details/8093756

## 8、Java锁

### 8.1 公平锁/非公平锁

公平锁是指多个线程按照申请锁的顺序来获取锁。

非公平锁是指多个线程获取锁的顺序并不是按照申请锁的顺序，有可能后申请的线程比先申请的线程优先获取锁。有可能，会造成优先级反转或者饥饿现象。

 

对于Java ReentrantLock而言，通过构造函数指定该锁是否是公平锁，默认是非公平锁。非公平锁的优点在于吞吐量比公平锁大。

 

对于Synchronized而言，也是一种非公平锁。由于其并不像ReentrantLock是通过AQS的来实现线程调度，所以并没有任何办法使其变成公平锁。

 

**实现原理**

那如何能保证每个线程都能拿到锁呢，队列FIFO是一个完美的解决方案，也就是先进先出，java的ReenTrantLock也就是用队列实现的公平锁和非公平锁。

在公平的锁中，如果有另一个线程持有锁或者有其他线程在等待队列中等待这个锁，那么新发出的请求的线程将被放入到队列中。而非公平锁上，只有当锁被某个线程持有时，新发出请求的线程才会被放入队列中（此时和公平锁是一样的）。所以，**它们的差别在于非公平锁会有更多的机会去抢占锁。（存在饿死）**

**优缺点**

非公平锁性能高于公平锁性能。首先，在恢复一个被挂起的线程与该线程真正运行之间存在着严重的延迟。而且，非公平锁能更充分的利用cpu的时间片，尽量的减少cpu空闲的状态时间。

**使用场景**

使用场景的话呢，其实还是和他们的属性一一相关，举个栗子：如果业务中线程占用(处理)时间要远长于线程等待，那用非公平锁其实效率并不明显，但是用公平锁会给业务增强很多的可控制性。

 

 

### 8.2 可重入锁

如果锁具备可重入性，则称作为可重入锁。像synchronized和ReentrantLock都是可重入锁，可重入性在我看来实际上表明了锁的分配机制：基于线程的分配，而不是基于方法调用的分配。举个简单的例子，当一个线程执行到某个synchronized方法时，比如说method1，而在method1中会调用另外一个synchronized方法method2，此时线程不必重新去申请锁，而是可以直接执行方法method2。

可重入锁又名递归锁，是指在同一个线程在外层方法获取锁的时候，在进入内层方法会自动获取锁。说的有点抽象，下面会有一个代码的示例。

对于Java ReentrantLock而言,是一个可重入锁。

对于Synchronized而言,也是一个可重入锁。可重入锁的一个好处是可一定程度避免死锁。

 

synchronized void setA() throws Exception{

  Thread.sleep(1000);

  setB();

}

 

synchronized void setB() throws Exception{

  Thread.sleep(1000);

}

上面的代码就是一个可重入锁的一个特点，如果不是可重入锁的话，setB可能不会被当前线程执行，可能造成死锁。

 

### 8.3 独享锁/共享锁

独享锁是指该锁一次只能被一个线程所持有。

共享锁是指该锁可被多个线程所持有。

 

对于Java ReentrantLock而言，其是独享锁。但是对于Lock的另一个实现类ReadWriteLock，其读锁是共享锁，其写锁是独享锁。

读锁的共享锁可保证并发读是非常高效的，读写，写读，写写的过程是互斥的。

独享锁与共享锁也是通过AQS来实现的，通过实现不同的方法，来实现独享或者共享。

对于Synchronized而言，当然是独享锁。

 

### 8.4 互斥锁/读写锁

上面讲的独享锁/共享锁就是一种广义的说法，互斥锁/读写锁就是具体的实现。

互斥锁在Java中的具体实现就是ReentrantLock

读写锁在Java中的具体实现就是ReadWriteLock

 

### 8.5 乐观锁/悲观锁

乐观锁与悲观锁不是指具体的什么类型的锁，而是指看待并发同步的角度。

悲观锁认为对于同一个数据的并发操作，一定是会发生修改的，哪怕没有修改，也会认为修改。因此对于同一个数据的并发操作，悲观锁采取加锁的形式。悲观的认为，不加锁的并发操作一定会出问题。

乐观锁则认为对于同一个数据的并发操作，是不会发生修改的。在更新数据的时候，会采用尝试更新，不断重新的方式更新数据。乐观的认为，不加锁的并发操作是没有事情的。

 

从上面的描述我们可以看出，悲观锁适合写操作非常多的场景，乐观锁适合读操作非常多的场景，不加锁会带来大量的性能提升。

悲观锁在Java中的使用，就是利用各种锁。

乐观锁在Java中的使用，是无锁编程，常常采用的是CAS算法，典型的例子就是原子类，通过CAS自旋实现原子操作的更新。

 

悲观锁

总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁（**共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程**）。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。Java中synchronized和ReentrantLock等独占锁就是悲观锁思想的实现。

 

乐观锁

总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号机制和CAS算法实现。**乐观锁适用于多读的应用类型，这样可以提高吞吐量**，像数据库提供的类似于write_condition机制，其实都是提供的乐观锁。在Java中java.util.concurrent.atomic包下面的原子变量类就是使用了乐观锁的一种实现方式CAS实现的。

 

两种锁的使用场景

从上面对两种锁的介绍，我们知道两种锁各有优缺点，不可认为一种好于另一种，像乐观锁适用于写比较少的情况下（多读场景），即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。但如果是多写的情况，一般会经常产生冲突，这就会导致上层应用会不断的进行retry，这样反倒是降低了性能，所以一般多写的场景下用悲观锁就比较合适。

 

乐观锁常见的两种实现方式

乐观锁一般会使用版本号机制或CAS算法实现。

 

\1. 版本号机制

一般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加一。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若刚才读取到的version值为当前数据库中的version值相等时才更新，否则重试更新操作，直到更新成功。

 

举一个简单的例子： 

假设数据库中帐户信息表中有一个 version 字段，当前值为 1 ；而当前帐户余额字段（ balance ）为 $100 。

 

操作员 A 此时将其读出（ version=1 ），并从其帐户余额中扣除 50（50（100-$50 ）。

在操作员 A 操作的过程中，操作员B 也读入此用户信息（ version=1 ），并从其帐户余额中扣除 20（20（100-$20 ）。

操作员 A 完成了修改工作，将数据版本号加一（ version=2 ），连同帐户扣除后余额（ balance=$50 ），提交至数据库更新，此时由于提交数据版本大于数据库记录当前版本，数据被更新，数据库记录 version 更新为 2 。

操作员 B 完成了操作，也将版本号加一（ version=2 ）试图向数据库提交数据（ balance=$80 ），但此时比对数据库记录版本时发现，操作员 B 提交的数据版本号为 2 ，数据库记录当前版本也为 2 ，不满足 “ 提交版本必须大于记录当前版本才能执行更新 “ 的乐观锁策略，因此，操作员 B 的提交被驳回。

这样，就避免了操作员 B 用基于 version=1 的旧数据修改的结果覆盖操作员A 的操作结果的可能。

 

\2. CAS算法

即compare and swap（比较与交换），是一种有名的无锁算法。无锁编程，即不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步（Non-blocking Synchronization）。CAS算法涉及到三个操作数

 

需要读写的内存值 V

进行比较的值 A

拟写入的新值 B

当且仅当 V 的值等于 A时，CAS通过原子方式用新值B来更新V的值，否则不会执行任何操作（比较和替换是一个原子操作）。一般情况下是一个自旋操作，即不断的重试。

 

乐观锁的缺点

ABA 问题是乐观锁一个常见的问题

 

1 ABA 问题

如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然是A值，那我们就能说明它的值没有被其他线程修改过了吗？很明显是不能的，因为在这段时间它的值可能被改为其他值，然后又改回A，那CAS操作就会误认为它从来没有被修改过。这个问题被称为CAS操作的 “ABA”问题。

 

JDK 1.5 以后的 AtomicStampedReference 类就提供了此种能力，其中的 compareAndSet 方法就是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。

 

2 循环时间长开销大

自旋CAS（也就是不成功就一直循环执行直到成功）如果长时间不成功，会给CPU带来非常大的执行开销。 如果JVM能支持处理器提供的pause指令那么效率会有一定的提升，pause指令有两个作用，第一它可以延迟流水线执行指令（de-pipeline）,使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起CPU流水线被清空（CPU pipeline flush），从而提高CPU的执行效率。

 

3 只能保证一个共享变量的原子操作

CAS 只对单个共享变量有效，当操作涉及跨多个共享变量时 CAS 无效。但是从 JDK 1.5开始，提供了AtomicReference类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行 CAS 操作.所以我们可以使用锁或者利用AtomicReference类把多个共享变量合并成一个共享变量来操作。

 

CAS与synchronized的使用情景

简单的来说CAS适用于写比较少的情况下（多读场景，冲突一般较少），synchronized适用于写比较多的情况下（多写场景，冲突一般较多）

 

对于资源竞争较少（线程冲突较轻）的情况，使用synchronized同步锁进行线程阻塞和唤醒切换以及用户态内核态间的切换操作额外浪费消耗cpu资源；而CAS基于硬件实现，不需要进入内核，不需要切换线程，操作自旋几率较少，因此可以获得更高的性能。

对于资源竞争严重（线程冲突严重）的情况，CAS自旋的概率会比较大，从而浪费更多的CPU资源，效率低于synchronized。

补充： Java并发编程这个领域中synchronized关键字一直都是元老级的角色，很久之前很多人都会称它为“重量级锁”。但是，在JavaSE 1.6之后进行了主要包括为了减少获得锁和释放锁带来的性能消耗而引入的 偏向锁 和 轻量级锁 以及其它各种优化之后变得在某些情况下并不是那么重了。synchronized的底层实现主要依靠 Lock-Free 的队列，基本思路是 自旋后阻塞，竞争切换后继续竞争锁，稍微牺牲了公平性，但获得了高吞吐量。在线程冲突较少的情况下，可以获得和CAS类似的性能；而线程冲突严重的情况下，性能远高于CAS。

 

 

 

### 8.6 分段锁

分段锁其实是一种锁的设计，并不是具体的一种锁，对于ConcurrentHashMap而言，其并发的实现就是通过分段锁的形式来实现高效的并发操作。

我们以ConcurrentHashMap来说一下分段锁的含义以及设计思想，ConcurrentHashMap中的分段锁称为Segment，它即类似于HashMap（JDK7与JDK8中HashMap的实现）的结构，即内部拥有一个Entry数组，数组中的每个元素又是一个链表；同时又是一个ReentrantLock（Segment继承了ReentrantLock)。

当需要put元素的时候，并不是对整个hashmap进行加锁，而是先通过hashcode来知道他要放在那一个分段中，然后对这个分段进行加锁，所以当多线程put的时候，只要不是放在一个分段中，就实现了真正的并行的插入。

但是，在统计size的时候，可就是获取hashmap全局信息的时候，就需要获取所有的分段锁才能统计。

分段锁的设计目的是细化锁的粒度，当操作不需要更新整个数组的时候，就仅仅针对数组中的一项进行加锁操作。

 

### 8.7 偏向锁/轻量级锁/重量级锁（待完善）

这三种锁是指锁的状态，并且是针对Synchronized。在Java 5通过引入锁升级的机制来实现高效Synchronized。这三种锁的状态是通过对象监视器在对象头中的字段来表明的。

偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁。降低获取锁的代价。

轻量级锁是指当锁是偏向锁的时候，被另一个线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，提高性能。

重量级锁是指当锁为轻量级锁的时候，另一个线程虽然是自旋，但自旋不会一直持续下去，当自旋一定次数的时候，还没有获取到锁，就会进入阻塞，该锁膨胀为重量级锁。重量级锁会让其他申请的线程进入阻塞，性能降低。

 

### 8.8 自旋锁

在Java中，自旋锁是指尝试获取锁的线程不会立即阻塞，而是采用循环的方式去尝试获取锁，这样的好处是减少线程上下文切换的消耗，缺点是循环会消耗CPU。

 

基本概念：自旋锁是SMP架构中的一种low-level的同步机制。

当线程A想要获取一把自旋锁而该锁又被其它线程锁持有时，线程A会在一个循环中自选以检测锁是不是已经可用了。

 

自旋锁需要注意：由于自旋时**不释放CPU**，因而持有自旋锁的线程应该尽快释放自旋锁，否则等待该自旋锁的线程会一直在那里自旋，这就会浪费CPU时间。持有自旋锁的线程在sleep之前应该释放自旋锁以便其它线程可以获得自旋锁。

 

目前的JVM实现自旋会消耗CPU，如果长时间不调用doNotify方法，doWait方法会一直自旋，CPU会消耗太大。

 

 

## 9、wait和sleep方法

最大的不同是在等待时wait会释放锁，而sleep一直持有锁。Wait通常被用于线程间交互，sleep通常被用于暂停执行。

 

此处我想理一下Java多线程的基础知识： 

\- Java的多线程锁是挂在对象上的，并不是在方法上的。即每个对象都有一个锁，当遇到类似synchronized的同步需要时，就会监视(monitor)每个想使用本对象的线程按照一定的规则来访问，规则也就是在同一时间内只能有一个线程能访问此对象。

\- Java中获取锁的单位是线程。当线程A获取了对象B的锁，也就是对象B的持有标记上写的是线程A的唯一标识，在需要同步的情况下的话，只有线程A能访问对象B。

\- Thread常用方法有：start/stop/yield/sleep/interrupt/join等，他们是线程级别的方法，所以并不会太关心锁的具体逻辑。

\- Object的线程有关方法是：wait/wait(事件参数)/notify/notifyAll，他们是对象的方法，所以使用的时候就有点憋屈了，必须当前线程获取了本对象的锁才能使用，否则会报异常。但他们能更细粒度的控制锁，可以释放锁。

 

## 10、Thread.sleep()唤醒以后是否需要重新竞争？（不需要）

sleep()方法是Thread类里面的，主要的意义就是让当前线程停止执行，让出cpu给其他的线程，**但是不会释放对象锁资源以及监控的状态**，当指定的时间到了之后又会自动恢复运行状态。

 

wait()方法是Object类里面的，主要的意义就是让线程放弃当前的对象的锁，进入等待此对象的等待锁定池，只有针对此对象调动notify方法后本线程才能够进入对象锁定池准备获取对象锁进入运行状态。

# 最终预测

根据今天的面试表现 之后有哪些地方可以重点提升一下

## 3、什么是死锁？死锁产生的条件？

1)死锁的概念

在两个或者多个并发进程中，如果每个进程持有某种资源而又等待其它进程释放它或它们现在保持着的资源，在未改变这种状态之前都不能向前推进，称这一组进程产生了死锁。通俗的讲，就是两个或多个进程无限期的阻塞、相互等待的一种状态。

2)死锁产生的四个必要条件

**互斥：**至少有一个资源必须属于非共享模式，即一次只能被一个进程使用；若其他申请使用该资源，那么申请进程必须等到该资源被释放为止；

**占有并等待：**一个进程必须占有至少一个资源，并等待另一个资源，而该资源为其他进程所占有；

**非抢占：**进程不能被抢占，即资源只能被进程在完成任务后自愿释放

**循环等待：**若干进程之间形成一种头尾相接的环形等待资源关系

 

 

## 4、堆和栈

C++

 

堆栈对比

 

 

 

Java 

在函数中定义的一些**基本类型的变量和对象的引用变量**都是在函数的栈内存中分配。当在一段代码块中定义一个变量时，java就在栈中为这个变量分配内存空间，当超过变量的作用域后，java会自动释放掉为该变量分配的内存空间，该内存空间可以立刻被另作他用。

堆内存用于存放**由new创建的对象和数组**。在堆中分配的内存，由java虚拟机自动垃圾回收器来管理。在堆中产生了一个数组或者对象后，还可以在栈中定义一个特殊的变量，这个变量的取值等于数组或者对象在堆内存中的首地址，在栈中的这个特殊的变量就变成了数组或者对象的引用变量，以后就可以在程序中使用栈内存中的引用变量来访问堆中的数组或者对象，引用变量相当于为数组或者对象起的一个别名，或者代号。

## 5、[数据库的ACID特性详解](https://www.cnblogs.com/dyfbk/p/7725051.html)

ACID是指在 数据库管理系统（DBMS）中事物所具有的四个特性：原子性、一致性、隔离性、持久性

事物：在数据库系统中，一个事务是指由一系列连续的数据库操作组成的一个完整的逻辑过程。这组操作执行前后，系统需要处于一个可预知的、一致的状态。

1、原子性：在一个事物中所有的操作要么都成功，要么都失败。如银行转账，A向B账户转账1000元，这里可分为三个操作，1.A向B转账、2.银行处理、3.B账户收到转账。原子性就是保证这三个操作要么都成功，要么多失败，如果1、2操作成功，3失败了，那么1、2操作要进行回滚

2、一致性：在事务执行前后，数据库的一致性约束没有被破坏。ACID中的一致性包含实体完整性约束不被破坏，完整性包含实体完整性（主属性不为空）、参照完整性（外键必须存在原表中）、用户自定义的完整性。比如列值非空（not null）、列值唯一（unique）、列值是否满足一个bool表达式（check语句，如性别只能有两个值、岁数是一定范围内的整数等），例如age smallint CHECK (age >=0 AND age <= 120).数据库保证age的值在[0, 120]的范围，如果不在这个范文，那么更新操作失败，事务也会失败。

3、隔离性：隔离性是指两个事物之间互不干扰。实现事物隔离性主要有两种方式。1.枷锁、2.多版本控制。

在并发环境当中，当不同的事务访问相同的数据时，每个事务都有各自的完整的数据空间，由于并发事务所做的修改必须与并发的其他事务的修改隔离，所以事务查看数据更新时，数据所处的状态要么是另一个事务开始前的状态，要么就是另一个事务结束后的状态，不会查看到中间状态数据。

事务最复杂的问题都是由隔离性引起的，但是完全的隔离是不现实的，完全的隔离要求数据库同一时间只能执行一个事务，这样会严重影响性能。

事务并发问题

\1. 脏读：事务A读取了事务B的更新的数据，但是事务B回滚了，导致A读取的为脏数据。

\2. 不可重复读：事务A读取同一数据两次，但是在两次之间事务B对该数据进行了修改并提交，导致事务A读取两次读取不一致

\3. 幻读：事务A修改全表的数据，在未提交时，事务B向表中插入或删除数据，导致事务A读取的数据与需要修改的数据不一致，就和幻觉一样。

注意：不可重复读和幻读很容易混淆，不可重复读针对的是数据的修改，幻读针对的是数据的新增和删除。解决不可重复读问题只需要给对应记录上**行锁**，而解决幻读需要对**表加锁**。

隔离级别

\1. 未提交读（read uncommitted），就是不做隔离控制，可以读到“脏数据”，比如A和B转账，当A账户修改后，在执行B账户修改时，事务还未提交，其他事务同样需要读取A账户的数据，那么这个时候是可以读到A账户修改后数据的。但是这个时候如果处理失败，则会导致其他事务读取的A账户的数据是错误的，这个问题就叫做脏读。显然这个隔离级别没有太大意义，现实中没有人会用，除非这个应用只有读取，没有任何写入。

\2. 提交读（read committed），提交读就是不允许读取事务没有提交的数据。显然这种级别可以避免了脏读问题。例如A和B转账，当A账户修改后，在执行B账户修改时，事务还未提交，其他事务同样读取A账户的数据，那么这个时候读取的应该是事务开始前的数据（也就是A账户修改前的数据）。但是当其他事务在事务开始前读取，同时在事务结束后读取，这样会造成两次读取数据不一致的情况（因为两次查询到的数据是不一样，所以这个问题叫做不可重复读）。这个隔离级别是大多数数据库（除了mysql）的默认隔离级别。

\3. 可重复读（repeatable read），与提交读（不可重复读）相对应，为了避免提交读级别不可重复读的问题，在事务中对符合条件的记录上排他锁，这样其他事务不能对该事务操作的数据进行修改，可避免不可重复读的问题产生。由于只对操作数据进行上锁的操作，所以当其他事务插入或删除数据时，会出现幻读的问题，此种隔离级别为Mysql默认的隔离级别。

\4. 序列化（Serializable），在事务中对表上锁，这样在事务结束前，其他事务都不能够对表数据进行操作（包括新增，删除和修改），这样避免了脏读，不可重复读和幻读，是最安全的隔离级别。但是由于该操作是堵塞的，不能够让其他事务进行操作，因此此种隔离级别性能会受到影响。

隔离级别解决事务并发问题表

 

4、持久性：事物对数据库所做的更改会持久的保存在数据库中，不会被回滚。持久性需要考虑到事物在执行过程中可能出现的各种异常，并对异常做出相应的处理。

## 6、同步与异步  阻塞与非阻塞

**同步阻塞IO：**在此种方式下，用户进程在发起一个IO操作以后，必须等待IO操作的完成，只有当真正完成了IO操作以后，用户进程才能运行。

**同步非阻塞IO：**在此种方式下，用户进程发起一个IO操作以后可返回做其它事情，但是用户进程需要时不时的询问IO操作是否就绪，这就要求用户进程不停的去询问，从而引入不必要的CPU资源浪费。

**异步阻塞IO：**此种方式下是指应用发起一个IO操作以后，不等待内核IO操作的完成，等内核完成IO操作以后会通知应用程序，这其实就是同步和异步最关键的区别同步必须等待或者主动的去询问IO是否完成，

**异步非阻塞IO：**在此种模式下，用户进程只需要发起一个IO操作然后立即返回，等IO操作真正的完成以后，应用程序会得到IO操作完成的通知，此时用户进程只需要对数据进行处理就好了，不需要进行实际的IO读写操作因为真正的IO读取或者写入操作已经由内核完成了。

 

## 8、Servlet

 

## 9、CoucurrentHashMap 锁分段技术

 

## 10、重写equals的注意事项

 

\1.  **自反性**：对于任何非空引用 x，`x.equals()`应该返回`true`。

\2.  **对称性**：对于任何引用 x 和 y，当且仅当`y.equals(x)`返回`true`，`x.equals(y)`也应该返回`true`。

\3.  **传递性**：对于任何引用 x、y 和 z，如果`x.equals(y)`返回`true`，`y.equals(z)`也应返回同样的结果。

\4.  **一致性**：如果 x 和 y 引用的对象没有发生变化，反复调用 `x.equals(y)` 应该返回同样的结果。

\5.  对于任意非空引用 x，`x.equals(null)`应该返回`false`。

 

在对象比较时，我们应该如何编写出一个符合特性的`equals`方法呢，《Core Java》中提出了如下建议：

\1.  显式参数命名为 otherObject，稍后将它转换成另一个叫做 other 的变量。

\2.      检测 this 与 otherObject 是否引用同一个对象： 

```
if (this == otherObject) return true;
```

计算这个等式可以避免一个个比较类中的域，实现优化。

\3.      检测 otherObject 是否为 null，如果为 null，返回 false。进行非空校验是十分重要的。

\4.      比较 this 与 otherObject 是否属于同一个类。

·     如果每个子类都重写了 `equals`，使用 `getClass` 检验：

```
5.  if (getClass() != otherObject.getClass()) 
    return false; 
```

·     如果所有子类都使用同一个 `equals`，就用 `instanceof` 检验：

```
if (!(otherObject instanceof ClassName))
    return false;
```

\6.      将 otherObject 转换为相应的类型变量。

```
ClassName other = (ClassName) otherObject;
```

\7.      现在可以对所有需要比较的域进行比较了。

·     基本类型使用 `==` 比较

·     对象使用 `equals` 比较

·     数组类型的域可以使用静态方法 `Arrays.equals`检测相应数组元素是否相等

·     如果所有域匹配，则返回 true

**注意：**子类重写父类`equals`方法时，必须完全覆盖父类方法，不能因为类型错误或者其他原因定义了一个完全无关的方法。可以使用`@Override`注解对覆盖父类的方法进行标记，这样编译器便会检测到覆盖过程中的错误。

## 11、重写hashCode的注意事项

散列码（hash code）是由对象导出的一个整型值。散列码没有规律，在不同的对象中通过不同的算法生成，Java中生成 hashCode 的策略为（以下说明均摘自 Java API 8）：

·   String 类的 hashCode 根据其字符串内容，使用算法计算后返回哈希码。

·   Integer 类返回的哈希码为其包含的整数数值。

·   Object 类的 hashCode 返回对象的内存地址经过处理后的数值。

在自己的类中想要重写`hashCode`的话一般怎么做呢？建议合理地组合实例域的散列码，让各个不同对象产生的散列码更加均匀。例如我们现在有一个`Cat`对象，它有`name`、`size`和`color`三个不同域，那么可以重写`hashCode`方法如下：

[     ](javascript:void(0);)

```
class Cat {
    ......
    public int hashCode() {
        //hashCode是可以返回负值的
        return 6 * name.hashCode()
            + 8 * new Double(size).hashCode()
            + 10 * color.hashCode();
    }
    ......
}
```

[     ](javascript:void(0);)

当然还有更好的做法，我们可以直接调用静态方法`Objects.hash`并提供多个参数。这个方法会对各个参数调用`Object.hashCode`，并组合返回的散列码。故以上的方法可以缩写为：

```
public int hashCode() {
    return Objects.hash(name, size, color);
}
```

**注意：**`**equals**`**与`hashCode`****的定义必须一致，两个对象`equals`****为`true`****，就必须有相同的`hashCode`****。例如：如果定义的`equals`****比较的是小猫的** **name****，那么`hashCode`****就需要散列该** **name****，而不是小猫的** **color** **或** **size****。**

## 12、四种引用

1.强引用：是指创建一个对象并把这个对象赋给一个引用变量。

强引用有引用变量指向时永远不会被垃圾回收，JVM宁愿抛出OutOfMemory错误也不会回收这种对象。

2.软引用：如果一个对象具有软引用，内存空间足够，垃圾回收器就不会回收它；

如果内存空间不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。

软引用可用来实现内存敏感的高速缓存,比如网页缓存、图片缓存等。使用软引用能防止内存泄露，增强程序的健壮性。

SoftReference的特点是它的一个实例保存对一个Java对象的软引用，该软引用的存在不妨碍垃圾收集线程对该Java对象的回收。也就是说，一旦SoftReference保存了对一个Java对象的软引用后，在垃圾线程对 这个Java对象回收前，SoftReference类所提供的get()方法返回Java对象的强引用。另外，一旦垃圾线程回收该Java对象之 后，get()方法将返回null。

3.弱引用：弱引用也是用来描述非必需对象的，当JVM进行垃圾回收时，无论内存是否充足，都会回收被弱引用关联的对象。

4.虚引用：虚引用和前面的软引用、弱引用不同，它并不影响对象的生命周期。在java中用java.lang.ref.PhantomReference类表示。如果一个对象与虚引用关联，则跟没有引用与之关联一样，在任何时候都可能被垃圾回收器回收。

要注意的是，虚引用必须和引用队列关联使用，当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会把这个虚引用加入到与之关联的引用队列中。程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。如果程序发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动。

 

# 树

## 红黑树

 

 

## B树、B+树

B+树是应文件系统所需而产生的一种B树的变形树(文件的目录一级一级索引,只有最底层的叶子节点(文件)保存数据.),非叶子节点只保存索引,不保存实际的数据,数据都保存在叶子节点中.

 

（数据库和文件系统的索引、B-树随机效果可能好，因为B-树非终端节点存储关键字索引，但B+树出度更大，平均效果好）[b+树相较于b-树，一方面所有关键字存储在最后一层，另一方面有两种查询方式，一种指向第一个叶子节点关键字的顺序查找，另一种指向根节点的随机查找][对于文件系统而言，插入一个数据，如果需要分裂一个节点，则需要做很多的操作，可以通过旋转从兄弟节点转移来解决这一问题]和红黑树（C++ set与map、Linux虚拟内存）

 

# 操作系统

## 2、线程创建

继承Thread类

实现Runnable接口

实现Callable接口

## 3、线程同步的方式

1）互斥量 Synchronized/Lock：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问

2）信号量 Semphare：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量

3）事件(信号)，Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作

 

## 5、死锁和活锁的区别？死锁和饥饿的区别？

死锁：当有两个或更多的线程在等待对方释放锁并无限期地卡住时，这种情况就称为死锁。

活锁：T1能使用资源A，但是它比较礼貌，让给了T2，T2此时能使用资源A，但是它也很绅士，选择让给T1，于是就这么让来让去，循环下去。

饥饿：非公平锁的抢占机制就会可能导致饥饿，当T1线程占用了资源A，T2，T3，T4…都在等待锁的释放，当锁释放的时候，T3抢到了资源，之后又释放锁，T4抢到了资源…T2 总是抢不到。这就是饿死。

 

死锁查看的常用两种方法： 

1、jstack

 

2、jconsole

 

## 5、进程有哪几种状态？

就绪状态：进程已获得除处理机以外的所需资源，等待分配处理机资源；

运行状态：占用处理机资源运行，处于此状态的进程数小于等于CPU数；

阻塞状态：进程等待某种条件，在条件满足之前无法执行；

 

 

 

## 6、Linux进程的生命周期

**在Linux内核，涉及进程和程序的所有算法都围绕一个名为task_struct的数据结构建立。在其中，state指定了进程的当前状态，有下列值：**

**运行状态（TASK_RUNNING）：**意味着进程处于可运行状态。并不意味着已经实际分配了CPU。进程可能会一直等到调度器选中它。该状态确保进程可以立即运行，而无需等待外部事件。Linux 中使用TASK_RUNNING 宏表示此状态。

**可中断睡眠状态（浅度睡眠）（TASK_INTERRUPTIBLE）：**针对等待某事件或其他资源的睡眠进程设置的。在内核发送信号给该进程表面事件已经发生时，进程状态变为TASK_RUNNING，它只要调度器选中该进程即可恢复执行。Linux 使用TASK_INTERRUPTIBLE 宏表示此状态。

**不可中断睡眠状态（深度睡眠状态）（TASK_UNINTERRUPTIBLE）：**其和浅度睡眠基本类似，因内核指示而停用的睡眠进程。不能由外部信号唤醒，只能由内核亲自唤醒。Linux 使用TASK_UNINTERRUPTIBLE 宏表示此状态。

**暂停状态（TASK_STOPPED）：**进程暂停执行接受某种处理。如正在接受调试的进程处于这种状态，Linux 使用TASK_STOPPED 宏表示此状态。

**僵死状态（TASK_ZOMBIE）：**进程已经结束但未释放PCB，Linux 使用TASK_ZOMBIE宏表示此状态

 

## 7、线程有几种状态？

  在 Java虚拟机 中，线程从最初的创建到最终的消亡，要经历若干个状态：创建(new)、就绪(runnable/start)、运行(running)、阻塞(blocked)、等待(waiting)、时间等待(time waiting) 和 消亡(dead/terminated)。在给定的时间点上，一个线程只能处于一种状态。

 

## 8、分页和分段有什么区别（内存管理）？

 

 

 

 

 

  段式存储管理是一种符合用户视角的内存分配管理方案。在段式存储管理中，将程序的地址空间划分为若干段（segment），如代码段，数据段，堆栈段；这样每个进程有一个二维地址空间，相互独立，互不干扰。段式管理的优点是：没有内碎片（因为段大小可变，改变段大小来消除内碎片）。但段换入换出时，会产生外碎片（比如4k的段换5k的段，会产生1k的外碎片）

  页式存储管理方案是一种用户视角内存与物理内存相分离的内存分配管理方案。在页式存储管理中，将程序的逻辑地址划分为固定大小的页（page），而物理内存划分为同样大小的帧，程序加载时，可以将任意一页放入内存中任意一个帧，这些帧不必连续，从而实现了离散分离。页式存储管理的优点是：没有外碎片（因为页的大小固定），但会产生内碎片（一个页可能填充不满）。

 

两者的不同点：

1）目的不同：分页是由于系统管理的需要而不是用户的需要，它是信息的物理单位；分段的目的是为了能更好地满足用户的需要，它是信息的逻辑单位，它含有一组其意义相对完整的信息；

2）大小不同：页的大小固定且由系统决定，而段的长度却不固定，由其所完成的功能决定；

3）地址空间不同：段向用户提供二维地址空间；页向用户提供的是一维地址空间；

4）信息共享：段是信息的逻辑单位，便于存储保护和信息的共享，页的保护和共享受到限制；

5）内存碎片：页式存储管理的优点是没有外碎片（因为页的大小固定），但会产生内碎片（一个页可能填充不满）；而段式管理的优点是没有内碎片（因为段大小可变，改变段大小来消除内碎片）。但段换入换出时，会产生外碎片（比如4k的段换5k的段，会产生1k的外碎片）。

 

## 9、操作系统中进程调度策略有哪几种？

1）FCFS(先来先服务，队列实现，非抢占的)：先请求CPU的进程先分配到CPU

2）SJF(最短作业优先调度算法)：平均等待时间最短，但难以知道下一个CPU区间长度

3）优先级调度算法(可以是抢占的，也可以是非抢占的)：优先级越高越先分配到CPU，相同优先级先到先服务，存在的主要问题是：低优先级进程无穷等待CPU，会导致无穷阻塞或饥饿；解决方案：老化

4）时间片轮转调度算法(可抢占的)：队列中没有进程被分配超过一个时间片的CPU时间，除非它是唯一可运行的进程。如果进程的CPU区间超过了一个时间片，那么该进程就被抢占并放回就绪队列。

5）多级队列调度算法：将就绪队列分成多个独立的队列，每个队列都有自己的调度算法，队列之间采用固定优先级抢占调度。其中，一个进程根据自身属性被永久地分配到一个队列中。

6）多级反馈队列调度算法：与多级队列调度算法相比，其允许进程在队列之间移动：若进程使用过多CPU时间，那么它会被转移到更低的优先级队列；在较低优先级队列等待时间过长的进程会被转移到更高优先级队列，以防止饥饿发生。

## 10、说一说进程同步有哪几种机制

原子操作、信号量机制、自旋锁管程、会合、分布式系统

## 11、什么是虚拟内存？

  虚拟内存允许执行进程不必完全在内存中。虚拟内存的基本思想是：每个进程拥有独立的地址空间，这个空间被分为大小相等的多个块，称为页(Page)，每个页都是一段连续的地址。这些页被映射到物理内存，但并不是所有的页都必须在内存中才能运行程序。当程序引用到一部分在物理内存中的地址空间时，由硬件立刻进行必要的映射；当程序引用到一部分不在物理内存中的地址空间时，由操作系统负责将缺失的部分装入物理内存并重新执行失败的命令。这样，对于进程而言，逻辑上似乎有很大的内存空间，实际上其中一部分对应物理内存上的一块(称为帧，通常页和帧大小相等)，还有一些没加载在内存中的对应在硬盘上，如图5所示。

注意，请求分页系统、请求分段系统和请求段页式系统都是针对虚拟内存的，通过请求实现内存与外存的信息置换。

 

  由图5可以看出，虚拟内存实际上可以比物理内存大。当访问虚拟内存时，会访问MMU（内存管理单元）去匹配对应的物理地址（比如图5的0，1，2）。如果虚拟内存的页并不存在于物理内存中（如图5的3,4），会产生缺页中断，从磁盘中取得缺的页放入内存，如果内存已满，还会根据某种算法将磁盘中的页换出。

## 12、页面置换算法  颠簸（抖动）

  FIFO先进先出算法：在操作系统中经常被用到，比如作业调度（主要实现简单，很容易想到）；

  LRU（Least recently use）最近最少使用算法：根据使用时间到现在的长短来判断；

  LFU（Least frequently use）最少使用次数算法：根据使用次数来判断；

  OPT（Optimal replacement）最优置换算法：理论的最优，理论；就是要保证置换出去的是不再被使用的页，或者是在实际内存中最晚使用的算法。

注：Belady现象：对有的页面置换算法，页错误率可能会随着分配帧数增加而增加。FIFO会产生Belady异常；栈式算法无Belady异常：LRU，LFU（最不经常使用），OPT。

 

4)虚拟内存的应用与优点

  虚拟内存很适合在多道程序设计系统中使用，许多程序的片段同时保存在内存中。当一个程序等待它的一部分读入内存时，可以把CPU交给另一个进程使用。虚拟内存的使用可以带来以下好处：

  在内存中可以保留多个进程，系统并发度提高

  解除了用户与内存之间的紧密约束，进程可以比内存的全部空间还大

 

 

 

  颠簸本质上是指频繁的页调度行为，具体来讲，进程发生缺页中断，这时，必须置换某一页。然而，其他所有的页都在使用，它置换一个页，但又立刻再次需要这个页。因此，会不断产生缺页中断，导致整个系统的效率急剧下降，这种现象称为颠簸（抖动）。

  内存颠簸的解决策略包括：

  如果是因为页面替换策略失误，可以修改替换算法来解决这个问题；

  如果是因为运行的程序太多，造成程序无法同时将所有频繁访问的页面调入内存，则要降低多道程序的数量；

  否则，还剩下两个办法：终止该进程或增加物理内存容量。

## 13、局部性原理

(1)时间上的局部性：最近被访问的页在不久的将来还会被访问；

(2)空间上的局部性：内存中被访问的页周围的页也很可能被访问。

## 15、用户态和核心态

当程序运行在3级特权级上时，就可以称之为运行在用户态，因为这是最低特权级，是普通的用户进程运行的特权级，大部分用户直接面对的程序都是运行在用户态；

反之，当程序运行在级特权级上时，就可以称之为运行在内核态。

虽然用户态下和内核态下工作的程序有很多差别，但最重要的差别就在于特权级的不同，即权力的不同。运行在用户态下的程序不能直接访问操作系统内核数据结构和程序。

当我们在系统中执行一个程序时，大部分时间是运行在用户态下的，在其需要操作系统帮助完成某些它没有权力和能力完成的工作时就会切换到内核态。

**用户态切换到内核态的3种方式**

1）系统调用：这是用户态进程主动要求切换到内核态的一种方式，用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的int 80h中断。

2）异常：当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。

3）外围设备的中断：当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。

 

 

 

## 16、进程上下文切换与和线程上下文切换有什么不同？

1）什么是上下文切换？ 

上下文切换就是从当前执行任务切换到另一个任务执行的过程。但是，为了确保下次能从正确的位置继续执行，在切换之前，会保存上一个任务的状态。

2）所以，进程上下文切换与线程上下文切换最主要的区别就是**线程的切换虚拟空间内存是相同的（因为都是属于自己的进程），但是，进程切换的虚拟空间内存则是不同的。**同时，这两种上下文切换的处理都是通过操作系统内核来完成的。内核的这种切换过程伴随的最显著的性能损耗是将寄存器中的内容切换出。线程上下文切换比进程上下文切换快的多。

 

## 19. 多线程的上下文切换

即使是单核CPU也支持多线程执行代码，CPU通过给每个线程分配CPU时间片来实现这个机制。时间片是CPU分配给各个线程的时间，因为时间片非常短，所以CPU通过不停地切换线程执行，让我们感觉多个线程时同时执行的，时间片一般是几十毫秒（ms）。

CPU通过时间片分配算法来循环执行任务，当前任务执行一个时间片后会切换到下一个任务。但是，在切换前会保存上一个任务的状态，以便下次切换回这个任务时，可以再次加载这个任务的状态，从任务保存到再加载的过程就是一次上下文切换。

 

多线程环境中，当一个线程的状态由Runnable转换为非Runnable（Blocked、Waiting、Timed_Waiting）时，相应线程的上下文信息（包括cpu的寄存器和程序计数器在某一时间点的内容等）需要被保存，以便相应线程稍后再次进入Runnable状态时能够在之前的执行进度的基础上继续前进。而一个线程从非Runnable状态进入Runnable状态可能涉及恢复之前保存的上下文信息。这个对线程的上下文进行保存和恢复的过程就被称为上下文切换。

 

如何减少上下文切换

1）无锁并发编程。多线程竞争时，会引起上下文切换，所以多线程处理数据时，可以用一些办法来避免使用锁，如将数据的ID按照Hash取模分段，不同的线程处理不同段的数据

2）CAS算法。Java的Atomic包使用CAS算法来更新数据，而不需要加锁

3）使用最少线程。避免创建不需要的线程，比如任务很少，但是创建了很多线程来处理，这样会造成大量线程都处于等待状态

4）协程。在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换

 

## Windows下的内存是如何管理的？

  Windows提供了3种方法来进行内存管理：**虚拟内存**，最适合用来管理大型对象或者结构数组；**内存映射文件**，最适合用来管理大型数据流（通常来自文件）以及在单个计算机上运行多个进程之间共享数据；**内存堆栈**，最适合用来管理大量的小对象。

  Windows操纵内存可以分两个层面：物理内存和虚拟内存。

  其中物理内存由系统管理，不允许应用程序直接访问，应用程序可见的只有一个2G地址空间，而内存分配是通过堆进行的。对于每个进程都有自己的默认堆，当一个堆创建后，就通过虚拟内存操作保留了相应大小的地址块（不占有实际的内存，系统消耗很小）。当在堆上分配一块内存时，系统在堆的地址表里找到一个空闲块（如果找不到，且堆创建属性是可扩充的，则扩充堆大小），为这个空闲块所包含的所有内存页提交物理对象（在物理内存上或硬盘的交换文件上），这时就可以访问这部分地址。提交时，系统将对所有进程的内存统一调配，如果物理内存不够，系统试图把一部分进程暂时不访问的页放入交换文件，以腾出部分物理内存。释放内存时，只在堆中将所在的页解除提交（相应的物理对象被解除），继续保留地址空间。

  如果要知道某个地址是否被占用/可不可以访问，只要查询此地址的虚拟内存状态即可。如果是提交，则可以访问。如果仅仅保留，或没保留，则产生一个软件异常。此外，有些内存页可以设置各种属性。如果是只读，向内存写也会产生软件异常。

 

## Windows消息调度机制是？

消息队列；

处理消息队列的顺序。首先Windows绝对不是按队列先进先出的次序来处理的，而是有一定优先级的。优先级通过消息队列的状态标志来实现的。首先，最高优先级的是别的线程发过来的消息（通过sendmessage）；其次，处理登记消息队列消息；再次处理QS_QUIT标志，处理虚拟输入队列，处理wm_paint；最后是wm_timer。

 

 

## 4、什么是死锁？死锁产生的条件？

1)死锁的概念

在两个或者多个并发进程中，如果每个进程持有某种资源而又等待其它进程释放它或它们现在保持着的资源，在未改变这种状态之前都不能向前推进，称这一组进程产生了死锁。通俗的讲，就是两个或多个进程无限期的阻塞、相互等待的一种状态。

2)死锁产生的四个必要条件

**互斥：**至少有一个资源必须属于非共享模式，即一次只能被一个进程使用；若其他申请使用该资源，那么申请进程必须等到该资源被释放为止；

**占有并等待：**一个进程必须占有至少一个资源，并等待另一个资源，而该资源为其他进程所占有；

**非抢占：**进程不能被抢占，即资源只能被进程在完成任务后自愿释放

**循环等待：**若干进程之间形成一种头尾相接的环形等待资源关系

3)死锁的处理基本策略和常用方法

解决死锁的基本方法主要有 预防死锁、避免死锁、检测死锁、解除死锁 、鸵鸟策略等。

  (1)死锁预防

  死锁预防的基本思想是：只要确保死锁发生的四个必要条件中至少有一个不成立，就能预防死锁的发生，具体方法包括：

  打破互斥条件：**允许进程同时访问某些资源。**但是，有些资源是不能被多个进程所共享的，这是由资源本身属性所决定的，因此，这种办法通常并无实用价值。

  打破占有并等待条件：可以实行资源预先分配策略(进程在运行前一次性向系统申请它所需要的全部资源，若所需全部资源得不到满足，则不分配任何资源，此进程暂不运行；只有当系统能满足当前进程所需的全部资源时，才一次性将所申请资源全部分配给该线程)或者只允许进程在没有占用资源时才可以申请资源（一个进程可申请一些资源并使用它们，但是在当前进程申请更多资源之前，它必须全部释放当前所占有的资源）。但是这种策略也存在一些缺点：在很多情况下，无法预知一个进程执行前所需的全部资源，因为进程是动态执行的，不可预知的；同时，会降低资源利用率，导致降低了进程的并发性。

  打破非抢占条件：允许进程强行从占有者哪里夺取某些资源。也就是说，但一个进程占有了一部分资源，在其申请新的资源且得不到满足时，它必须释放所有占有的资源以便让其它线程使用。这种预防死锁的方式实现起来困难，会降低系统性能。

  打破循环等待条件：实行资源有序分配策略。对所有资源排序编号，所有进程对资源的请求必须严格按资源序号递增的顺序提出，即只有占用了小号资源才能申请大号资源，这样就不回产生环路，预防死锁的发生。

  (2)死锁避免的基本思想

  死锁避免的基本思想是**动态地检测资源分配状态**，以确保循环等待条件不成立，从而确保系统处于安全状态。所谓安全状态是指：如果系统能按某个顺序为每个进程分配资源（不超过其最大值），那么系统状态是安全的，换句话说就是，如果存在一个安全序列，那么系统处于安全状态。**资源分配图算法和银行家算法**是两种经典的死锁避免的算法，其可以确保系统始终处于安全状态。其中，资源分配图算法应用场景为每种资源类型只有一个实例(申请边，分配边，需求边，不形成环才允许分配)，而银行家算法应用于每种资源类型可以有多个实例的场景。

  (3)死锁解除

  死锁解除的常用两种方法为**进程终止和资源抢占**。所谓进程终止是指简单地终止一个或多个进程以打破循环等待，包括两种方式：终止所有死锁进程和一次只终止一个进程直到取消死锁循环为止；所谓资源抢占是指从一个或多个死锁进程那里抢占一个或多个资源，此时必须考虑三个问题：

  (I)选择一个牺牲品

  (II)回滚：回滚到安全状态

  (III)饥饿（在代价因素中加上回滚次数，回滚的越多则越不可能继续被作为牺牲品，避免一个进程总是被回滚）

 

# 数据库

## 1、[数据库的ACID特性详解](https://www.cnblogs.com/dyfbk/p/7725051.html)

ACID是指在 数据库管理系统（DBMS）中事物所具有的四个特性：原子性、一致性、隔离性、持久性

事物：在数据库系统中，一个事务是指由一系列连续的数据库操作组成的一个完整的逻辑过程。这组操作执行前后，系统需要处于一个可预知的、一致的状态。

1、原子性：在一个事物中所有的操作要么都成功，要么都失败。如银行转账，A向B账户转账1000元，这里可分为三个操作，1.A向B转账、2.银行处理、3.B账户收到转账。原子性就是保证这三个操作要么都成功，要么多失败，如果1、2操作成功，3失败了，那么1、2操作要进行回滚

2、一致性：在事务执行前后，数据库的一致性约束没有被破坏。ACID中的一致性包含实体完整性约束不被破坏，完整性包含实体完整性（主属性不为空）、参照完整性（外键必须存在原表中）、用户自定义的完整性。比如列值非空（not null）、列值唯一（unique）、列值是否满足一个bool表达式（check语句，如性别只能有两个值、岁数是一定范围内的整数等），例如age smallint CHECK (age >=0 AND age <= 120).数据库保证age的值在[0, 120]的范围，如果不在这个范文，那么更新操作失败，事务也会失败。

3、隔离性：隔离性是指两个事物之间互不干扰。实现事物隔离性主要有两种方式。1.枷锁、2.多版本控制。

在并发环境当中，当不同的事务访问相同的数据时，每个事务都有各自的完整的数据空间，由于并发事务所做的修改必须与并发的其他事务的修改隔离，所以事务查看数据更新时，数据所处的状态要么是另一个事务开始前的状态，要么就是另一个事务结束后的状态，不会查看到中间状态数据。

事务最复杂的问题都是由隔离性引起的，但是完全的隔离是不现实的，完全的隔离要求数据库同一时间只能执行一个事务，这样会严重影响性能。

事务并发问题

\1. 脏读：事务A读取了事务B的更新的数据，但是事务B回滚了，导致A读取的为脏数据。

\2. 不可重复读：事务A读取同一数据两次，但是在两次之间事务B对该数据进行了修改并提交，导致事务A读取两次读取不一致

\3. 幻读：事务A修改全表的数据，在未提交时，事务B向表中插入或删除数据，导致事务A读取的数据与需要修改的数据不一致，就和幻觉一样。

注意：不可重复读和幻读很容易混淆，不可重复读针对的是数据的修改，幻读针对的是数据的新增和删除。解决不可重复读问题只需要给对应记录上**行锁**，而解决幻读需要对**表加锁**。

隔离级别

\1. 未提交读（read uncommitted），就是不做隔离控制，可以读到“脏数据”，比如A和B转账，当A账户修改后，在执行B账户修改时，事务还未提交，其他事务同样需要读取A账户的数据，那么这个时候是可以读到A账户修改后数据的。但是这个时候如果处理失败，则会导致其他事务读取的A账户的数据是错误的，这个问题就叫做脏读。显然这个隔离级别没有太大意义，现实中没有人会用，除非这个应用只有读取，没有任何写入。

\2. 提交读（read committed），提交读就是不允许读取事务没有提交的数据。显然这种级别可以避免了脏读问题。例如A和B转账，当A账户修改后，在执行B账户修改时，事务还未提交，其他事务同样读取A账户的数据，那么这个时候读取的应该是事务开始前的数据（也就是A账户修改前的数据）。但是当其他事务在事务开始前读取，同时在事务结束后读取，这样会造成两次读取数据不一致的情况（因为两次查询到的数据是不一样，所以这个问题叫做不可重复读）。这个隔离级别是大多数数据库（除了mysql）的默认隔离级别。

\3. 可重复读（repeatable read），与提交读（不可重复读）相对应，为了避免提交读级别不可重复读的问题，在事务中对符合条件的记录上排他锁，这样其他事务不能对该事务操作的数据进行修改，可避免不可重复读的问题产生。由于只对操作数据进行上锁的操作，所以当其他事务插入或删除数据时，会出现幻读的问题，此种隔离级别为Mysql默认的隔离级别。

\4. 序列化（Serializable），在事务中对表上锁，这样在事务结束前，其他事务都不能够对表数据进行操作（包括新增，删除和修改），这样避免了脏读，不可重复读和幻读，是最安全的隔离级别。但是由于该操作是堵塞的，不能够让其他事务进行操作，因此此种隔离级别性能会受到影响。

隔离级别解决事务并发问题表

 

4、持久性：事物对数据库所做的更改会持久的保存在数据库中，不会被回滚。持久性需要考虑到事物在执行过程中可能出现的各种异常，并对异常做出相应的处理。

 

**mysql的事务支持**

  MySQL的事务支持不是绑定在MySQL服务器本身，而是与存储引擎相关：

MyISAM：不支持事务，用于只读程序提高性能；

InnoDB：支持ACID事务、行级锁、并发；

Berkeley DB：支持事务。

## 2、MySQL

### 2.1 SQL语句优化

1）应尽量避免在 where 子句中使用!=或<>操作符，否则引擎将放弃使用索引而进行全表扫描。

2）应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描，如：

select id from t where num is null

可以在num上设置默认值0，确保表中num列没有null值，然后这样查询：

select id from t where num=0

3）很多时候用 exists 代替 in 是一个好的选择

4）用Where子句替换HAVING 子句 因为HAVING 只会在检索出所有记录之后才对结果集进行过滤

5）in 和 not in 也要慎用，否则会导致全表扫描，如：

select id from t where num in(1,2,3)

对于连续的数值，能用 between 就不要用 in 了：

select id from t where num between 1 and 3

6）不要在 where 子句中的“=”左边进行函数、算术运算或其他表达式运算，否则系统将可能无法正确使用索引

7）尽可能的使用 varchar 代替 char ，因为首先变长字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些

8）任何地方都不要使用 select * from t ，用具体的字段列表代替“*”，不要返回用不到的任何字段

9）尽量避免大事务操作，提高系统并发能力

10）应尽量避免在 where 子句中使用 or 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描，如：

select id from t where num=10 or num=20

可以这样查询：

select id from t where num=10  

union all 

select id from t where num=20

### 2.2 存储过程与触发器的区别

触发器与存储过程非常相似，触发器也是SQL语句集，两者唯一的区别是触发器不能用EXECUTE语句调用，而是在用户执行Transact-SQL语句时自动触发（激活）执行。触发器是在一个修改了指定表中的数据时执行的存储过程。通常通过创建触发器来强制实现不同表中的逻辑相关数据的引用完整性和一致性。由于用户不能绕过触发器，所以可以用它来强制实施复杂的业务规则，以确保数据的完整性。触发器不同于存储过程，触发器主要是通过事件执行触发而被执行的，而存储过程可以通过存储过程名称名字而直接调用。当对某一表进行诸如UPDATE、INSERT、DELETE这些操作时，SQLSERVER就会自动执行触发器所定义的SQL语句，从而确保对数据的处理必须符合这些SQL语句所定义的规则。

 

### 2.3 MySQL中myisam与innodb的区别

  在MySQL 5.5之前，MyISAM是mysql的默认数据库引擎，其由早期的ISAM（Indexed Sequential Access Method：有索引的顺序访问方法）所改良。虽然MyISAM性能极佳，但却有一个显著的缺点： 不支持事务处理。不过，MySQL也导入了另一种数据库引擎InnoDB，以强化参考完整性与并发违规处理机制，后来就逐渐取代MyISAM。

 

  InnoDB是MySQL的数据库引擎之一，其由Innobase oy公司所开发，2006年五月由甲骨文公司并购。与传统的ISAM、MyISAM相比，InnoDB的最大特色就是支持ACID兼容的事务功能，类似于PostgreSQL。目前InnoDB采用双轨制授权，一是GPL授权，另一是专有软件授权。具体地，MyISAM与InnoDB作为MySQL的两大存储引擎的差异主要包括：

  1）存储结构：每个MyISAM在磁盘上存储成三个文件：第一个文件的名字以表的名字开始，扩展名指出文件类型。.frm文件存储表定义，数据文件的扩展名为.MYD (MYData)，索引文件的扩展名是.MYI (MYIndex)。InnoDB所有的表都保存在同一个数据文件中（也可能是多个文件，或者是独立的表空间文件），InnoDB表的大小只受限于操作系统文件的大小，一般为2GB。

  2）存储空间：MyISAM可被压缩，占据的存储空间较小，支持静态表、动态表、压缩表三种不同的存储格式。InnoDB需要更多的内存和存储，它会在主内存中建立其专用的缓冲池用于高速缓冲数据和索引。

  3）可移植性、备份及恢复：MyISAM的数据是以文件的形式存储，所以在跨平台的数据转移中会很方便，同时在备份和恢复时也可单独针对某个表进行操作。InnoDB免费的方案可以是拷贝数据文件、备份 binlog，或者用 mysqldump，在数据量达到几十G的时候就相对痛苦了。

  4）事务支持：MyISAM强调的是性能，每次查询具有原子性，其执行数度比InnoDB类型更快，但是不提供事务支持。InnoDB提供事务、外键等高级数据库功能，具有事务提交、回滚和崩溃修复能力。

  5）AUTO_INCREMENT：在MyISAM中，可以和其他字段一起建立联合索引。引擎的自动增长列必须是索引，如果是组合索引，自动增长可以不是第一列，它可以根据前面几列进行排序后递增。InnoDB中必须包含只有该字段的索引，并且引擎的自动增长列必须是索引，如果是组合索引也必须是组合索引的第一列。

  6）表锁差异：MyISAM只支持表级锁，用户在操作MyISAM表时，select、update、delete和insert语句都会给表自动加锁，如果加锁以后的表满足insert并发的情况下，可以在表的尾部插入新的数据。InnoDB支持事务和行级锁。行锁大幅度提高了多用户并发操作的新能，但是InnoDB的行锁，只是在WHERE的主键是有效的，非主键的WHERE都会锁全表的。

  7）全文索引：MyISAM支持 FULLTEXT类型的全文索引；InnoDB不支持FULLTEXT类型的全文索引，但是innodb可以使用sphinx插件支持全文索引，并且效果更好。

 

  8）表主键：MyISAM允许没有任何索引和主键的表存在，索引都是保存行的地址。对于InnoDB，如果没有设定主键或者非空唯一索引，就会自动生成一个6字节的主键(用户不可见)，数据是主索引的一部分，附加索引保存的是主索引的值。

  9）表的具体行数：MyISAM保存表的总行数，select count() from table;会直接取出出该值；而InnoDB没有保存表的总行数，如果使用select count() from table；就会遍历整个表，消耗相当大，但是在加了wehre条件后，myisam和innodb处理的方式都一样。

  10）CURD操作：在MyISAM中，如果执行大量的SELECT，MyISAM是更好的选择。对于InnoDB，如果你的数据执行大量的INSERT或UPDATE，出于性能方面的考虑，应该使用InnoDB表。DELETE从性能上InnoDB更优，但DELETE FROM table时，InnoDB不会重新建立表，而是一行一行的删除，在innodb上如果要清空保存有大量数据的表，最好使用truncate table这个命令。

  11）外键：MyISAM不支持外键，而InnoDB支持外键。

  通过上述的分析，基本上可以考虑使用InnoDB来替代MyISAM引擎了，原因是InnoDB自身很多良好的特点，比如事务支持、存储过程、视图、行级锁、外键等。尤其在并发很多的情况下，相信InnoDB的表现肯定要比MyISAM强很多。另外，必须需要注意的是，任何一种表都不是万能的，合适的才是最好的，才能最大的发挥MySQL的性能优势。如果是不复杂的、非关键的Web应用，还是可以继续考虑MyISAM的，这个具体情况具体考虑。

 

 

 

(1)问5点不同；

1>.InnoDB支持事物，而MyISAM不支持事物

2>.InnoDB支持行级锁，而MyISAM支持表级锁

3>.InnoDB支持MVCC,而MyISAM不支持

 

 

 

4>.InnoDB支持外键，而MyISAM不支持

5>.InnoDB不支持全文索引，而MyISAM支持。

 

(2)innodb引擎的4大特性

插入缓冲（insert buffer),二次写(double write),自适应哈希索引(ahi),预读(read ahead)

 

(3)2者select count(*)哪个更快，为什么

myisam更快，因为myisam内部维护了一个计数器，可以直接调取。

 

 

### 2.4 MySQL中InnoDB引擎的行锁是通过加在什么上完成(或称实现)的？

InnoDB是基于索引来完成行锁

例: select * from tab_with_index where id = 1 for update;

for update 可以根据条件来完成行锁锁定,并且 id 是有索引键的列,

如果 id 不是索引键那么InnoDB将完成表锁,并发将无从谈起。

 

### 2.5 MySQL中varchar与char的区别以及varchar(50)中的50代表的涵义？

(1) varchar与char的区别

char是一种固定长度的类型，varchar则是一种可变长度的类型

(2) varchar(50)中50的涵义

最多存放50个字符，varchar(50)和(200)存储hello所占空间一样，但后者在排序时会消耗更多内存，因为order by col采用fixed_length计算col长度(memory引擎也一样)。

 

### 2.6 MySQL的复制原理以及流程

基本原理流程，3个线程以及之间的关联；

\1. 主：binlog线程——记录下所有改变了数据库数据的语句，放进master上的binlog中；

\2. 从：io线程——在使用start slave 之后，负责从master上拉取 binlog 内容，放进 自己的relay log中；

\3. 从：sql执行线程——执行relay log中的语句；

 

### 2.7 MySQL主从同步 负载均衡

**mysql主从同步（复制）定义**

主从同步使得数据可以从一个数据库服务器复制到其他服务器上，在复制数据时，一个服务器充当主服务器（master），其余的服务器充当从服务器（slave）。因为复制是异步进行的，所以从服务器不需要一直连接着主服务器，从服务器甚至可以通过拨号断断续续地连接主服务器。通过配置文件，可以指定复制所有的数据库，某个数据库，甚至是某个数据库上的某个表。

在一主多从的数据库体系中，多个从服务器采用异步的方式更新主数据库的变化，业务服务器在执行写或者相关修改数据库的操作是在主服务器上进行的，读操作则是在各从服务器上进行。如果配置了多个从服务器或者多个主服务器又涉及到相应的负载均衡问题（Mysql-proxy中间件）。

 

**主从同步机制**

Mysql服务器之间的主从同步是基于二进制日志机制，主服务器使用二进制日志来记录数据库的变动情况，从服务器通过读取和执行该日志文件来保持和主服务器的数据一致。

在使用二进制日志时，主服务器的所有操作都会被记录下来，然后从服务器会接收到该日志的一个副本。从服务器可以指定执行该日志中的哪一类事件（譬如只插入数据或者只更新数据），默认会执行日志中的所有语句。

每一个从服务器会记录关于二进制日志的信息：文件名和已经处理过的语句，这样意味着不同的从服务器可以分别执行同一个二进制日志的不同部分，并且从服务器可以随时连接或者中断和服务器的连接。

主服务器和每一个从服务器都必须配置一个唯一的ID号（在my.cnf文件的[mysqld]模块下有一个server-id配置项），另外，每一个从服务器还需要通过CHANGE MASTER TO语句来配置它要连接的主服务器的ip地址，日志文件名称和该日志里面的位置（这些信息存储在主服务器的数据库里）

 

https://wenku.baidu.com/view/39d3ee0c0975f46526d3e122.html

**使用主从同步的好处**

1）通过增加从服务器来提高数据库的性能，在主服务器上执行写入和更新，在从服务器上向外提供读功能，可以动态地调整从服务器的数量，从而调整整个数据库的性能。

2）提高数据安全-因为数据已复制到从服务器，从服务器可以终止复制进程，所以，可以在从服务器上备份而不破坏主服务器相应数据

3）在主服务器上生成实时数据，而在从服务器上分析这些数据，从而提高主服务器的性能

注意，mysql是异步复制的，而MySQL Cluster是同步复制的。有很多种主从同步的方法，但核心的方法有两种，Statement Based Replication（SBR）基于SQL语句的复制，另一种是Row Based Replication（RBR）基于行的复制，也可以使用Mixed Based Replication（MBR）。在mysql5.6中，默认使用的是SBR。而mysql 5.6.5和往后的版本是基于global transaction identifiers(GTIDs)来进行事务复制。当使用GTIDs时可以大大简化复制过程，因为GTIDs完全基于事务，只要在主服务器上提交了事务，那么从服务器就一定会执行该事务。

 

通过设置服务器的系统变量binlog_format来指定要使用的格式：

1.SBR：当使用二进制日志时，主服务器会把SQL语句写入到日志中，然后从服务器会执行该日志，这就是SBR，在mysql5.1.4之前的版本都只能使用这种格式。使用SBR会有如下长处：

1）日志文件更小

2）记录了所有的语句，可以用来日后审计

弊端：

1）使用如下函数的语句不能被正确地复制（不确定的语句）：load_file(); uuid(), uuid_short(); user(); found_rows(); sysdate(); get_lock(); is_free_lock(); is_used_lock(); master_pos_wait(); rand(); release_lock(); sleep(); version();

2）在日志中出现如下警告信息的不能正确地复制：[Warning] Statement is not safe to log in statement format.

3）或者在客户端中出现show warnings

4）Insert … select语句会执行大量的行级锁表

5）Update语句会执行大量的行级锁表来扫描整个表

2.RBR：主服务器把表的行变化作为事件写入到二进制日志中，主服务器把代表了行变化的事件复制到从服务中，使用RBR的长处：

1）所有的数据变化都是被复制，这是最安全的复制方式

2）更少的行级锁表

弊端：

1）日志会很大

2）不能通过查看日志来审计执行过的sql语句，不过可以通过使用mysqlbinlog 

--base64-output=decode-rows --verbose来查看数据的 变动

3.MBR：既使用SBR也使用RBR，默认使用SBR

### 2.8 怎么发现有问题的SQL?（通过MySQL慢查询日志对有效率问题的SQL进行监控）

MySQL的慢查询日志是MySQL提供的一种日志记录，它用来记录在MySQL中响应时间超过阀值的语句，具体指运行时间超过long_query_time值的SQL，则会被记录到慢查询日志中。long_query_time的默认值为10，意思是运行10s以上的语句。慢查询日志的相关参数如下所示：

 

 

### 2.9 mysql调优三步曲(慢查询、explain、profile)

mysql profile explain slow_query_log分析优化查询

在做性能测试中经常会遇到一些sql的问题，其实做性能测试这几年遇到问题最多还是数据库这块，要么就是IO高要么就是cpu高，所以对数据的优化在性能测试过程中占据着很重要的地方，下面我就介绍一些msyql性能调优过程中经常用到的三件利器：

1、慢查询（分析出现出问题的sql）

2、Explain（显示了mysql如何使用索引来处理select语句以及连接表。可以帮助选择更好的索引和写出更优化的查询语句）

3、Profile（查询到SQL会执行多少时间,并看出CPU/Memory 使用量,执行过程中Systemlock,Table lock花多少时间等等.）

## 3、redis

### 3.1 Redis优点

Redis是一款基于内存的且支持持久化、高性能的Key-Value NoSQL 数据库，其支持丰富数据类型(string，list，set，sorted set，hash)，常被用作缓存的解决方案。Redis具有以下显著特点：

  1）速度快，因为数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)；

  2）支持丰富数据类型，支持string，list，set，sorted set，hash；

  3）支持事务，操作都是原子性，所谓的原子性就是对数据的更改要么全部执行，要么全部不执行；

  4）丰富的特性：可用于缓存，消息，按key设置过期时间，过期后将会自动删除。

 

### 3.2 Redis持久化的几种方式

 

 

 

 

 

### 3.3 基本的redis的容灾策略

1 采用master-slave方式

2 为了得到好的读写性能，master不做任何的持久化

3 slave同时开启Snapshot和AOF来进行持久化，保证数据的安全性 

4 当master挂掉后，修改slave为master 

5 恢复原master数据，修改原先master为slave，启动slave

6 若master与slave都挂掉后，调用命令通过aof和snapshot进行恢复

恢复时要先确保恢复文件都正确了，才能启动主库；也可以先启动slave，将master与slave对调

 

 

### 3.4 Redis作查询缓存需要注意的问题：包括防止脏读、序列化查询结果、为查询结果生成一个标识和怎么使用四个问题

 

 

## 4、数据库范式（）

第一范式：列不可分，eg:【联系人】（姓名，性别，电话），一个联系人有家庭电话和公司电话，那么这种表结构设计就没有达到 1NF；

第二范式：有主键，保证完全依赖。eg:订单明细表【OrderDetail】（OrderID，ProductID，UnitPrice，Discount，Quantity，ProductName），Discount（折扣），Quantity（数量）完全依赖（取决）于主键（OderID，ProductID），而 UnitPrice，ProductName 只依赖于 ProductID，不符合2NF；

第三范式：无传递依赖(非主键列 A 依赖于非主键列 B，非主键列 B 依赖于主键的情况)，eg:订单表【Order】（OrderID，OrderDate，CustomerID，CustomerName，CustomerAddr，CustomerCity）主键是（OrderID），CustomerName，CustomerAddr，CustomerCity 直接依赖的是 CustomerID（非主键列），而不是直接依赖于主键，它是通过传递才依赖于主键，所以不符合 3NF。

 

## 5、数据库索引

**索引是对数据库表中一个或多个列的值进行排序的数据结构，以协助快速查询、更新数据库表中数据。**索引的实现通常使用B_TREE及其变种。索引加速了数据访问，因为存储引擎不会再去扫描整张表得到需要的数据；相反，它从根节点开始，根节点保存了子节点的指针，存储引擎会根据指针快速寻找数据。

 

 

### 5.1 索引的底层实现原理和优化

  在数据结构中，我们最为常见的搜索结构就是二叉搜索树和AVL树(高度平衡的二叉搜索树，为了提高二叉搜索树的效率，减少树的平均搜索长度)了。然而，无论二叉搜索树还是AVL树，当数据量比较大时，都会由于树的深度过大而造成I/O读写过于频繁，进而导致查询效率低下，因此对于索引而言，多叉树结构成为不二选择。**特别地，B-Tree的各种操作能使B树保持较低的高度，从而保证高效的查找效率。**

(1)B-Tree(平衡多路查找树)

  B_TREE是一种平衡多路查找树，是一种动态查找效率很高的树形结构。B_TREE中所有结点的孩子结点的最大值称为B_TREE的阶，B_TREE的阶通常用m表示，简称为m叉树。一般来说，应该是m>=3。一颗m阶的B_TREE或是一颗空树，或者是满足下列条件的m叉树：

  a)树中每个结点最多有m个孩子结点；

 

  b)若根结点不是叶子节点，则根结点至少有2个孩子结点；

  c)除根结点外，其它结点至少有(m/2的上界)个孩子结点；

  d)结点的结构如下图所示，其中，n为结点中关键字个数，(m/2的上界)-1 <= n <= m-1；di(1<=i<=n)为该结点的n个关键字值的第i个，且di< d(i+1)；ci(0<=i<=n)为该结点孩子结点的指针，且ci所指向的节点的关键字均大于或等于di且小于d(i+1)；

 

  e)所有的叶结点都在同一层上，并且不带信息（可以看作是外部结点或查找失败的结点，实际上这些结点不存在，指向这些结点的指针为空）。

  B_TREE的查找类似二叉排序树的查找，所不同的是B-树每个结点上是多关键码的有序表，在到达某个结点时，先在有序表中查找，若找到，则查找成功；否则，到按照对应的指针信息指向的子树中去查找，当到达叶子结点时，则说明树中没有对应的关键码。由于B_TREE的高检索效率，B-树主要应用在文件系统和数据库中，对于存储在硬盘上的大型数据库文件，可以极大程度减少访问硬盘次数，大幅度提高数据检索效率。

(2)**B+Tree****：InnoDB存储引擎的索引实现**

  B+Tree是应文件系统所需而产生的一种B_TREE树的变形树。一棵m阶的B+树和m阶的B_TREE的差异在于以下三点：

  a)n 棵子树的结点中含有n个关键码；

  b)所有的叶子结点中包含了全部关键码的信息，及指向含有这些关键码记录的指针，且叶子结点本身依关键码的大小自小而大的顺序链接；

  c)非终端结点可以看成是索引部分，结点中仅含有其子树根结点中最大（或最小）关键码。

 

  可以对B+树进行两种查找运算：**一种是从最小关键字起顺序查找，另一种是从根节点开始，进行随机查找。**

  在B+树上进行随机查找、插入和删除的过程基本上与B-树类似。只是在查找时，若非终端结点上的关键码等于给定值，并不终止，而是继续向下直到叶子结点。**因此，对于B+树，不管查找成功与否，每次查找都是走了一条从根到叶子结点的路径。**

 

(3)为什么说B+-tree比B树更适合实际应用中操作系统的文件索引和数据库索引？

B+tree的磁盘读写代价更低：B+tree的内部结点并没有指向关键字具体信息的指针(红色部分)，因此其内部结点相对B 树更小。如果把所有同一内部结点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多。一次性读入内存中的需要查找的关键字也就越多，相对来说IO读写次数也就降低了；

 

B+tree的查询效率更加稳定：由于内部结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引，所以，任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当；

 

数据库索引采用B+树而不是B树的主要原因：B+树只要遍历叶子节点就可以实现整棵树的遍历，而且在数据库中基于范围的查询是非常频繁的，而B树只能中序遍历所有节点，效率太低。

 

(4)文件索引和数据库索引为什么使用B+树?

文件与数据库都是需要较大的存储，也就是说，它们都不可能全部存储在内存中，故需要存储到磁盘上。而所谓索引，则为了数据的快速定位与查找，那么索引的结构组织要尽量减少查找过程中磁盘I/O的存取次数，因此B+树相比B树更为合适。数据库系统巧妙利用了局部性原理与磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入，而红黑树这种结构，高度明显要深的多，并且由于逻辑上很近的节点(父子)物理上可能很远，无法利用局部性。最重要的是，B+树还有一个最大的好处：方便扫库。B树必须用中序遍历的方法按序扫库，而B+树直接从叶子结点挨个扫一遍就完了，B+树支持range-query非常方便，而B树不支持，这是数据库选用B+树的最主要原因。

 

### 5.2 索引的优点

1)大大加快数据的检索速度，这也是创建索引的最主要的原因；

2)加速表和表之间的连接；

3)在使用分组和排序子句进行数据检索时，同样可以显著减少查询中分组和排序的时间；

4)通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性；

### 5.3 什么情况下设置了索引但无法使用？

1)以“%(表示任意0个或多个字符)”开头的LIKE语句，模糊匹配；

2)OR语句前后没有同时使用索引；

3)数据类型出现隐式转化（如varchar不加单引号的话可能会自动转换为int型）；

4)对于多列索引，必须满足 最左匹配原则 (eg：多列索引col1、col2和col3，则 索引生效的情形包括 col1或col1，col2或col1，col2，col3)。

 

### 5.4 什么样的字段适合创建索引？

1)经常作查询选择的字段

2)经常作表连接的字段

3)经常出现在order by, group by, distinct 后面的字段

 

### 5.5 创建索引时需要注意什么？

1)非空字段：应该指定列为NOT NULL，除非你想存储NULL。在mysql中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。你应该用0、一个特殊的值或者一个空串代替空值；

 

2)取值离散大的字段：（变量各个取值之间的差异程度）的列放到联合索引的前面，可以通过count()函数查看字段的差异值，返回值越大说明字段的唯一值越多字段的离散程度高；

 

3)索引字段越小越好：数据库的数据存储以页为单位一页存储的数据越多一次IO操作获取的数据越大效率越高。

 

### 5.6 索引的缺点

1)时间方面：创建索引和维护索引要耗费时间，具体地，当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，这样就降低了数据的维护速度；

 

2)空间方面：索引需要占物理空间。

 

### 5.7 索引的分类

1)普通索引和唯一性索引：索引列的值的唯一性

 

2)单个索引和复合索引：索引列所包含的列数

 

3)聚簇索引与非聚簇索引：聚簇索引按照数据的物理存储进行划分的。对于一堆记录来说，使用聚集索引就是对这堆记录进行堆划分，即主要描述的是物理上的存储。正是因为这种划分方法，导致聚簇索引必须是唯一的。聚集索引可以帮助把很大的范围，迅速减小范围。但是查找该记录，就要从这个小范围中Scan了；而非聚集索引是把一个很大的范围，转换成一个小的地图，然后你需要在这个小地图中找你要寻找的信息的位置，最后通过这个位置，再去找你所需要的记录。

 

### 5.8 主键、自增主键、主键索引与唯一索引概念区别

主键：指字段 唯一、不为空值 的列；

 

主键索引：指的就是主键，主键是索引的一种，是唯一索引的特殊类型。创建主键的时候，数据库默认会为主键创建一个唯一索引；

 

自增主键：字段类型为数字、自增、并且是主键；

 

唯一索引：索引列的值必须唯一，但允许有空值。主键是唯一索引，这样说没错；但反过来说，唯一索引也是主键就错误了，因为唯一索引允许空值，主键不允许有空值，所以不能说唯一索引也是主键。

 

### 5.9 主键就是聚集索引吗？主键和索引有什么区别？

  主键是一种特殊的唯一性索引，其可以是聚集索引，也可以是非聚集索引。在SQLServer中，主键的创建必须依赖于索引，默认创建的是聚集索引，但也可以显式指定为非聚集索引。InnoDB作为MySQL存储引擎时，默认按照主键进行聚集，如果没有定义主键，InnoDB会试着使用唯一的非空索引来代替。如果没有这种索引，InnoDB就会定义隐藏的主键然后在上面进行聚集。所以，对于聚集索引来说，你创建主键的时候，自动就创建了主键的聚集索引。

 

## 6、Else

### 6.1 什么是存储过程？有哪些优缺点？

  存储过程是事先经过编译并存储在数据库中的一段SQL语句的集合。进一步地说，存储过程是由一些T-SQL语句组成的代码块，这些T-SQL语句代码像一个方法一样实现一些功能（对单表或多表的增删改查），然后再给这个代码块取一个名字，在用到这个功能的时候调用他就行了。存储过程具有以下特点：

  1）存储过程只在创建时进行编译，以后每次执行存储过程都不需再重新编译，而一般 SQL 语句每执行一次就编译一次，所以使用存储过程可提高数据库执行效率；

  2）当SQL语句有变动时，可以只修改数据库中的存储过程而不必修改代码；

  3）减少网络传输，在客户端调用一个存储过程当然比执行一串SQL传输的数据量要小；

  4）通过存储过程能够使没有权限的用户在控制之下间接地存取数据库，从而确保数据的安全。

 

 

### 6.2 简单说一说drop、delete与truncate的区别

SQL中的drop、delete、truncate都表示删除，但是三者有一些差别：

Delete用来删除表的全部或者一部分数据行，执行delete之后，用户需要提交(commmit)或者回滚(rollback)来执行删除或者撤销删除， delete命令会触发这个表上所有的delete触发器；

Truncate删除表中的所有数据，这个操作不能回滚，也不会触发这个表上的触发器，TRUNCATE比delete更快，占用的空间更小；

Drop命令从数据库中删除表，所有的数据行，索引和权限也会被删除，所有的DML触发器也不会被触发，这个命令也不能回滚。

因此，在不再需要一张表的时候，用drop；在想删除部分数据行时候，用delete；在保留表而删除所有数据的时候用truncate。

 

### 6.3 什么叫视图？游标是什么？

  视图是一种虚拟的表，通常是有一个表或者多个表的行或列的子集，具有和物理表相同的功能，可以对视图进行增，删，改，查等操作。特别地，对视图的修改不影响基本表。相比多表查询，它使得我们获取数据更容易。

  游标是对查询出来的结果集作为一个单元来有效的处理。游标可以定在该单元中的特定行，从结果集的当前行检索一行或多行。可以对结果集当前行做修改。一般不使用游标，但是需要逐条处理数据的时候，游标显得十分重要。

  在操作mysql的时候，我们知道MySQL检索操作返回一组称为结果集的行。这组返回的行都是与 SQL语句相匹配的行（零行或多行）。使用简单的 SELECT语句，例如，没有办法得到第一行、下一行或前 10行，也不存在每次一行地处理所有行的简单方法（相对于成批地处理它们）。有时，需要在检索出来的行中前进或后退一行或多行。这就是使用游标的原因。游标（cursor）是一个存储在MySQL服务器上的数据库查询，它不是一条 SELECT语句，而是被该语句检索出来的结果集。在存储了游标之后，应用程序可以根据需要滚动或浏览其中的数据。游标主要用于交互式应用，其中用户需要滚动屏幕上的数据，并对数据进行浏览或做出更改。

 

## 7、Memcached

### 7.1 简介

Memcached是一个自由开源的，高性能，分布式内存对象缓存系统。

Memcached是一种基于内存的key-value存储，用来存储小块的任意数据（字符串、对象）。这些数据可以是数据库调用、API调用或者是页面渲染的结果。

Memcached简洁而强大。它的简洁设计便于快速开发，减轻开发难度，解决了大数据量缓存的很多问题。它的API兼容大部分流行的开发语言。

一般的使用目的是，通过缓存数据库查询结果，减少数据库访问次数，以提高动态Web应用的速度、提高可扩展性。

 

### 7.2 与Redis的区别

 

 

 

 

  

## 8、MySQL锁

 

### 8.1 表级锁

表级锁是MySQL中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分MySQL引擎支持。最常使用的MYISAM与INNODB都支持表级锁定。表级锁定分为表**共享读锁（共享锁）与表独占写锁（排他锁）**。特点是开销小，加锁快；不会出现死锁；锁定粒度大，发出锁冲突的概率最高，并发度最低。

 

### 8.2 行级锁

行级锁是Mysql中锁定粒度最细的一种锁，表示只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突。其加锁粒度最小，但加锁的开销也最大。行级锁分为共享锁和排他锁。特点是开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。

 

### 8.3 页级锁

表级锁是MySQL中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录。BDB支持页级锁。特点是开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。

 

 

 

### 8.4 共享锁

共享锁又称为读锁，简称S锁，共享锁就是多个事务对于同一数据可以共享一把锁，都能访问到数据，但是只能读不能修改。

比如事务T对数据对象A加上S锁，则事务T只能读A；其他事务只能再对A加S锁，而不能加X锁，直到T释放A上的S锁。这就保证了其他事务可以读A，但在T释放A上的S锁之前不能对A做任何修改。

 

### 8.5 排他锁

排他锁又称为写锁，简称X锁，排他锁就是不能与其他所并存，如一个事务获取了一个数据行的排他锁，其他事务就不能再获取该行的其他锁，包括共享锁和排他锁，但是获取排他锁的事务是可以对数据就行读取和修改。

比如事物T对数据对象A加上X锁，则只允许T读取和修改A，其它任何事务都不能再对A加任何类型的锁，直到T释放A上的锁。它防止任何其它事务获取资源上的锁，直到在事务的末尾将资源上的原始锁释放为止。

 

 

### 8.6 意向锁

意向锁是一种**表锁**，锁定的粒度是整张表，分为**意向共享锁(IS)和意向排它锁(IX)**两类。意向共享锁表示一个事务有意对数据上共享锁或者排它锁。“有意”这两个字表达的意思比较微妙，说的明白点就是指事务想干这个事但还没真去干。

 

当一个事务在需要获取资源的锁定时，如果该资源已经被排他锁占用，则数据库会自动给该事务申请一个该表的意向锁。如果自己需要一个共享锁定，就申请一个意向共享锁。如果需要的是某行（或者某些行）的排他锁定，则申请一个意向排他锁。

 

# 网络

## Tcp与UDP

### 1、TCP的拥塞控制与滑动窗口（流量控制）

http://blog.chinaunix.net/uid-21768364-id-4823449.html

https://blog.csdn.net/qzcsu/article/details/72861891

拥塞控制

 

 

 

### 2、TCP十一种状态

 

 

 

 

 

### 3、三次握手

 

 

 

### 4、四次挥手

 

 

### 5、为什么TCP链接需要三次握手，两次不可以么，为什么？

为了防止已失效的链接请求报文突然又传送到了服务端，因而产生错误。

客户端发出的连接请求报文并未丢失，而是在某个网络节点长时间滞留了，以致延误到链接释放以后的某个时间才到达Server。这是，Server误以为这是Client发出的一个新的链接请求，于是就向客户端发送确认数据包，同意建立链接。若不采用“三次握手”，那么只要Server发出确认数据包，新的链接就建立了。由于client此时并未发出建立链接的请求，所以其不会理睬Server的确认，也不与Server通信；而这时Server一直在等待Client的请求，这样Server就白白浪费了一定的资源。若采用“三次握手”，在这种情况下，由于Server端没有收到来自客户端的确认，则就会知道Client并没有要求建立请求，就不会建立链接。

### 6、TCP协议如何来保证传输的可靠性

  TCP提供一种面向连接的、可靠的字节流服务。其中，面向连接意味着两个使用TCP的应用（通常是一个客户和一个服务器）在彼此交换数据之前必须先建立一个TCP连接。在一个TCP连接中，仅有两方进行彼此通信；而字节流服务意味着两个应用程序通过TCP链接交换8bit字节构成的字节流，TCP不在字节流中插入记录标识符。

  对于可靠性，TCP通过以下方式进行保证：

  数据包校验：目的是检测数据在传输过程中的任何变化，若校验出包有错，则丢弃报文段并且不给出响应，这时TCP发送数据端超时后会重发数据；

  对失序数据包重排序：既然TCP报文段作为IP数据报来传输，而IP数据报的到达可能会失序，因此TCP报文段的到达也可能会失序。TCP将对失序数据进行重新排序，然后才交给应用层；

  丢弃重复数据：对于重复数据，能够丢弃重复数据；

  应答机制：当TCP收到发自TCP连接另一端的数据，它将发送一个确认。这个确认不是立即发送，通常将推迟几分之一秒；

  超时重发：当TCP发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段；

  流量控制：TCP连接的每一方都有固定大小的缓冲空间。TCP的接收端只允许另一端发送接收端缓冲区所能接纳的数据，这可以防止较快主机致使较慢主机的缓冲区溢出，这就是流量控制。TCP使用的流量控制协议是可变大小的滑动窗口协议。

### 7、客户端不断进行请求链接会怎样？DDos(Distributed Denial of Service)攻击？

 

### 8、TCP与UDP的区别

1、TCP面向连接（如打电话要先拨号建立连接）;UDP是无连接的，即发送数据之前不需要建立连接

2、TCP提供可靠的服务。也就是说，通过TCP连接传送的数据，无差错，不丢失，不重复，且按序到达;UDP尽最大努力交付，即不保证可靠交付

3、TCP面向字节流，实际上是TCP把数据看成一连串无结构的字节流;UDP是面向报文的

UDP没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如IP电话，实时视频会议等）

4、每一条TCP连接只能是点到点的;UDP支持一对一，一对多，多对一和多对多的交互通信

5、TCP首部开销20字节;UDP的首部开销小，只有8个字节

6、TCP的逻辑通信信道是全双工的可靠信道，UDP则是不可靠信道

 

## HTTP与https

### 1、Http与Https的基本概念和他们的区别

Http协议运行在TCP之上，明文传输，客户端与服务器端都无法验证对方的身份；Https是身披SSL(Secure Socket Layer)外壳的Http，运行于SSL上，SSL运行于TCP之上，是添加了加密和认证机制的HTTP。二者之间存在如下不同：

1）端口不同：Http与Http使用不同的连接方式，用的端口也不一样，前者是80，后者是443；

2）资源消耗：和HTTP通信相比，Https通信会由于加减密处理消耗更多的CPU和内存资源；

3）开销：Https通信需要证书，而证书一般需要向认证机构购买；

Https的加密机制是一种共享密钥加密和公开密钥加密并用的混合加密机制。

 

http的中文叫做超文本传输协议,它负责完成客户端到服务端的一系列操作,是专门用来传输注入HTML的超媒体文档等web内容的协议,它是基于传输层的TCP协议的应用层协议

 

https:https是基于安全套接字的http协议,也可以理解为是http+ssl/tls(数字证书)的组合

 

http和https的区别:

HTTP 的 URL 以 http:// 开头，而 HTTPS 的 URL 以 https:// 开头

HTTP 是不安全的，而 HTTPS 是安全的

HTTP 标准端口是 80 ，而 HTTPS 的标准端口是 443

在 OSI 网络模型中，HTTPS的加密是在传输层完成的,因为SSL是位于传输层的,TLS的前身是SSL,所以同理

HTTP无需认证证书,而https需要认证证书

 

### 2、HTTPS工作原理

首先服务端给客户端传输证书,这个证书就是公钥,只是包含了很多的信息,比如说证书的办法机构,证书的过期时间

客户端进行证书的解析,比如说验证办法机构,过期时间,如果发现没有任何问题,就生成一个随机值(私钥),然后用证书对这个私钥进行加密,并发送给服务端

服务端使用私钥将这个信息进行解密,得到客户端的私钥,然后客户端和服务端就可以通过这个私钥进行通信了

服务端将消息进行对称加密(简单来说就是讲消息和私钥进行混合,除非知道私钥否则服务进行解密),私钥正好只有客户端和服务端知道,所以信息就比较安全了

服务端将进行对称加密后的消息进行传送

客户端使用私钥进行信息的解密

 

### 3、常用的HTTP方法有哪些

GET 从服务器获得资源

POST 客户端向服务器提交资源

PUT 修改服务器相关资源(已经很少用)

DELETE 删除服务器相关资源(已经很少用)

 

### 4、GET方法与POST方法的区别,什么时候应该使用GET什么时候应该使用POST

GET：一般用于**信息获取**，使用URL传递参数，对所发送信息的**数量也有限制**，一般在2000个字符

POST：一般用于**修改服务器上的资源**，对所发送的信息数**量没有限制**

GET方式需要使用Request.QueryString来取得变量的值，而POST方式通过Request.Form来获取变量的值，也就是说Get是**通过地址栏来传值**，而Post是**通过提交表单来传值**。

小结：

对于信息的获取一般使用get,在以下情况下最好使用post请求:

向服务器发送大量数据（因为post没有发送数据的数量限制） 

无法使用缓存文件（会更新服务器上的文件）

发送包含未知字符的用户输入时(亲身经历过GET的坑,泪目) 

 

 

Get Post（补充）

GET：一般用于信息获取，使用URL传递参数，对所发送信息的数量也有限制，一般在2000个字符

POST：一般用于修改服务器上的资源，对所发送的信息没有限制。

GET方式需要使用Request.QueryString来取得变量的值，而POST方式通过Request.Form来获取变量的值，也就是说Get是通过地址栏来传值，而Post是通过提交表单来传值。

然而，在以下情况中，请使用 POST 请求：

无法使用缓存文件（更新服务器上的文件或数据库）

向服务器发送大量数据（POST 没有数据量限制）

发送包含未知字符的用户输入时，POST 比 GET 更稳定也更可靠

区别一：

get重点在从服务器上获取资源，post重点在向服务器发送数据；

区别二：

get传输数据是通过URL请求，以field（字段）= value的形式，置于URL后，并用"?"连接，多个请求数据间用"&"连接，如http://127.0.0.1/Test/login.action?name=admin&password=admin，这个过程用户是可见的；

post传输数据通过Http的post机制，将字段与对应值封存在请求实体中发送给服务器，这个过程对用户是不可见的；

区别三：

Get传输的数据量小，因为受URL长度限制，但效率较高；

Post可以传输大量数据，所以上传文件时只能用Post方式；

区别四：

get是不安全的，因为URL是可见的，可能会泄露私密信息，如密码等；

post较get安全性较高；

区别五：

get方式只能支持ASCII字符，向服务器传的中文字符可能会乱码。

post支持标准字符集，可以正确传递中文字符。

### 5、HTTP请求报文与响应报文格式

主要的区别就是请求报文有url和请求方法,响应报文没有这两个,但是有状态码和状态码描述,还要注意一些常见的请求头和响应头代表的意思,比如说Connection:Keep-Alive

 

HTTP请求报文

一个HTTP请求报文由请求行（request line）、请求头部（header）、空行和请求数据4个部分组成

1.请求头

请求行由请求方法字段、URL字段和HTTP协议版本字段3个字段组成，它们用空格分隔。例如，GET /index.html HTTP/1.1。

2.请求头部

请求头部由关键字/值对组成，每行一对，关键字和值用英文冒号“:”分隔。请求头部通知服务器有关于客户端请求的信息，典型的请求头有：

User-Agent：产生请求的浏览器类型。

Accept：客户端可识别的内容类型列表。

Host：请求的主机名，允许多个域名同处一个IP地址，即虚拟主机。

3.空行

最后一个请求头之后是一个空行，发送回车符和换行符，通知服务器以下不再有请求头。

4.请求数据

请求数据不在GET方法中使用，而是在POST方法中使用。POST方法适用于需要客户填写表单的场合。与请求数据相关的最常使用的请求头是Content-Type和Content-Length。

HTTP响应报文

HTTP响应也由三个部分组成，分别是：状态行、消息报头、响应正文。

 

 

### 6、常见的HTTP的状态码

1xx：指示信息--表示请求已接收，继续处理

2xx：成功--表示请求已被成功接收、理解、接受

3xx：重定向--要完成请求必须进行更进一步的操作

4xx：客户端错误--请求有语法错误或请求无法实现

5xx：服务器端错误--服务器未能实现合法的请求

100 Continue 继续，一般在发送post请求时，已发送了http header之后服务端将返回此信息，表示确认，之后发送具体参数信息

200 OK  正常返回信息

201 Created 请求成功并且服务器创建了新的资源

202 Accepted 服务器已接受请求，但尚未处理

301 Moved Permanently 请求的网页已永久移动到新位置。

302 Found 临时性重定向。

303 See Other 临时性重定向，且总是使用 GET 请求新的 URI。

304 Not Modified 自从上次请求后，请求的网页未修改过。

400 Bad Request 服务器无法理解请求的格式，客户端不应当尝试再次使用相同的内容发起请求。

401 Unauthorized 请求未授权。

403 Forbidden 禁止访问。

404 Not Found 找不到如何与 URI 相匹配的资源。

500 Internal Server Error 最常见的服务器端错误。

503 Service Unavailable 服务器端暂时无法处理请求（可能是过载或维护）。

 

304实现原理 

服务器首先产生ETag，服务器可在稍后使用它来判断页面是否已经被修改。本质上，客户端通过将该记号传回服务器要求服务器验证其（客户端）缓存。

304是HTTP状态码，服务器用来标识这个文件没修改，不返回内容，浏览器在接收到个状态码后，会使用浏览器已缓存的文件

客户端请求一个页面（A）。 服务器返回页面A，并在给A加上一个ETag。 客户端展现该页面，并将页面连同ETag一起缓存。 客户再次请求页面A，并将上次请求时服务器返回的ETag一起传递给服务器。 服务器检查该ETag，并判断出该页面自上次客户端请求之后还未被修改，直接返回响应304（未修改——Not Modified）和一个空的响应体。

### 7、HTTP1.0,1.1,2.0之间的区别和特性

http1.0:

是一种无状态、无连接的应用层协议,每个请求都会新创建一个tcp连接,完成后关闭服务端不跟踪也不记录过去的请求(无状态),但正因频繁创建连接,由于tcp的慢启动(为了不给网络造成拥堵,在首次进行tcp请求的时候,会限制服务端和客户端之间交互数据量的上限,大概为14kb,之后以指数级增长),服务端接受请求,处理完,发送完响应之后就会将tcp连接关闭,这造成了很大的资源浪费,而且http1.0在一个请求接收到响应之后才会接着发送下一个,这也造成了head of line blocking(队头阻塞),现在的浏览器为了解决这个问题,采用了一个页面可以建立多个tcp连接的方式来进行

http1.1:

继承了http1.0的特点,同时改善了http的一些问题,首先是长连接,http1.1新增加了connecion字段,里面可以设置keey-Alive(保持连接)或者close(关闭长连接),避免了每次请求都会新建连接,提高了网络的利用率

http1.1还增加了Host字段,用来明确表示浏览器要服务器上的哪一个WEB站点,这才实现了在一台WEB服务器上可以在同一个IP地址和端口号上使用不同的主机名来创建多个虚拟WEB站点,同时还支持了断点续传

http1.1的管道:可以发送很多请求到服务端,但是服务端必须要按顺序返回响应,由此可以看出http1.1的管道只是把客户端的请求序列变成了服务端的响应序列,还是有问题,很多浏览器并不是很支持

http1.1还增加了缓存,断点续传

http2.0 : 

采用了二进制分帧(frame),在应用层和传输层之间增加了一个二进制分帧层,也就是把http1.x的header和body使用帧(frame)进行了封装

这里明确几个概念:流(stream) : 已经建立上连接的双向字节流(也就是一个请求和其对应的响应) 消息:与逻辑消息对应的完整的一系列数据帧 帧(frame):http2.0进行通信的最小单位,每个帧都会包含一个头部,这个头部会包含当前帧所处的流

多路复用:所有的HTTP2.0通信都在一个TCP连接上完成，这个连接可以承载任意数量的双向数据流,每个数据流都以消息的方式进行发送,这个发送可以使乱序的,然后在通过每个帧头部的流标识符进行组装,同时每个数据流都可以设置优先级,可见http2.0真正实现了并行发送数据,这个是给予二进制分帧来实现的,接下来上一张图片,展示一下一个在一个流中分帧传输的实例

头部压缩:就是和服务端约定头部的数据的编码,来将头部进行压缩后发送,这样就可以增加请求头的容量

小结

 

这里讲的稍微有一点多,这里给一个总结

 

http1.0:无连接,无状态,一次请求一个tcp连接

http1.1:持久连接,请求管道化(有一些缺陷) ,增加了host字段,缓存,断点续传

http2.0 : 二进制分帧(多路复用的实现基础), 多路复用,头部压缩

常见HTTP首部字段

这里我还是给大家推荐两篇博客,写的很详细就不在这里献丑了

 

 

### 8、HTTP的缺点与HTTPS有哪些改进

http的传输是不安全的,https是http+ssl证书进行加密的,所以比http安全(这里的详细过程上面有写)

HTTP优化

资源内敛 : 资源内联 : 既然每个资源的首次访问都会存在握手等rtt损耗,那么越少数量的资源请求就越好,例如咋一个html中src访问css,不如直接将其这个css集成到html中

图片懒加载 ; 用到的时候在加载,这个已经很普遍了,就不细说了

服务器渲染 : 让服务端先将页面渲染好,在发送给客户端,也可以减少rtt的次数

### 10、https建立连接过程

HTTP通信机制是在一次完整的HTTP通信过程中，Web浏览器与Web服务器之间将完成下列7个步骤：

\* 建立TCP连接

在HTTP工作开始之前，Web浏览器首先要通过网络与Web服务器建立连接，该连接是通过TCP来完成的，该协议与IP协议共同构建 Internet，即著名的TCP/IP协议族，因此Internet又被称作是TCP/IP网络。HTTP是比TCP更高层次的应用层协议，根据规则， 只有低层协议建立之后才能，才能进行更层协议的连接，因此，首先要建立TCP连接，一般TCP连接的端口号是80。

\* Web浏览器向Web服务器发送请求行

一旦建立了TCP连接，Web浏览器就会向Web服务器发送请求命令。例如：GET /sample/hello.jsp HTTP/1.1。

\* Web浏览器发送请求头

  \* 浏览器发送其请求命令之后，还要以头信息的形式向Web服务器发送一些别的信息，之后浏览器发送了一空白行来通知服务器，它已经结束了该头信息的发送。

\* Web服务器应答

  \* 客户机向服务器发出请求后，服务器会客户机回送应答， HTTP/1.1 200 OK ，应答的第一部分是协议的版本号和应答状态码。

\* Web服务器发送应答头

  \* 正如客户端会随同请求发送关于自身的信息一样，服务器也会随同应答向用户发送关于它自己的数据及被请求的文档。

\* Web服务器向浏览器发送数据

  \* Web服务器向浏览器发送头信息后，它会发送一个空白行来表示头信息的发送到此为结束，接着，它就以Content-Type应答头信息所描述的格式发送用户所请求的实际数据。

\* Web服务器关闭TCP连接

  \* 一般情况下，一旦Web服务器向浏览器发送了请求数据，它就要关闭TCP连接，然后如果浏览器或者服务器在其头信息加入了这行

代码：Connection:keep-alive

TCP连接在发送后将仍然保持打开状态，于是，浏览器可以继续通过相同的连接发送请求。保持连接节省了为每个请求建立新连接所需的时间，还节约了网络带宽。

建立TCP连接->发送请求行->发送请求头->（到达服务器）发送状态行->发送响应头->发送响应数据->断TCP连接

 

 

### 11、如何知道http传输已经结束

Content-Length

Content-Length表示实体内容的长度。浏览器通过这个字段来判断当前请求的数据是否已经全部接收。

### 12、为什么http要用长连接，一般用在什么场景

长连接

连接->传输数据->保持连接 -> 传输数据-> ...........->直到一方关闭连接，多是客户端关闭连接。

长连接指建立SOCKET连接后不管是否使用都保持连接，但安全性较差。

从 HTTP/1.1起，默认使用长连接，用以保持连接特性。使用长连接的HTTP协议，会在响应头有加入这行代码：

Connection:keep-alive 服务器和客户端都要设置

长连接多用于操作频繁，点对点的通讯，而且连接数不能太多情况

### 13、cookie、sessionStorage、localStorage的区别，大小限制

cookie还需要指定作用域，不可以跨域调用。cookie的作用是与服务器进行交互，作为HTTP规范的一部分而存在

sessionStorage用于本地存储一个会话（session）中的数据，这些数据只有在同一个会话中的页面才能访问并且当会话结束后数据也随之销毁。因此sessionStorage不是一种持久化的本地存储，仅仅是会话级别的存储。

localStorage用于持久化的本地存储，除非主动删除数据，否则数据是永远不会过期的。

### 14、session和cookie的区别

Cookie和Session都是客户端与服务器之间保持状态的解决方案，具体来说，cookie机制采用的是在**客户端保持状态的方案**，而session机制采用的是在**服务器端保持状态的方案**。

 

1、cookie数据存放在客户的浏览器上，session数据放在服务器上。

2、cookie不是很安全，别人可以分析存放在本地的COOKIE并进行COOKIE欺骗考虑到安全应当使用session。

3、session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能考虑到减轻服务器性能方面，应当使用COOKIE。

4、单个cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个cookie。

5、所以个人建议：

将登陆信息等重要信息存放为SESSION

其他信息如果需要保留，可以放在COOKIE中

 

(1)Cookie及其相关API

  Cookie实际上是一小段的文本信息。客户端请求服务器，如果服务器需要记录该用户状态，就使用response向客户端浏览器颁发一个Cookie，而客户端浏览器会把Cookie保存起来。当浏览器再请求该网站时，浏览器把请求的网址连同该Cookie一同提交给服务器，服务器检查该Cookie，以此来辨认用户状态。服务器还可以根据需要修改Cookie的内容。

(2)Session及其相关API

  同样地，会话状态也可以保存在服务器端。客户端请求服务器，如果服务器记录该用户状态，就获取Session来保存状态，这时，如果服务器已经为此客户端创建过session，服务器就按照sessionid把这个session检索出来使用；如果客户端请求不包含sessionid，则为此客户端创建一个session并且生成一个与此session相关联的sessionid，并将这个sessionid在本次响应中返回给客户端保存。保存这个sessionid的方式可以采用 cookie机制 ，这样在交互过程中浏览器可以自动的按照规则把这个标识发挥给服务器；若浏览器禁用Cookie的话，可以通过 URL重写机制 将sessionid传回服务器。

(3)Session 与 Cookie 的对比

  实现机制：Session的实现常常依赖于Cookie机制，通过Cookie机制回传SessionID；

  大小限制：Cookie有大小限制并且浏览器对每个站点也有cookie的个数限制，Session没有大小限制，理论上只与服务器的内存大小有关；

  安全性：Cookie存在安全隐患，通过拦截或本地文件找得到cookie后可以进行攻击，而Session由于保存在服务器端，相对更加安全；

  服务器资源消耗：Session是保存在服务器端上会存在一段时间才会消失，如果session过多会增加服务器的压力。

(4)Application

  Application（Java Web中的ServletContext）：与一个Web应用程序相对应，为应用程序提供了一个全局的状态，所有客户都可以使用该状态。

### 15、分布式session存储

1.基于数据库的Session共享

2.基于NFS共享文件系统（网络文件系统）

3.基于memcached 的session，如何保证 memcached 本身的高可用性？

4.基于resin/tomcat web容器本身的session复制机制

5.基于TT/Redis 或 jbosscache 进行 session 共享。

6.基于cookie 进行session共享

 

### 16、webWorker和webSocket

1.通过 worker = new Worker( url ) 加载一个JS文件来创建一个worker，同时返回一个worker实例。

2.通过worker.postMessage( data ) 方法来向worker发送数据。

3.绑定worker.onmessage方法来接收worker发送过来的数据。

4.可以使用 worker.terminate() 来终止一个worker的执行。

WebSocket是Web应用程序的传输协议，它提供了双向的，按序到达的数据流。他是一个HTML5协议，WebSocket的连接是持久的，他通过在客户端和服务器之间保持双工连接，服务器的更新可以被及时推送给客户端，而不需要客户端以一定时间间隔去轮询。

### 17、token

客户端使用用户名和密码登录

服务器验证成功，签发一个token发送给客户端

客户端收到token存储在诸如cookie中

每次请求带上token

客户端每次验证token，如果成功返回数据

### 18、token和session的区别

token本身就代表一个登录态，而sessionid只是一个标识符需要校验是否存在该sessionid对应

的对话，对于token而言只要按照规则检验这个token是否合法就可以

cookie-session的方案限制了客户端的类型，而token机制对于app也可以适用

### 19、http请求方式，最好了解常用的四个以外其他的那几个

GET：只用于获取数据

HEAD：与GET类似，但是没有响应体

POST：将实体提交到指定的资源，通常导致状态或服务器上的副作用的改变

PUT：更新指定内容

DELETE：删除资源

CONNECT：建⽴立一个到服务器的隧道

OPTIONS：用于描述目标资源的通信选项，返回支持的方法

TRACE：沿着到目标资源的路径做一个消息环回测试

PATCH：用于对资源应用部分修改

 

GET： 请求指定的页面信息，并返回实体主体。

HEAD： 只请求页面的首部。

POST： 请求服务器接受所指定的文档作为对所标识的URI的新的从属实体。

PUT： 从客户端向服务器传送的数据取代指定的文档的内容。

DELETE： 请求服务器删除指定的页面。

OPTIONS： 允许客户端查看服务器的性能。

TRACE： 请求服务器在响应中的实体主体部分返回所得到的内容。

### 20、http缓存

 

### 21、Cache-control策略（重点关注）：

Cache-Control与Expires的作用一致，都是指明当前资源的有效期，控制浏览器是否直接从浏览器缓存取数据还是重新发请求到服务器取数据。只不过Cache-Control的选择更多，设置更细致，如果同时设置的话，其优先级高于Expires。

Cache-Control 是最重要的规则。常见的取值有private、public、no-cache、max-age，no-store，默认为private。 private: 客户端可以缓存 public: 客户端和代理服务器都可缓存（前端的同学，可以认为public和private是一样的） max-age=xxx: 缓存的内容将在 xxx 秒后失效 

no-cache: 需要使用对比缓存来验证缓存数据（后面介绍） 

no-store: 所有内容都不会缓存，强制缓存，对比缓存都不会触发（对于前端开发来说，缓存越多越好，so...基本上和它说886） 

Last-Modified：

服务器在响应请求时，告诉浏览器资源的最后修改时间。

If-Modified-Since：

再次请求服务器时，通过此字段通知服务器上次请求时，服务器返回的资源最后修改时间。

服务器收到请求后发现有头If-Modified-Since 则与被请求资源的最后修改时间进行比对。

若资源的最后修改时间大于If-Modified-Since，说明资源有被改动过，则响应整片资源内容，返回状态码200；

若资源的最后修改时间小于或等于If-Modified-Since，说明资源无新修改，则响应HTTP 304，告知浏览器继续使用所保存的cache。

Etag / If-None-Match（优先级高于Last-Modified / If-Modified-Since）

Etag：

服务器响应请求时，告诉浏览器当前资源在服务器的唯一标识（生成规则由服务器决定）。

If-None-Match：

再次请求服务器时，通过此字段通知服务器客户段缓存数据的唯一标识。

服务器收到请求后发现有头If-None-Match 则与被请求资源的唯一标识进行比对，

不同，说明资源又被改动过，则响应整片资源内容，返回状态码200；

相同，说明资源无新修改，则响应HTTP 304，告知浏览器继续使用所保存的cache。

总结：

1.对于强制缓存，服务器通知浏览器一个缓存时间，在缓存时间内，下次请求，直接用缓存，不在时间内，执行比较缓存策略。

2.对于比较缓存，将缓存信息中的Etag和Last-Modified通过请求发送给服务器，由服务器校验，返回304状态码时，浏览器直接使用缓存。

 

### 22、XSS 攻击

  XSS是一种经常出现在web应用中的计算机安全漏洞，与SQL注入一起成为web中最主流的攻击方式。XSS是指恶意攻击者利用网站没有对用户提交数据进行转义处理或者过滤不足的缺点，进而添加一些脚本代码嵌入到web页面中去，使别的用户访问都会执行相应的嵌入代码，从而盗取用户资料、利用用户身份进行某种动作或者对访问者进行病毒侵害的一种攻击方式。

 

1)XSS攻击的危害

 

盗取各类用户帐号，如机器登录帐号、用户网银帐号、各类管理员帐号

控制企业数据，包括读取、篡改、添加、删除企业敏感数据的能力

盗窃企业重要的具有商业价值的资料

非法转账

强制发送电子邮件

网站挂马

控制受害者机器向其它网站发起攻击

2)原因解析

主要原因：过于信任客户端提交的数据！

解决办法：不信任任何客户端提交的数据，只要是客户端提交的数据就应该先进行相应的过滤处理然后方可进行下一步的操作。

进一步分析细节：客户端提交的数据本来就是应用所需要的，但是恶意攻击者利用网站对客户端提交数据的信任，在数据中插入一些符号以及javascript代码，那么这些数据将会成为应用代码中的一部分了，那么攻击者就可以肆无忌惮地展开攻击啦，因此我们绝不可以信任任何客户端提交的数据！！！

3)XSS 攻击分类

(1)反射性XSS攻击 (非持久性XSS攻击)

漏洞产生的原因是攻击者注入的数据反映在响应中。一个典型的非持久性XSS攻击包含一个带XSS攻击向量的链接(即每次攻击需要用户的点击)，例如，正常发送消息：

http://www.test.com/message.php?send=Hello,World！

接收者将会接收信息并显示Hello,World；但是，非正常发送消息：

http://www.test.com/message.php?send=<script>alert(‘foolish!’)</script>！

接收者接收消息显示的时候将会弹出警告窗口！

(2)持久性XSS攻击(留言板场景)

XSS攻击向量(一般指XSS攻击代码)存储在网站数据库，当一个页面被用户打开的时候执行。也就是说，每当用户使用浏览器打开指定页面时，脚本便执行。与非持久性XSS攻击相比，持久性XSS攻击危害性更大。从名字就可以了解到，持久性XSS攻击就是将攻击代码存入数据库中，然后客户端打开时就执行这些攻击代码。

 

例如，留言板表单中的表单域：

<input type=“text” name=“content” value=“这里是用户填写的数据”>

正常操作流程是：用户是提交相应留言信息 —— 将数据存储到数据库 —— 其他用户访问留言板，应用去数据并显示；而非正常操作流程是攻击者在value填写:

<script>alert(‘foolish!’)；</script> <!--或者html其他标签（破坏样式。。。）、一段攻击型代码-->

并将数据提交、存储到数据库中；当其他用户取出数据显示的时候，将会执行这些攻击性代码。

4)修复漏洞方针

漏洞产生的根本原因是太相信用户提交的数据，对用户所提交的数据过滤不足所导致的，因此解决方案也应该从这个方面入手，具体方案包括：

将重要的cookie标记为http only,这样的话Javascript 中的document.cookie语句就不能获取到cookie了（如果在cookie中设置了HttpOnly属性，那么通过js脚本将无法读取到cookie信息，这样能有效的防止XSS攻击）；

表单数据规定值的类型，例如：年龄应为只能为int、name只能为字母数字组合。。。。

对数据进行Html Encode 处理

过滤或移除特殊的Html标签，例如: <script>, <iframe> , < for <, > for>, &quot for

过滤JavaScript 事件的标签，例如 “onclick=”, “onfocus” 等等。

需要注意的是，在有些应用中是允许html标签出现的，甚至是javascript代码出现。因此，我们在过滤数据的时候需要仔细分析哪些数据是有特殊要求（例如输出需要html代码、javascript代码拼接、或者此表单直接允许使用等等），然后区别处理！

# 一面准备

 

## 1、Java常见异常种类

Error、Runtime Exception运行时异常、Exception、throw用户自定义异常

异常类分两大类型：Error类代表了编译和系统的错误，不允许捕获；Exception类代表了标准Java库方法所激发的异常。Exception类还包含运行异常类Runtime_Exception和非运行异常类Non_RuntimeException这两个直接的子类。

**运行异常类**对应于**编译错误**，它是指Java程序在运行时产生的由解释器引发的各种异常。运行异常可能出现在任何地方，且出现频率很高，因此为了避免巨大的系统资源开销，编译器不对异常进行检查。所以Java语言中的运行异常不一定被捕获。出现运行错误往往表示代码有错误，如：算数异常（如被0除）、下标异常（如数组越界）等。

非运行异常时Non_RuntimeException类及其子类的实例，又称为可检测异常。Java编译器利用分析方法或构造方法中可能产生的结果来检测Java程序中是否含有检测异常的处理程序，对于每个可能的可检测异常，方法或构造方法的throws子句必须列出该异常对应的类。在Java的标准包java.lang java.util 和 java.net 中定义的异常都是非运行异常。

 

## 2、session

具体来说cookie机制采用的是在客户端保持状态的方案，而session机制采用的是在服务器端保持状态的方案。

 

**一、****HTTP****协议与状态保持**

其中cookie的作用就是为了解决HTTP协议无状态的缺陷所作出的努力。至于后来出现的session机制则是又一种在客户端与服务器之间保持状态的解决方案。
 **二、理解****cookie****机制**

正统的cookie分发是通过扩展HTTP协议来实现的，服务器通过在HTTP的响应头中加上一行特殊的指示以提示浏览器按照指示生成相应的cookie。然而纯粹的客户端脚本如JavaScript或者VBScript也可以生成cookie。

而cookie的使用是由浏览器按照一定的原则在后台自动发送给服务器的。浏览器检查所有存储的cookie，如果某个cookie所声明的作用范围大于等于将要请求的资源所在的位置，则把该cookie附在请求资源的HTTP请求头上发送给服务器。

cookie的内容主要包括：名字，值，过期时间，路径和域。

其中域可以指定某一个域比如.google.com，相当于总店招牌，比如宝洁公司，也可以指定一个域下的具体某台机器比如[www.google.com](http://www.google.com/)或者froogle.google.com，可以用飘柔来做比。

路径就是跟在域名后面的URL路径，比如/或者/foo等等，可以用某飘柔专柜做比。路径与域合在一起就构成了cookie的作用范围。如果不设置过期时间，则表示这个cookie的生命期为浏览器会话期间，只要关闭浏览器窗口，cookie就消失了。这种生命期为浏览器会话期的cookie被称为会话cookie。会话cookie一般不存储在硬盘上而是保存在内存里，当然这种行为并不是规范规定的。如果设置了过期时间，浏览器就会把cookie保存到硬盘上，关闭后再次打开浏览器，这些cookie仍然有效直到超过设定的过期时间。

存储在硬盘上的cookie可以在不同的浏览器进程间共享，比如两个IE窗口。而对于保存在内存里的cookie，不同的浏览器有不同的处理方式。对于IE，在一个打开的窗口上按Ctrl-N（或者从文件菜单）打开的窗口可以与原窗口共享，而使用其他方式新开的IE进程则不能共享已经打开的窗口的内存cookie；对于Mozilla Firefox0.8，所有的进程和标签页都可以共享同样的cookie。一般来说是用javascript的window.open打开的窗口会与原窗口共享内存cookie。浏览器对于会话cookie的这种只认cookie不认人的处理方式经常给采用session机制的web应用程序开发者造成很大的困扰。

**三、理解session机制**

session机制是一种服务器端的机制，服务器使用一种类似于散列表的结构（也可能就是使用散列表）来保存信息。

当程序需要为某个客户端的请求创建一个session的时候，服务器首先检查这个客户端的请求里是否已包含了一个session标识 - 称为session id，如果已包含一个session id则说明以前已经为此客户端创建过session，服务器就按照session id把这个session检索出来使用（如果检索不到，可能会新建一个），如果客户端请求不包含session id，则为此客户端创建一个session并且生成一个与此session相关联的session id，session id的值应该是一个既不会重复，又不容易被找到规律以仿造的字符串，这个session id将被在本次响应中返回给客户端保存。

保存这个session id的方式可以采用cookie，这样在交互过程中浏览器可以自动的按照规则把这个标识发挥给服务器。一般这个cookie的名字都是类似于SEEESIONID，而。比如weblogic对于web应用程序生成的cookie，JSESSIONID=ByOK3vjFD75aPnrF7C2HmdnV6QZcEbzWoWiBYEnLerjQ99zWpBng!-145788764，它的名字就是JSESSIONID。

由于cookie可以被人为的禁止，必须有其他机制以便在cookie被禁止时仍然能够把session id传递回服务器。经常被使用的一种技术叫做URL重写，就是把session id直接附加在URL路径的后面，附加方式也有两种，一种是作为URL路径的附加信息，表现形式为http://...../xxx;jsessionid=ByOK3vjFD75aPnrF7C2HmdnV6QZcEbzWoWiBYEnLerjQ99zWpBng!-145788764 
 另一种是作为查询字符串附加在URL后面，表现形式为http://...../xxx?jsessionid=ByOK3vjFD75aPnrF7C2HmdnV6QZcEbzWoWiBYEnLerjQ99zWpBng!-145788764 
 这两种方式对于用户来说是没有区别的，只是服务器在解析的时候处理的方式不同，采用第一种方式也有利于把session id的信息和正常程序参数区分开来。
 为了在整个交互过程中始终保持状态，就必须在每个客户端可能请求的路径后面都包含这个session id。 
 另一种技术叫做表单隐藏字段。就是服务器会自动修改表单，添加一个隐藏字段，以便在表单提交时能够把session id传递回服务器。这种技术现在已较少应用，笔者接触过的很古老的iPlanet6(SunONE应用服务器的前身)就使用了这种技术。实际上这种技术可以简单的用对action应用URL重写来代替。

在谈论session机制的时候，常常听到这样一种误解“只要关闭浏览器，session就消失了”。除非程序通知服务器删除一个session，否则服务器会一直保留，程序一般都是在用户做log off的时候发个指令去删除session。然而浏览器从来不会主动在关闭之前通知服务器它将要关闭，因此服务器根本不会有机会知道浏览器已经关闭，之所以会有这种错觉，是大部分session机制都使用会话cookie来保存session id，而关闭浏览器后这个session id就消失了，再次连接服务器时也就无法找到原来的session。如果服务器设置的cookie被保存到硬盘上，或者使用某种手段改写浏览器发出的HTTP请求头，把原来的session id发送给服务器，则再次打开浏览器仍然能够找到原来的session。

恰恰是由于关闭浏览器不会导致session被删除，迫使服务器为seesion设置了一个失效时间，当距离客户端上一次使用session的时间超过这个失效时间时，服务器就可以认为客户端已经停止了活动，才会把session删除以节省存储空间。

**四、理解****javax.servlet.http.HttpSession**

HttpSession是Java平台对session机制的实现规范，因为它仅仅是个接口，具体到每个web应用服务器的提供商，除了对规范支持之外，仍然会有一些规范里没有规定的细微差异。

这里我们以BEA的Weblogic Server8.1作为例子来演示。

首先，Weblogic Server提供了一系列的参数来控制它的HttpSession的实现，包括使用cookie的开关选项，使用URL重写的开关选项，session持久化的设置，session失效时间的设置，以及针对cookie的各种设置，比如设置cookie的名字、路径、域，cookie的生存时间等。

一般情况下，session都是存储在内存里，当服务器进程被停止或者重启的时候，内存里的session也会被清空，如果设置了session的持久化特性，服务器就会把session保存到硬盘上，当服务器进程重新启动或这些信息将能够被再次使用，Weblogic Server支持的持久性方式包括文件、数据库、客户端cookie保存和复制。

复制严格说来不算持久化保存，因为session实际上还是保存在内存里，不过同样的信息被复制到各个cluster内的服务器进程中，这样即使某个服务器进程停止工作也仍然可以从其他进程中取得session。

cookie生存时间的设置则会影响浏览器生成的cookie是否是一个会话cookie。默认是使用会话cookie。有兴趣的可以用它来试验我们在第四节里提到的那个误解。

cookie的路径对于web应用程序来说是一个非常重要的选项，Weblogic Server对这个选项的默认处理方式使得它与其他服务器有明显的区别。
 **五、****HttpSession****常见问题**（在本小节中session的含义为⑤和⑥的混合）

**1****、****session****在何时被创建**

一个常见的误解是以为session在有客户端访问时就被创建，然而事实是直到某server端程序调用HttpServletRequest.getSession(true)这样的语句时才被创建，注意如果JSP没有显示的使用 <%@page session="false"%> 关闭session，则JSP文件在编译成Servlet时将会自动加上这样一条语句HttpSession session = HttpServletRequest.getSession(true);这也是JSP中隐含的session对象的来历。

由于session会消耗内存资源，因此，如果不打算使用session，应该在所有的JSP中关闭它。

**2****、****session****何时被删除**

综合前面的讨论，session在下列情况下被删除a.程序调用HttpSession.invalidate();或b.距离上一次收到客户端发送的session id时间间隔超过了session的超时设置;或c.服务器进程被停止（非持久session）

**3****、如何做到在浏览器关闭时删除****session**

严格的讲，做不到这一点。可以做一点努力的办法是在所有的客户端页面里使用javascript代码window.oncolose来监视浏览器的关闭动作，然后向服务器发送一个请求来删除session。但是对于浏览器崩溃或者强行杀死进程这些非常规手段仍然无能为力。

**4****、有个****HttpSessionListener****是怎么回事**

你可以创建这样的listener去监控session的创建和销毁事件，使得在发生这样的事件时你可以做一些相应的工作。注意是session的创建和销毁动作触发listener，而不是相反。类似的与HttpSession有关的listener还有HttpSessionBindingListener，HttpSessionActivationListener和HttpSessionAttributeListener。

**5****、存放在****session****中的对象必须是可序列化的吗**

不是必需的。要求对象可序列化只是为了session能够在集群中被复制或者能够持久保存或者在必要时server能够暂时把session交换出内存。在Weblogic Server的session中放置一个不可序列化的对象在控制台上会收到一个警告。

**6****、如何才能正确的应付客户端禁止****cookie****的可能性**

对所有的URL使用URL重写，包括超链接，form的action，和重定向的URL。

**7****、开两个浏览器窗口访问应用程序会使用同一个****session****还是不同的****session**

对session来说是只认id不认人，因此不同的浏览器，不同的窗口打开方式以及不同的cookie存储方式都会对这个问题的答案有影响。

**8****、如何防止用户打开两个浏览器窗口操作导致的****session****混乱**

这个问题与防止表单多次提交是类似的，可以通过设置客户端的令牌来解决。就是在服务器每次生成一个不同的id返回给客户端，同时保存在session里，客户端提交表单时必须把这个id也返回服务器，程序首先比较返回的id与保存在session里的值是否一致，如果不一致则说明本次操作已经被提交过了。需要注意的是对于使用javascript window.open打开的窗口，一般不设置这个id，或者使用单独的id，以防主窗口无法操作，建议不要再window.open打开的窗口里做修改操作，这样就可以不用设置。

**9****、为什么在****Weblogic Server****中改变****session****的值后要重新调用一次****session.setValue**

做这个动作主要是为了在集群环境中提示Weblogic Server session中的值发生了改变，需要向其他服务器进程复制新的session值。

**10****、为什么****session****不见了**

排除session正常失效的因素之外，服务器本身的可能性应该是微乎其微的，虽然笔者在iPlanet6SP1加若干补丁的Solaris版本上倒也遇到过；浏览器插件的可能性次之，笔者也遇到过3721插件造成的问题；理论上防火墙或者代理服务器在cookie处理上也有可能会出现问题。

出现这一问题的大部分原因都是程序的错误，最常见的就是在一个应用程序中去访问另外一个应用程序。

 

## 3、cookie的限制

 

## 6、listlink arraylist 区别

### 6.1 List概括

(01)List 是一个接口，它继承于Collection的接口。它代表着有序的队列。
 (02)AbstractList 是一个抽象类，它继承于AbstractCollection。AbstractList实现List接口中除size()、get(int location)之外的函数。
 (03)AbstractSequentialList 是一个抽象类，它继承于AbstractList。AbstractSequentialList 实现了“链表中，根据index索引值操作链表的全部函数”。

(04)ArrayList, LinkedList, Vector, Stack是List的4个实现类。
   ArrayList 是一个**数组队列，相当于动态数组**。它由数组实现，随机访问效率高，随机插入、随机删除效率低。
   LinkedList 是一个**双向链表**。它也可以被当作堆栈、队列或双端队列进行操作。LinkedList随机访问效率低，但随机插入、随机删除效率低。
   Vector 是**矢量队列，和****ArrayList****一样，它也是一个动态数组，由数组实现**。但是ArrayList是非线程安全的，而Vector是线程安全的。
   Stack 是**栈，它继承于****Vector**。它的特性是：先进后出(FILO, First In Last Out)。

### 6.2 vector与arraylist

**1** **线程安全性不一样**

ArrayList是非线程安全；

而Vector是线程安全的，它的函数都是synchronized的，即都是支持同步的。
 ArrayList适用于单线程，Vector适用于多线程。

**2** **对序列化支持不同**

ArrayList支持序列化，而Vector不支持；即ArrayList有实现java.io.Serializable接口，而Vector没有实现该接口。

**3** **构造函数个数不同**
 ArrayList有3个构造函数，而Vector有4个构造函数。Vector除了包括和ArrayList类似的3个构造函数之外，另外的一个构造函数可以指定容量增加系数。

**4** **容量增加方式不同**

逐个添加元素时，若ArrayList容量不足时，“新的容量”=“(原始容量x3)/2 + 1”。
 而Vector的容量增长与“增长系数有关”，若指定了“增长系数”，且“增长系数有效(即，大于0)”；那么，每次容量不足时，“新的容量”=“原始容量+增长系数”。若增长系数无效(即，小于/等于0)，则“新的容量”=“原始容量 x 2”。

**5** **对****Enumeration****的支持不同。****Vector****支持通过****Enumeration****去遍历，而****List****不支持**

## 7、Thread的notify()和notifyAll()的区别?

wait()方法表示，放弃当前对资源的占有权。

notify()方法表示，当前的线程已经放弃对资源的占有，通知等待的线程来获得对资源的占有权，但是只有一个线程能够从wait状态中恢复，然后继续运行wait()后面的语句；

notifyAll()方法表示，当前的线程已经放弃对资源的占有，通知所有的等待线程从wait()方法后的语句开始运行。

 

**区别**

notify()方法只是让一个线程从wait中恢复过来，至于具体是哪个，那就得看那些线程的运气了(不设置优先级的情况下)，继续执行后面的语句；

notifyAll()方法是让所有的线程从wait中恢复过来，继续执行后面的语句。

## 9、Thread.join()?

  Thread提供了让一个线程等待另一个线程完成的方法 — join()方法。当在某个程序执行流程中调用其它线程的join()方法时，调用线程将被阻塞，直到被join()方法加入的join线程执行完毕为止，在继续运行。join()方法的实现原理是不停检查join线程是否存活，如果join线程存活则让当前线程永远等待。直到join线程完成后，线程的this.notifyAll()方法会被调用。

## 9(2)、start()方法 run()方法

当你调用start()方法时你将**创建新的线程**，并且执行在run()方法里的代码。但是如果你直接调用run()方法，它不会创建新的线程也不会执行调用线程的代码。

简单点来说：

new一个Thread，线程进入了新建状态;调用start()方法，线程进入了就绪状态，当分配到时间片后就可以开始运行了。

start()会执行线程的相应准备工作，然后自动执行run()方法的内容。是真正的多线程工作。

而直接执行run()方法，会把run方法当成一个mian线程下的普通方法去执行，并不会在某个线程中执行它，这并不是**多线程工作**。

## 10、volatile vs synchronized 

volatile关键字的作用是：**保证变量的可见性。**

在java内存结构中，每个线程都是有自己独立的内存空间(此处指的线程栈)。当需要对一个共享变量操作时，线程会将这个数据从主存空间复制到自己的独立空间内进行操作，然后在某个时刻将修改后的值刷新到主存空间。这个中间时间就会发生许多奇奇怪怪的线程安全问题了，volatile就出来了，它保证读取数据时只从主存空间读取，修改数据直接修改到主存空间中去，这样就保证了这个变量对多个操作线程的可见性了。换句话说，被volatile修饰的变量，能保证该变量的 **单次读**或者**单次写** 操作是原子的。

 

但是线程安全是两方面需要的 原子性(指的是**多条操作**)和可见性。volatile只能保证可见性，synchronized是两个均保证的。

volatile轻量级，只能修饰变量；synchronized重量级，还可修饰方法。

volatile不会造成线程的阻塞，而synchronized可能会造成线程的阻塞。

 

volatile作为java中的关键词之一，用以**声明变量的值可能随时会别的线程修改**，使用volatile修饰的变量**会强制将修改的值立即写入主存**，**主存中值的更新会使缓存中的值失效**(非volatile变量不具备这样的特性，非volatile变量的值会被缓存，线程A更新了这个值，线程B读取这个变量的值时可能读到的并不是是线程A更新后的值)。volatile会禁止指令重排。

 

volatile具有可见性、有序性，不具备原子性。

注意，volatile**不具备原子性**，这是volatile与java中的synchronized、java.util.concurrent.locks.Lock最大的功能差异.

 

下面来分别看下可见性、有序性、原子性：

**原子性：**如果你了解事务，那这个概念应该好理解。原子性通常指多个操作不存在只执行一部分的情况，如果全部执行完成那没毛病，如果只执行了一部分，那对不起，你得撤销(即事务中的回滚)已经执行的部分。

**可见性：**当多个线程访问同一个变量x时，线程1修改了变量x的值，线程1、线程2...线程n能够立即读取到线程1修改后的值。

**有序性：**即程序执行时按照代码书写的先后顺序执行。在Java内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。

 

volatile适用场景:

适用于对变量的写操作不依赖于当前值，对变量的读取操作不依赖于非volatile变量。

适用于读多写少的场景。

可用作状态标志。

JDK中volatile应用：JDK中ConcurrentHashMap的Entry的value和next被声明为volatile，AtomicLong中的value被声明为volatile。AtomicLong通过CAS原理(也可以理解为乐观锁)保证了原子性。

 

volatile VS synchronized

volatile不会让线程阻塞，**响应速度比synchronized高**，这是它的优点。

## 11、atomic与volatile的区别？

Synchronized 基于阻塞的**锁机制**，也就是说当一个线程拥有锁的时候，访问同一资源的其它线程需要等待，直到该线程释放锁，这里会有些**问题**：首先，如果被阻塞的线程优先级很高很重要怎么办？其次，如果获得锁的线程一直不释放锁怎么办？（这种情况是非常糟糕的）。还有一种情况，如果有大量的线程来竞争资源，那CPU将会花费大量的时间和资源来处理这些竞争（事实上CPU的主要工作并非这些），同时，还有可能出现一些例如死锁之类的情况，最后，其实锁机制是一种比较粗糙，粒度比较大的机制，相对于像计数器这样的需求有点儿过于笨重，因此，对于这种需求我们期待一种更合适、更高效的线程安全机制。

 

volatile关键字的作用是：**保证变量的可见性。**

在java内存结构中，每个线程都是有自己独立的内存空间(此处指的线程栈)。当需要对一个共享变量操作时，线程会将这个数据从主存空间复制到自己的独立空间内进行操作，然后在某个时刻将修改后的值刷新到主存空间。这个中间时间就会发生许多奇奇怪怪的线程安全问题了，volatile就出来了，它保证读取数据时只从主存空间读取，修改数据直接修改到主存空间中去，这样就保证了这个变量对多个操作线程的可见性了（内存屏障）。换句话说，被volatile修饰的变量，能保证该变量的 **单次读**或者**单次写**操作是原子的。

 

**什么是内存屏障（Memory Barrier）？**

内存屏障（memory barrier） 是一个CPU指令。基本上，它是这样一条指令： a) 确保一些特定操作执行的顺序； b) 影响一些数据的可见性(可能是某些指令执行后的结果)。编译器和CPU可以在保证输出结果一样的情况下对指令重排序，使性能得到优化。**插入一个内存屏障，相当于告诉CPU和编译器先于这个命令的必须先执行，后于这个命令的必须后执行。内存屏障另一个作用是强制更新一次不同CPU的缓存。**例如，一个写屏障会把这个屏障前写入的数据刷新到缓存，这样任何试图读取该数据的线程将得到最新值，而不用考虑到底是被哪个cpu核心或者哪颗CPU执行的。

 

volatile为什么没有原子性?

明白了内存屏障（memory barrier）这个CPU指令，回到前面的JVM指令：从Load到store到内存屏障，一共4步，其中最后一步jvm让这个最新的变量的值在所有线程可见，也就是最后一步让所有的CPU内核都获得了最新的值，但中间的几步（从Load到Store）是不安全的，中间如果其他的CPU修改了值将会丢失。

 

Atomic CAS+volatile实现

 

 

## 12、单例有多少种写法? 有什么区别? 

### 12.1 懒汉模式

线程不安全，但可以延迟

【不推荐，不使用】

 

public class Singleton1 {

  private static Singleton1 singleton1=null;

  private Singleton1(){}

  public static Singleton1 getIntance(){

​    return singleton1;

  }

}

注释：这种写法lazy loading很明显，但是致命的是在多线程不能正常工作。

 

### 12.2 懒汉模式

线程安全。但可以延迟。

使用情况：【不要求延迟时，可以使用，不推荐】

class Singleton2{

  private tatic Singleton2 singleton2=null;

  private Singleton2(){}

  public static **synchronized** Singleton2 getIntance(){

​    return singleton2;

  }

}

注释：这种写法能够在多线程中很好的工作，而且看起来它也具备很好的lazy loading，但是，遗憾的是，效率很低，99%情况下不需要同步

 

### 12.3 饿汉模式

所有饿汉模式的单例都是线程安全的。

使用情况：【常用】

class Singleton3{

  private static Singleton3 singleton3=new Singleton3();

  private Singleton3(){}

  public static Singleton3 getIntance(){

​    return singleton3;

  }

}

注释： 这种方式基于classloder机制避免了多线程的同步问题，不过，instance在类装载时就实例化，虽然导致类装载的原因有很多种，在单例模式中大多数都是调用getInstance方法，但是也不能确定有其他的方式（或者其他的静态方法）导致类装载，这时候初始化instance显然没有达到lazy loading的效果

 

### 12.4 饿汉模式

静态内部类

【推荐使用】

class Singleton4 { 

  private static class SingletonHolder { 

​    private static final Singleton4 INSTANCE = new Singleton4(); 

  } 

  private Singleton4 (){} 

  public static final Singleton4 getInstance() { 

​    return SingletonHolder.INSTANCE; 

  } 

}

注释：这种方式同样利用了classloder的机制来保证初始化instance时只有一个线程，它跟第三种和第四种方式不同的是（很细微的差别）：第三种和第四种方式是只要Singleton类被装载了，那么instance就会被实例化（没有达到lazy loading效果），而这种方式是Singleton类被装载了，instance不一定被初始化。因为SingletonHolder类没有被主动使用，只有显示通过调用getInstance方法时，才会显示装载SingletonHolder类，从而实例化instance。想象一下，如果实例化instance很消耗资源，我想让他延迟加载，另外一方面，我不希望在Singleton类加载时就实例化，因为我不能确保Singleton类还可能在其他的地方被主动使用从而被加载，那么这个时候实例化instance显然是不合适的。这个时候，这种方式相比第三和第四种方式就显得很合理。

### 12.5 双重校验锁

使用情况：【推荐使用，常用，用吧，非常不错啦】

class Singleton5{ 

   private volatile static Singleton4 singleton;

  private Singleton5 (){} 

  public static Singleton5 getSingleton() { 

   if (singleton == null) { 

​      synchronized (Singleton5.class) {

​      if (singleton == null) { 

​      singleton = new Singleton5();

​     } 

​    }

  } 

  return singleton5;}

}

注释：在双重检查锁中，代码会检查两次单例类是否有已存在的实例，一次加锁一次不加锁，一次确保不会有多个实例被创建。声明_instance变量时使用了volatile关键字。没有volatile修饰符，可能出现Java中的另一个线程看到个初始化了一半的_instance的情况，但使用了volatile变量后，就能保证先行发生关系（happens-before relationship）。对于volatile变量_instance，所有的写（write）都将先行发生于读（read）

 

### 12.6 枚举单例模式

【好处不外乎三点：1.线程安全2.不会因为序列化而产生新实例3.防止反射攻击】

private Object readResolve(){

​    return INSTANCE;

}

注释：代码就这么简单，你可以使用EasySingleton.INSTANCE调用它，比起你在单例中调用getInstance()方法容易多了。下面是我总结的使用枚举实现单例模式的几个原因。

枚举单例模式代码简洁 这是迄今为止最大的优点，如果你曾经在java5之前写过单例模式实现代码，那么你会知道即使是使用双检锁你有时候也会返回不止一个实例对象。虽然这种问 题通过改善java内存模型和使用volatile变量可以解决，但是这种方法对于很多初学者来说写起来还是很棘手。相比用 synchronization的双检索实现方式来说，枚举单例就简单多了。

用枚举实现的单例：这是我们通常写枚举单例的方式，它可能包含实例变量和实例方法，但是简单来说我什么都没用，需要注意的是如果你使用实例方法，你就需要确保方法的线程安全性，避免它会影响对象的状态。通常情况下枚举里面创建实例是线程安全的，但是其它的方法就需要编程者自己去考虑了。

## 13、kafka 原理和容错（待整理）

https://www.cnblogs.com/dumi/p/9284072.html

## 14、redis 同步机制

在Slave启动并连接到Master之后，它将主动发送一条SYNC命令。此后Master将启动后台存盘进程，同时收集所有接收到的用于修改数据集的命令，在后台进程执行完毕后，Master将传送整个数据库文件到Slave，以完成一次完全同步。而Slave服务器在接收到数据库文件数据之后将其存盘并加载到内存中。此后，Master继续将所有已经收集到的修改命令，和新的修改命令依次传送给Slaves，Slave将在本次执行这些数据修改命令，从而达到最终的数据同步。

 

## 15、Spring加载过程？（控制反转与依赖注入）

 

## 16、aop 原理

https://www.cnblogs.com/lcngu/p/5339555.html

 

## 17、Spring AOP的实现原理，底层用什么实现的？（动态代理）

AOP (Aspect Oriented Programing) ：面向切面编程，它是一种编程思想。AOP采取横向抽取机制，取代了传统纵向继承体系重复性代码的编写方式（可用于性能监视、事务管理、安全检查、缓存,日志记录等）。

AOP就是要对目标进行代理对象的创建，Spring AOP是基于动态代理的，基于两种动态代理机制：JDK动态代理和CGLIB动态代理。

 

动态代理和静态代理区别？

动态代理：在虚拟机内部，运行的时候，动态生成代理类(运行时生成，runtime生成) ，并不是真正存在的类。

静态代理：存在代理类 （例如：struts2 Action的代理类 ActionProxy）

 

JDK代理：基于接口的代理，一定是基于接口，会生成目标对象的接口类型的子对象。

Cglib代理：基于类的代理，不需要基于接口，会生成目标对象类型的子对象。

## 18、写一个JAVA死锁的例子?（实际测试）

package com.simon.study;

/**

 \* 线程死锁 一个线程要同时拥有两个对象的资源才能进行下一步操作；

*/

public class DeadLock implements Runnable{

 static Object o1=new Object(),o2=new Object();

 public int flag=1;

 

 

   public void run() {

​      // TODO Auto-generated method stub

​      System.out.println("flag***********"+flag);

​      if(flag==1){

​        synchronized (o1) {

​           try {

​              Thread.sleep(500);

​           } catch (Exception e) {

​              // TODO: handle exception

​           }

​           synchronized (o2) {

​              System.out.println("这里线程1获取所有的线程权限");

​           }

​        }

​        

​        }

​      if(flag==0){

​        synchronized (o2) {

​           try {

​              Thread.sleep(500);

​           } catch (Exception e) {

​              // TODO: handle exception

​           }

​           synchronized (o1) {

​              System.out.println("这里线程2获取所有的线程权限");

​           }

​        }

​        

​      }

​      }

   public static void main(String[] args){

​      DeadLock deadLock1=new DeadLock();

​      DeadLock deadLock2=new DeadLock();

​      deadLock1.flag=1;

​      deadLock2.flag=0;

​      Thread r1=new Thread(deadLock1);

​      Thread r2=new Thread(deadLock2);

​      r1.start();

​      r2.start();

   }

   }

 

 

## 19、NIO与IO

### 19.1 Java NIO和IO的主要区别

IO        NIO

面向流      面向缓冲

阻塞IO      非阻塞IO

无        选择器

 

IO和NIO 又称为Blocking IO 和 No Blocking IO 即为阻塞，非阻塞IO。

IO每一个连接都需要建立一个线程，NIO不需要。

NIO主要有**buffer、channel、selector**三种技术的整合，**通过零拷贝的buffer取得数据，每一个客户端通过channel在selector（多路复用器）上进行注册**。**服务端不断轮询channel来获取客户端的信息**。channel上有connect,accept（阻塞）、read（可读）、write(可写)四种状态标识。根据标识来进行后续操作。所以一个服务端可接收无限多的channel。不需要新开一个线程。大大提升了性能。

AIO--NIO升级版：AIO即Asynchronous I/O(异步非阻塞 I/O)，AIO通过调用accept方法，一个会话接入之后再次调用（递归）accept方法，监听下一次会话，读取也不再阻塞，回调complete方法异步进行。不再需要selector使用channel线程组来接收。

但是不管是哪种IO技术，编码都很复杂。故出现了netty。基于NIO。提供更简单的API让网络编程代码更容易，只需关注业务逻辑。

 

 

 

### 19.2 面向流与面向缓冲

Java NIO和IO之间第一个最大的区别是，IO是面向流的，NIO是面向缓冲区的。 Java IO面向流意味着每次从流中读一个或多个字节，直至读取所有字节，它们没有被缓存在任何地方。此外，它不能前后移动流中的数据。如果需要前后移动从流中读取的数据，需要先将它缓存到一个缓冲区。 Java NIO的缓冲导向方法略有不同。数据读取到一个它稍后处理的缓冲区，需要时可在缓冲区中前后移动。这就增加了处理过程中的灵活性。但是，还需要检查是否该缓冲区中包含所有您需要处理的数据。而且，需确保当更多的数据读入缓冲区时，不要覆盖缓冲区里尚未处理的数据。

 

### 19.3 阻塞与非阻塞IO

Java IO的各种流是阻塞的。这意味着，当一个线程调用read() 或 write()时，该线程被阻塞，直到有一些数据被读取，或数据完全写入。该线程在此期间不能再干任何事情了。 Java NIO的非阻塞模式，使一个线程从某通道发送请求读取数据，但是它仅能得到目前可用的数据，如果目前没有数据可用时，就什么都不会获取。而不是保持线程阻塞，所以直至数据变的可以读取之前，该线程可以继续做其他的事情。 非阻塞写也是如此。一个线程请求写入一些数据到某通道，但不需要等待它完全写入，这个线程同时可以去做别的事情。 线程通常将非阻塞IO的空闲时间用于在其它通道上执行IO操作，所以一个单独的线程现在可以管理多个输入和输出通道（channel）。

 

### 19.4 选择器（Selectors）

Java NIO的选择器允许一个单独的线程来监视多个输入通道，你可以注册多个通道使用一个选择器，然后使用一个单独的线程来“选择”通道：这些通道里已经有可以处理的输入，或者选择已准备写入的通道。这种选择机制，使得一个单独的线程很容易来管理多个通道。

 

 

 

## 20、关系型数据库与非关系型数据库

1.关系型数据库通过外键关联来建立表与表之间的关系

2.非关系型数据库通常指数据以对象的形式存储在数据库中，而对象之间的关系通过每个对象自身的属性来决定

 

 

 

## 21、分表分库

### 21.1、基础概念

**分表：**能够解决单表数据量过大带来的查询效率下降的问题；

**分库：**面对高并发的读写访问，当数据库master服务器无法承载写操作压力时，不管如何扩展slave服务器，此时都没有意义。此时，则需要通过数据分库策略，提高数据库并发访问能力。

**优点：**分库、分表技术优化了数据存储方式，有效减小数据库服务器的负担、缩短查询响应时间。

**数据分库、分表存储场景条件：**

1）关系型数据库

2）主从架构(master-slave)

3）单表数据量在百万、千万级别

4）数据库面临极高的并发访问

**分库、分表实现策略**：关键字取模，实现对数据访问进行路由。

**分库举例：**

1）按功能分：用户类库、商品类库、订单类库、日志类库等。

2）按地区分：每个城市或省市一个同样的库。

 

### 21.2 横向/水平分表:解决表记录太大问题

主要解决问题：

单表过大造成的性能问题；

单表过大造成的单服务器空间问题。

按某个字段分

如：将用户资料附件表分成3个附件分表pre_forum_attachment_[0|1|2]，和1个附件索引表（存储tid和附件id关系），根据tid最后一位判断附件保存在哪个分表中。

按日期分表 

日志类、统计类数据表按年、月、日、周分表。如：点击量统计click_201801、click_201802

通过MySQL的merge存储引擎实现

需要创建分表、总表，总表需要merge存储引擎。 

示例代码

create table log_merge (

dt datetime not null,

info varchar (100) not null,

index (dt)

) engine = merge

union= (log_2017,log_2018) insert_method = last;

### 21.3 纵向/垂直分表 : 解决 列过多问题

纵向分表常见的方式有**根据活跃度分表、根据重要性分表**等。

 

**主要解决问题：**

表与表之间资源争用问题；

锁争用机率小；

实现核心与非核心的分级存储，如UDB登陆库拆分成一级二级三级库；

数据库同步压力问题。

 

**具体策略**

经常组合查询的列放在一个表，常用字段的表可考虑Memory引擎。

不经常使用的字段单独成表。

把text、blob等大字段拆分放在附表。如：把用户文章表分成主表news和从表news_data，主表存标题、关键字、浏览量等，从表存具体内容、模板等。

分库、分表注意事项

**维度问题**

针对用户购买记录数据，如果按照用户纬度分表，则每个用户的交易记录都保存在同一表中，所以很快很方便的查找到某用户的购买情况，但是某商品被购买的情况则可能分布在多张表中，查找起来比较麻烦。

若按照商品维度分表，方便查找商品购买情况，但查找个人交易记录比较麻烦。

**常见解决方案：**

通过扫表方式解决，效率太低，不可行。

记录两份数据，一份按照用户纬度分表，一份按照商品维度分表。

通过搜索引擎解决，但如果实时性要求很高，则牵涉到实时搜索问题。

避免分表join操作。关联的表有可能不在同一数据库中。

**避免跨库事务**

避免在一个事务中修改db0、db1中的表，不仅操作复杂，而且影响效率。

分表宜多不宜少；避免后期可能二次拆分。

尽量同组数据统一DB服务器。例如将卖家a的商品和交易信息都放到db0中，当db1挂了的时候，卖家a相关的东西可以正常使用。即避免多个数据库中的数据产生依赖。

## 22、dubbo

 

## 23、IO多路复用之select、poll、epoll详解

目前支持I/O多路复用的系统调用有`select，pselect，poll，epoll`，I/O多路复用就是`通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作`。`但select，pselect，poll，epoll本质上都是**同步I/O**`，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。(netty)

与多进程和多线程技术相比，`I/O多路复用技术的最大优势是**系统开销小**，系统不必创建进程/线程`，也不必维护这些进程/线程，从而大大减小了系统的开销。

 

### 一、使用场景

**IO****多路复用是指内核一旦发现进程指定的一个或者多个****IO****条件准备读取，它就通知该进程。**IO多路复用适用如下场合：

1）当客户处理多个描述符时（一般是交互式输入和网络套接口），必须使用I/O复用。

2）当一个客户同时处理多个套接口时，这种情况是可能的，但很少出现。

3）如果一个TCP服务器既要处理监听套接口，又要处理已连接套接口，一般也要用到I/O复用。

4）如果一个服务器即要处理TCP，又要处理UDP，一般要使用I/O复用。

5）如果一个服务器要处理多个服务或多个协议，一般要使用I/O复用。

 

### 二、select、poll、epoll简介

epoll跟select都能提供多路I/O复用的解决方案。在现在的Linux内核里有都能够支持，`其中epoll是Linux所特有，而select则应该是POSIX所规定`，一般操作系统均有实现。

#### select

**基本原理：**select 函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds。调用后select函数会阻塞，直到有描述符就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以通过遍历fdset，来找到就绪的描述符。

 

**基本流程，如图所示：**

 

select目前几乎在所有的平台上支持，`其良好跨平台支持也是它的一个优点`。`select的一个缺点在于单个进程能够监视的文件描述符的数量存在最大限制`，在Linux上一般为1024，`可以通过修改宏定义甚至重新编译内核的方式提升这一限制`，但是这样也会造成效率的降低。

 

`select本质上是通过设置或者检查存放fd标志位的数据结构来进行下一步处理`。这样所带来的缺点是：

1、select最大的缺陷就是单个进程所打开的FD是有一定限制的，它由FD_SETSIZE设置，默认值是1024**。**

一般来说这个数目和系统内存关系很大，`具体数目可以cat /proc/sys/fs/file-max察看`。32位机默认是1024个。64位机默认是2048.

2、对socket进行扫描时是线性扫描，即采用轮询的方法，效率较低。

当套接字比较多的时候，每次select()都要通过遍历FD_SETSIZE个Socket来完成调度，不管哪个Socket是活跃的，都遍历一遍。这会浪费很多CPU时间。`如果能给套接字注册某个回调函数，当他们活跃时，自动完成相关操作，那就避免了轮询`，这正是epoll与kqueue做的。

`3``、需要维护一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大。`

 

#### **poll**

**基本原理：**`poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间`，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历完所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历fd。这个过程经历了多次无谓的遍历。

 

**它没有最大连接数的限制，**`**原因是它是基于链表来存储的**`**，但是同样有一个缺点：**

`1）大量的fd的数组被整体复制于用户态和内核地址空间之间`，而不管这样的复制是不是有意义。

`2）poll还有一个特点是“水平触发”`，如果报告了fd后，没有被处理，那么下次poll时会再次报告该fd。

 

**注意：**从上面看，select和poll都需要在返回后，`通过遍历文件描述符来获取已经就绪的socket`。事实上，`同时连接的大量客户端在一时刻可能只有很少的处于就绪状态`，因此随着监视的描述符数量的增长，其效率也会线性下降。

 

#### epoll

epoll是在2.6内核中提出的，是之前的select和poll的增强版本。相对于select和poll来说，epoll更加灵活，没有描述符限制。`epoll使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次`。

 

**基本原理：**`epoll支持水平触发和边缘触发，最大的特点在于边缘触发，它只告诉进程哪些fd刚刚变为就绪态，并且只会通知一次`。还有一个特点是，`epoll使用“事件”的就绪通知方式`，通过epoll_ctl注册fd，`一旦该fd就绪，内核就会采用类似callback的回调机制来激活该fd`，epoll_wait便可以收到通知。

 

**epoll****的优点：**

`1、没有最大并发连接的限制`，能打开的FD的上限远大于1024（1G的内存上能监听约10万个端口）。

`2、效率提升，不是轮询的方式，不会随着FD数目的增加效率下降`。

只有活跃可用的FD才会调用callback函数；`即Epoll最大的优点就在于它只管你“活跃”的连接，而跟连接总数无关`，因此在实际的网络环境中，Epoll的效率就会远远高于select和poll。

`3、内存拷贝`，利用mmap()文件映射内存加速与内核空间的消息传递；`即epoll使用mmap减少复制开销`。

 

epoll对文件描述符的操作有两种模式：`LT（level trigger）和ET（edge trigger）`。LT模式是默认模式，LT模式与ET模式的区别如下：

LT模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，`应用程序可以不立即处理该事件`。下次调用epoll_wait时，会再次响应应用程序并通知此事件。

ET模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，`应用程序必须立即处理该事件`。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。

**1****、****LT****模式**

`LT(level triggered)是缺省的工作方式，并且同时支持block和no-block socket`。在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。`如果你不作任何操作，内核还是会继续通知你的`。

**2****、****ET****模式**

`ET(edge-triggered)是高速工作方式，只支持no-block socket`。在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，直到你做了某些操作导致那个文件描述符不再为就绪状态了(比如，你在发送，接收或者接收请求，或者发送接收的数据少于一定量时导致了一个EWOULDBLOCK 错误）。`但是请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核不会发送更多的通知(only once)`。

`ET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高`。epoll工作在ET模式的时候，`必须使用非阻塞套接口`，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。

3、在select/poll中，`进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描`，而epoll事先通过epoll_ctl()来注册一个文件描述符，`一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制`，迅速激活这个文件描述符，当进程调用epoll_wait()时便得到通知。(`此处去掉了遍历文件描述符，而是通过监听回调的的机制。这正是epoll的魅力所在。`)

**注意：**如果没有大量的idle-connection或者dead-connection，epoll的效率并不会比select/poll高很多，但是当遇到大量的idle-connection，就会发现epoll的效率大大高于select/poll。

 

https://www.cnblogs.com/lojunren/p/3856290.html

 

epoll的三大关键要素：**mmap****、红黑树、链表**

 

 

### 三、select、poll、epoll区别

#### 1、支持一个进程所能打开的最大连接数

 

#### 2、FD剧增后带来的IO效率问题

 

#### 3、消息传递方式

 

 

综上，在选择select，poll，epoll时要根据具体的使用场合以及这三种方式的自身特点：

1、表面上看epoll的性能最好，`但是在连接数少并且连接都十分活跃的情况下，select和poll的性能可能比epoll好`，毕竟epoll的通知机制需要很多函数回调。

`2、select低效是因为每次它都需要轮询`。但低效也是相对的，视情况而定，也可通过良好的设计改善。

 

## 24、数据库常见的三种避免死锁的方法

1）如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大降低死锁机会；

2）在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率；

3）对于非常容易产生死锁的业务部分，可以尝试使用升级锁定颗粒度，通过表级锁定来减少死锁产生的概率。

 

 

## 25、sql语法（join，union）

https://www.cnblogs.com/logon/p/3748020.html

 

## 26、Memcache、Oscache、Ehcache

**Memcache:**分布式内存对象缓存系统，占用其他机子的内存。很多互联网，负载均衡三台(以三台为例)web服务器可以共享一台Memcache的资源。传递的信息以键值对的形式存储。传递的数据要实现序列化。

 

**Oscache:**页面级缓存（网上强调最多的东西）,占用本机的内存资源。可以选择缓存到硬盘，如存取到硬盘重启服务也可重新获得上次持久化的资源，而如果缓存到内存就不行。一般没必要缓存到硬盘，因为I/O操作也是比较耗资源，和从数据库取往往优势很小。Oscache存取数据的作用域分为application和session两种

**EhCache：**Hibernate缓存，DAO缓存，安全性凭证缓存（Acegi），Web缓存，应用持久化和分布式缓存。

  EhCache在默认情况下，即在用户未提供自身配置文件ehcache.xml或ehcache-failsafe.xml时，EhCache会依据其自身Jar存档包含的ehcache-failsafe.xml文件所定制的策略来管理缓存。如果用户在classpath下提供了ehcache.xml或ehcache-failsafe.xml文件，那么EhCache将会应用这个文件。如果两个文件同时提供，那么EhCache会使用ehcache.xml文件的配置。

  ehcache主要是对**数据库访问**的缓存,相同的查询语句只需查询一次数据库,从而提高了查询的速度,使用spring的AOP可以很容易实现这一功能。

  oscache 主要是对**页面的**缓存,可以整页或者指定网页某一部分缓存,同时指定他的过期时间,这样在此时间段里面访问的数据都是一样的。

 

## 27、序列化

**1．序列化和反序列化的概念**

序列化：把对象转换为字节序列的过程称为对象的序列化。

反序列化：把字节序列恢复为对象的过程称为对象的反序列化。

 

上面是专业的解释，现在来点通俗的解释。在代码运行的时候，我们可以看到很多的对象，可以是一个，也可以是一类对象的集合，很多的对象数据，这些数据中，有些信息我们想让他持久的保存起来，那么这个就叫序列化。就是把内存里面的这些对象给变成一连串的字节(bytes)描述的过程。常见的就是变成文件

 

**2．什么情况下需要序列化**

当你想把的内存中的对象状态保存到一个文件中或者数据库中时候；

当你想用套接字在网络上传送对象的时候；

当你想通过RMI传输对象的时候；

 

**3．java如何实现序列化**

实现Serializable接口即可

 

 

## 28、限流

在开发高并发系统时有三把利器用来保护系统：**缓存、降级和限流**。缓存的目的是提升系统访问速度和增大系统能处理的容量，可谓是抗高并发流量的银弹；而降级是当服务出问题或者影响到核心流程的性能则需要暂时屏蔽掉，待高峰或者问题解决后再打开；而有些场景并不能用缓存和降级来解决，比如稀缺资源（秒杀、抢购）、写服务（如评论、下单）、频繁的复杂查询（评论的最后几页），因此需有一种手段来限制这些场景的并发/请求量，即限流。

 

限流的目的是**通过对并发访问/请求进行限速或者一个时间窗口内的的请求进行限速来保护系统**，一旦达到限制速率则可以拒绝服务（定向到错误页或告知资源没有了）、排队或等待（比如秒杀、评论、下单）、降级（返回兜底数据或默认数据，如商品详情页库存默认有货）。

 

一般开发高并发系统常见的限流有：限制总并发数（比如数据库连接池、线程池）、限制瞬时并发数（如nginx的limit_conn模块，用来限制瞬时并发连接数）、限制时间窗口内的平均速率（如Guava的RateLimiter、nginx的limit_req模块，限制每秒的平均速率）；其他还有如限制远程接口调用速率、限制MQ的消费速率。另外还可以根据网络连接数、网络流量、CPU或内存负载等来限流。

 

先有缓存这个银弹，后有限流来应对618、双十一高并发流量，在处理高并发问题上可以说是如虎添翼，不用担心瞬间流量导致系统挂掉或雪崩，最终做到有损服务而不是不服务；限流需要评估好，不可乱用，否则会正常流量出现一些奇怪的问题而导致用户抱怨。

 

### 限流算法

常见的限流算法有：**令牌桶、漏桶。计数器也可以进行粗暴限流实现。**

 

#### 令牌桶算法

令牌桶算法是一个存放固定容量令牌的桶，按照固定速率往桶里添加令牌。令牌桶算法的描述如下：

1）假设限制2r/s，则按照500毫秒的固定速率往桶中添加令牌；

2）桶中最多存放b个令牌，当桶满时，新添加的令牌被丢弃或拒绝；

3）当一个n个字节大小的数据包到达，将从桶中删除n个令牌，接着数据包被发送到网络上；

4）如果桶中的令牌不足n个，则不会删除令牌，且该数据包将被限流（要么丢弃，要么缓冲区等待）。

 

#### 漏桶算法

漏桶作为计量工具（The Leaky Bucket Algorithm as a Meter）时，可以用于流量整形（Traffic Shaping）和流量控制（TrafficPolicing），漏桶算法的描述如下：

1）一个固定容量的漏桶，按照常量固定速率流出水滴；

2）如果桶是空的，则不需流出水滴；

3）可以以任意速率流入水滴到漏桶；

4）如果流入水滴超出了桶的容量，则流入的水滴溢出了（被丢弃），而漏桶容量是不变的。

 

**令牌桶和漏桶对比：**

 

1）令牌桶是按照固定速率往桶中添加令牌，请求是否被处理需要看桶中令牌是否足够，当令牌数减为零时则拒绝新的请求；

2）漏桶则是按照常量固定速率流出请求，流入请求速率任意，当流入的请求数累积到漏桶容量时，则新流入的请求被拒绝；

3）令牌桶限制的是平均流入速率（允许突发请求，只要有令牌就可以处理，支持一次拿3个令牌，4个令牌），并允许一定程度突发流量；

4）漏桶限制的是常量流出速率（即流出速率是一个固定常量值，比如都是1的速率流出，而不能一次是1，下次又是2），从而平滑突发流入速率；

5）令牌桶允许一定程度的突发，而漏桶主要目的是平滑流入速率；

6）两个算法实现可以一样，但是方向是相反的，对于相同的参数得到的限流效果是一样的。

 

#### 计数器

另外有时候我们还使用**计数器**来进行限流，主要用来限制总并发数，比如数据库连接池、线程池、秒杀的并发数；只要全局总请求数或者一定时间段的总请求数设定的阀值则进行限流，是简单粗暴的总数量限流，而不是平均速率限流。

 

### 应用级限流

#### 限流总并发/连接/请求数

对于一个应用系统来说一定会有极限并发/请求数，即总有一个TPS/QPS阀值，如果超了阀值则系统就会不响应用户请求或响应的非常慢，因此我们最好进行过载保护，防止大量请求涌入击垮系统。

 

#### 限流总资源数

如果有的资源是稀缺资源（如数据库连接、线程），而且可能有多个系统都会去使用它，那么需要限制应用；可以使用池化技术来限制总资源数：连接池、线程池。比如分配给每个应用的数据库连接是100，那么本应用最多可以使用100个资源，超出了可以等待或者抛异常。

 

#### 限流某个接口的总并发/请求数

如果接口可能会有突发访问情况，但又担心访问量太大造成崩溃，如抢购业务；这个时候就需要限制这个接口的总并发/请求数总请求数了；因为粒度比较细，可以为每个接口都设置相应的阀值。可以使用Java中的AtomicLong进行限流：

 

=================================

 

try {

  if(atomic.incrementAndGet() > 限流数) {

​    //拒绝请求

  }

  //处理请求

} finally {

  atomic.decrementAndGet();

}

=================================

 

适合对业务无损的服务或者需要过载保护的服务进行限流，如抢购业务，超出了大小要么让用户排队，要么告诉用户没货了，对用户来说是可以接受的。而一些开放平台也会限制用户调用某个接口的试用请求量，也可以用这种计数器方式实现。这种方式也是简单粗暴的限流，没有平滑处理，需要根据实际情况选择使用；

 

 

#### 限流某个接口的时间窗请求数

即一个时间窗口内的请求数，如想限制某个接口/服务每秒/每分钟/每天的请求数/调用量。如一些基础服务会被很多其他系统调用，比如商品详情页服务会调用基础商品服务调用，但是怕因为更新量比较大将基础服务打挂，这时我们要对每秒/每分钟的调用量进行限速；一种实现方式如下所示：

#### 平滑限流某个接口的请求数

之前的限流方式都不能很好地应对突发请求，即瞬间请求可能都被允许从而导致一些问题；因此在一些场景中需要对突发请求进行整形，整形为平均速率请求处理（比如5r/s，则每隔200毫秒处理一个请求，平滑了速率）。这个时候有两种算法满足我们的场景：令牌桶和漏桶算法。Guava框架提供了令牌桶算法实现，可直接拿来使用。

Guava RateLimiter提供了令牌桶算法实现：平滑突发限流(SmoothBursty)和平滑预热限流(SmoothWarmingUp)实现。

**假设将应用部署到多台机器，应用级限流方式只是单应用内的请求限流，不能进行全局限流。因此我们需要分布式限流和接入层限流来解决这个问题。**

 

### 分布式限流

分布式限流最关键的是要将限流服务做成原子化，而解决方案可以使使用Redis+lua或者nginx+lua技术进行实现，通过这两种技术可以实现的高并发和高性能。

 

首先我们来使用redis+lua实现时间窗内某个接口的请求数限流，实现了该功能后可以改造为限流总并发/请求数和限制总资源数。Lua本身就是一种编程语言，也可以使用它实现复杂的令牌桶或漏桶算法。

 

有人会纠结如果应用并发量非常大那么redis或者nginx是不是能抗得住；不过这个问题要从多方面考虑：你的流量是不是真的有这么大，是不是可以通过一致性哈希将分布式限流进行分片，是不是可以当并发量太大降级为应用级限流；对策非常多，可以根据实际情况调节；像在京东使用Redis+Lua来限流抢购流量，一般流量是没有问题的。

 

对于分布式限流目前遇到的场景是业务上的限流，而不是流量入口的限流；流量入口限流应该在接入层完成，而接入层笔者一般使用Nginx。

 

 

 

## 29、分布式事务

### 一 分布式中的CAP怎么理解

#### 1 CAP

C（Consistency）一致性 每一次读取都会让你得到最新的写入结果

A（Availability）可用性每个节点(如果没有失败)，总能执行查询(读取和写入)操作

P（Partition Tolerance）分区容忍性 即使节点之间的连接关闭，其他两个属性也会得到保证

CAP理论认为，任何联网的共享数据系统智能实现三个属性中的两个，但是可以通过明确处理分区，优化一致性和可用性，从而实现三者之间的某种权衡

#### 2 zookeeper提供的一致性服务

zookeeper是一种提供强一致性的服务，在分区容错性和可用性上做了一定折中，这和CAP理论是吻合的。但实际上zookeeper提供的只是单调一致性。

原因：
 1.假设有2n+1个server，在同步流程中，leader向follower同步数据，当同步完成的follower数量大于n+1时同步流程结束，系统可接受client的连接请求。如果client连接的并非同步完成的follower，那么得到的并非最新数据，但可以保证单调性。
 2.follower接收写请求后，转发给leader处理；leader完成两阶段提交的机制。向所有server发起提案，当提案获得超过半数（n+1）的server认同后，将对整个集群进行同步，超过半数（n+1）的server同步完成后，该写请求完成。如果client连接的并非同步完成follower，那么得到的并非最新数据，但可以保证单调性。

用分布式系统的CAP原则来分析Zookeeper：
 （1）C: Zookeeper保证了最终一致性,在十几秒可以Sync到各个节点.
 （2）A: Zookeeper保证了可用性,数据总是可用的,没有锁.并且有一大半的节点所拥有的数据是最新的,实时的.如果想保证取得是数据一定是最新的,需要手工调用Sync()
 （2）P:有2点需要分析的.

①节点多了会导致写数据延时非常大,因为需要多个节点同步.
 ②节点多了Leader选举非常耗时, 就会放大网络的问题. 可以通过引入observer节点缓解这个问题.

### 二 分布式一致性

#### 1 引言

在分布式系统中，为了保证数据的高可用,通常我们会将数据保留多个副本(replica),这些副本会放置在不同的物理机器上。为了对用户提供正确的curd等语意，我们需要保证这些放置在不同无力机器上的副本是一致的

为了解决这种分布式一致性问题，提出了很多典型的协议和算法，比较著名的是二阶段提交协议，三阶段提交协议和paxos算法。

#### 2 分布式事务

在分布式系统中，各个节点之间在物理上相互独立，通过网络进行沟通和协调。由于存在事务机制，可以保证每个独立节点上的数据操作可以满足ACID。但是，相互独立的节点之间无法准确地知道其他节点的事务执行情况。所以从理论上来讲，两台机器无法达到一致的状态。如果想让分布式部署的多台机器中的数据保持一致性，那么就要保证在所有节点数据的写操作，要么全部都执行，要么全部都不执行。但是，一台机器在执行本地事务的时候无法知道其他机器中的本地事务的执行结果，所以它也就不知道本次事务到底应该commit还是rollback。所以，常规的解决办法就是引入一个"协调者"的组件来统一调度所有分布式节点的执行。

### 三 2PC（Two-phaseCommit）

#### 1 二阶段提交

二阶段提交的算法思路可以概括为: 参与者将操作成败通知协调者，再由协调者根据所有参与者的反馈情报决定各参与者是否要提交操作还是中止操作。

二阶段是指:第一阶段 - 请求阶段(表决阶段)第二阶段 - 提交阶段(执行阶段)

(1) 请求阶段(表决)：

事务协调者通知每个参与者准备提交或取消事务，然后进入表决过程，参与者要么在本地执行事务，写本地的redo和undo日志，但不提交，到达一种"万事俱备，只欠东风"的状态。请求阶段，参与者将告知协调者自己的决策: 同意(事务参与者本地作业执行成功)或取消（本地作业执行故障）

(2) 提交阶段(执行):

在该阶段，写调整将基于第一个阶段的投票结果进行决策:提交或取消

当且仅当所有的参与者同意提交事务，协调者才通知所有的参与者提交事务，否则协调者将通知所有的参与者取消事务

参与者在接收到协调者发来的消息后将执行响应的操作

 

 

#### 2 两阶段提交的缺点

1.同步阻塞问题。执行过程中，所有参与节点都是事务阻塞型的。
 当参与者占有公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态。

2.单点故障。由于协调者的重要性，一旦协调者发生故障。
 参与者会一直阻塞下去。尤其在第二阶段，协调者发生故障，那么所有的参与者还都处于锁定事务资源的状态中，而无法继续完成事务操作。（如果是协调者挂掉，可以重新选举一个协调者，但是无法解决因为协调者宕机导致的参与者处于阻塞状态的问题）

3.数据不一致。在二阶段提交的阶段二中，当协调者向参与者发送commit请求之后，发生了局部网络异常或者在发送commit请求过程中协调者发生了故障，这回导致只有一部分参与者接受到了commit请求。
 而在这部分参与者接到commit请求之后就会执行commit操作。但是其他部分未接到commit请求的机器则无法执行事务提交。于是整个分布式系统便出现了数据不一致性的现象。

#### 3 两阶段提交无法解决的问题

当协调者出错，同时参与者也出错时，两阶段无法保证事务执行的完整性。
 考虑协调者在发出commit消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了。
 那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，没人知道事务是否被已经提交。

### 四 3PC（Three-phaseCommit）

#### 1 三阶段提交

三阶段提交协议在协调者和参与者中都引入超时机制，并且把两阶段提交协议的第一个阶段分成了两步: 询问，然后再锁资源，最后真正提交。

 

#### 2 三阶段的执行

(1)**canCommit****阶段**

3PC的canCommit阶段其实和2PC的准备阶段很像。协调者向参与者发送commit请求，参与者如果可以提交就返回yes响应，否则返回no响应

(2)**preCommit****阶段**

协调者根据参与者canCommit阶段的响应来决定是否可以继续事务的preCommit操作。根据响应情况，有下面两种可能:

a) 协调者从所有参与者得到的反馈都是yes:

那么进行事务的预执行，协调者向所有参与者发送preCommit请求，并进入prepared阶段。参与泽和接收到preCommit请求后会执行事务操作，并将undo和redo信息记录到事务日志中。如果一个参与者成功地执行了事务操作，则返回ACK响应，同时开始等待最终指令

b) 协调者从所有参与者得到的反馈有一个是No或是等待超时之后协调者都没收到响应:

那么就要中断事务，协调者向所有的参与者发送abort请求。参与者在收到来自协调者的abort请求，或超时后仍未收到协调者请求，执行事务中断。

(3)**doCommit****阶段**

协调者根据参与者preCommit阶段的响应来决定是否可以继续事务的doCommit操作。根据响应情况，有下面两种可能:

a) 协调者从参与者得到了ACK的反馈:

协调者接收到参与者发送的ACK响应，那么它将从预提交状态进入到提交状态，并向所有参与者发送doCommit请求。参与者接收到doCommit请求后，执行正式的事务提交，并在完成事务提交之后释放所有事务资源，并向协调者发送haveCommitted的ACK响应。那么协调者收到这个ACK响应之后，完成任务。

b) 协调者从参与者没有得到ACK的反馈, 也可能是接收者发送的不是ACK响应，也可能是响应超时:执行事务中断。

### 五 2PC vs 3PC

#### 1 2PC和3PC

对于协调者(Coordinator)和参与者(Cohort)都设置了超时机制（在2PC中，只有协调者拥有超时机制，即如果在一定时间内没有收到cohort的消息则默认失败）。
 在2PC的准备阶段和提交阶段之间，插入预提交阶段，使3PC拥有CanCommit、PreCommit、DoCommit三个阶段。
 PreCommit是一个缓冲，保证了在最后提交阶段之前各参与节点的状态是一致的。

#### 2 三阶段提交协议的缺点

如果进入PreCommit后，Coordinator发出的是abort请求，假设只有一个Cohort收到并进行了abort操作，
 而其他对于系统状态未知的Cohort会根据3PC选择继续Commit，此时系统状态发生不一致性。

#### 3 替代

目前还有一种重要的算法就是Paxos算法，Zookeeper采用的就是Paxos算法的改进。

## 30、泛型

 

Netty

Netty是一个高性能事件驱动的异步的非堵塞的IO(NIO)框架，用于建立TCP等底层的连接，基于Netty可以建立高性能的Http服务器。

 

Netty底层基于上述Java NIO的零拷贝原理实现

# 设计模式：单例模式、工厂模式、策略模式、设配器模式

 

## 1、创建型模式

### 1.1、工厂模式

工厂模式（Factory Pattern）是 Java 中最常用的设计模式之一，它提供了一种创建对象的最佳方式。

在工厂模式中，我们在创建对象时不会对客户端暴露创建逻辑，并且是通过使用一个共同的接口来指向新创建的对象。

 

 

 

 

 

### 1.2、单例模式

单例模式（Singleton Pattern）是 Java 中最简单的设计模式之一，它提供了一种创建对象的最佳方式。

这种模式涉及到一个单一的类，该类负责创建自己的对象，同时确保只有单个对象被创建。这个类提供了一种访问其唯一的对象的方式，可以直接访问，不需要实例化该类的对象。

注意：

1、单例类只能有一个实例。

2、单例类必须自己创建自己的唯一实例。

3、单例类必须给所有其他对象提供这一实例。

 

 

 

## 2、结构型模式

### 2.1、适配器模式

适配器模式（Adapter Pattern）是作为两个不兼容的接口之间的桥梁，它结合了两个独立接口的功能。

这种模式涉及到一个单一的类，该类负责加入独立的或不兼容的接口功能。举个真实的例子，读卡器是作为内存卡和笔记本之间的适配器。您将内存卡插入读卡器，再将读卡器插入笔记本，这样就可以通过笔记本来读取内存卡。

我们通过下面的实例来演示适配器模式的使用。其中，音频播放器设备只能播放 mp3 文件，通过使用一个更高级的音频播放器来播放 vlc 和 mp4 文件。

 

 

 

​     

 

 

## 3、行为型模式

### 3.1、策略模式

在策略模式（Strategy Pattern）中，一个类的行为或其算法可以在运行时更改。

在策略模式中，我们创建表示各种策略的对象和一个行为随着策略对象改变而改变的 context 对象。策略对象改变 context 对象的执行算法

 

 

 

## 4、J2EE模式

 

# SPRING里四大模式的表现 依赖注入和切面编程的用途及原理

 

# 多线程与并发

## 1、Lock vs 同步代码块（synchronized block）？ 

 

 

## 2、序列化和反序列化的概念

把对象转换为字节序列的过程称为对象的序列化。

把字节序列恢复为对象的过程称为对象的反序列化。

 

对象的序列化主要有两种用途：

1）把对象的字节序列永久地保存到硬盘上，通常存放在一个文件中；

2）在网络上传送对象的字节序列。

在很多应用中，需要对某些对象进行序列化，让它们离开内存空间，入住物理硬盘，以便长期保存。比如最常见的是Web服务器中的Session对象，当有 10万用户并发访问，就有可能出现10万个Session对象，内存可能吃不消，于是Web容器就会把一些seesion先序列化到硬盘中，等要用了，再把保存在硬盘中的对象还原到内存中。

当两个进程在进行远程通信时，彼此可以发送各种类型的数据。无论是何种类型的数据，都会以二进制序列的形式在网络上传送。发送方需要把这个Java对象转换为字节序列，才能在网络上传送；接收方则需要把字节序列再恢复为Java对象。

## 5、CAS 比较并交换

CAS，Compare and Swap即比较并交换，设计并发算法时常用到的一种技术。CAS有3个操作数，内存值V，旧的预期值A，新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。CAS是通过unsafe类的compareAndSwap (JNI, Java Native Interface) 方法实现的，该方法包括四个参数：第一个参数是要修改的对象，第二个参数是对象中要修改变量的偏移量，第三个参数是修改之前的值，第四个参数是预想修改后的值。

  CAS虽然很高效的解决原子操作，但是CAS仍然存在三大问题：ABA问题、循环时间长开销大和只能保证一个共享变量的原子操作。

  ABA问题：因为CAS需要在操作值的时候检查下值有没有发生变化，如果没有发生变化则更新，但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了。ABA问题的解决思路就是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加一，那么A－B－A 就会变成1A-2B－3A。

  不适用于竞争激烈的情形中：并发越高，失败的次数会越多，CAS如果长时间不成功，会极大的增加CPU的开销。因此CAS不适合竞争十分频繁的场景。

  只能保证一个共享变量的原子操作：当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁，或者有一个取巧的办法，就是把多个共享变量合并成一个共享变量来操作。比如有两个共享变量i＝2,j=a，合并一下ij=2a，然后用CAS来操作ij。从Java1.5开始JDK提供了AtomicReference类来保证引用对象之间的原子性，因此可以把多个变量放在一个对象里来进行CAS操作。

 

## 6、AQS 队列同步器

 

 

 

 

## 7、Condition

Condition可以用来实现线程的分组通信与协作。以生产者/消费者问题为例，

  wait/notify/notifyAll:在队列为空时，通知所有线程；在队列满时，通知所有线程，防止生产者通知生产者，消费者通知消费者的情形产生。

  await/signal/signalAll：将线程分为消费者线程和生产者线程两组：在队列为空时，通知生产者线程生产；在队列满时，通知消费者线程消费。

 

## 8、final

基本类型的数据：定值，只能赋值一次，不能再被修改。

方法：该方法不能被覆盖。Private的方法默认为final方法。

类：该类不能被继承。

## 9、什么是阻塞队列？如何使用阻塞队列来实现生产者-消费者模型？

  java.util.concurrent.BlockingQueue的特性是：当队列是空的时，从队列中获取或删除元素的操作将会被阻塞，或者当队列是满时，往队列里添加元素的操作会被阻塞。特别地，阻塞队列不接受空值，当你尝试向队列中添加空值的时候，它会抛出NullPointerException。另外，阻塞队列的实现都是线程安全的，所有的查询方法都是原子的并且使用了内部锁或者其他形式的并发控制。

  BlockingQueue 接口是java collections框架的一部分，它主要用于实现生产者-消费者问题。特别地，SynchronousQueue是一个没有容量的阻塞队列，每个插入操作必须等待另一个线程的对应移除操作，反之亦然。CachedThreadPool使用SynchronousQueue把主线程提交的任务传递给空闲线程执行。

 

## 10、线程安全和线程不安全

**线程安全的类**：在线程安全性的定义中，最核心的概念就是 正确性。当多个线程访问某个类时，不管运行时环境采用何种调度方式或者这些线程将如何交替执行，并且在主调代码中不需要任何额外的同步或协同，这个类都能表现出正确的行为，那么这个类就是线程安全的。

 

通俗的说：加锁的就是线程安全的，不加锁的就是线程不安全的。

线程安全：就是多线程访问时，采用了加锁机制，当一个线程访问该类的某个数据时，进行保护，其他线程不能进行访问，直到该线程读取完，其他线程才可使用。不会出现数据不一致或者数据污染。

一个线程安全的计数器类的同一个实例对象在被多个线程使用的情况下也不会出现计算失误。很显然你可以将集合类分成两组，线程安全和非线程安全的。Vector 是用同步方法来实现线程安全的,而和它相似的ArrayList 不是线程安全的。

线程不安全：就是不提供数据访问保护，有可能出现多个线程先后更改数据造成所得到的数据是脏数据

如果你的代码所在的进程中有多个线程在同时运行，而这些线程可能会同时运行这段代码。如果每次运行结果和单线程运行的结果是一样的，而且其他的变量的值也和预期的是一样的，就是线程安全的。

线程安全问题都是由全局变量及静态变量引起的。若每个线程中对全局变量、静态变量只有读操作，而无写操作，一般来说，这个全局变量是线程安全的；若有多个线程同时执行写操作，一般都需要考虑线程同步，否则的话就可能影响线程安全。

 

## 12、为什么线程通信的方法wait(), notify()和notifyAll()被定义在Object类里？

 

## 13、如何停止一个线程

使用volatile变量终止正常运行的线程 + 抛异常法/Return法

组合使用interrupt方法与interruptted/isinterrupted方法终止正在运行的线程 + 抛异常法/Return法

使用interrupt方法终止 正在阻塞中的 线程

## 14、JAVA实现同步的几种方法

java允许多线程并发控制，当多个线程同时操作一个可共享的资源变量时（如数据的增删改查），将会导致数据不准确，相互之间产生冲突，因此加入同步锁以避免在该线程没有完成操作之前，被其他线程的调用，从而保证了该变量的唯一性和准确性。

1）同步方法

即有synchronized关键字修饰的方法。

由于java的每个对象都有一个内置锁，当用此关键字修饰方法时，内置锁会保护整个方法。在调用该方法前，需要获得内置锁，否则就处于阻塞状态。

代码如：public synchronized void save(){}

注： synchronized关键字也可以修饰静态方法，此时如果调用该静态方法，将会锁住整个类。

2）同步代码块 

即有synchronized关键字修饰的语句块。被该关键字修饰的语句块会自动被加上内置锁，从而实现同步。

代码如：

synchronized(object){}

注：同步是一种高开销的操作，因此应该尽量减少同步的内容。

通常没有必要同步整个方法，使用synchronized代码块同步关键代码即可。

 

这样也实现了线程同步，运行效率上来说也比方法同步效率高，同步是一种高开销的操作，因此应该尽量减少同步的内容。通常没有必要同步整个方法，使用synchronized代码块同步关键代码即可。

 

3）使用特殊域变量(volatile)实现线程同步

a. volatile关键字为域变量的访问提供了一种免锁机制。

b.使用volatile修饰域相当于告诉虚拟机该域可能会被其他线程更新。

c.因此每次使用该域就要重新计算，而不是使用寄存器中的值。

d. volatile不会提供任何原子操作，它也不能用来修饰final类型的变量。

volatile不能保证原子操作导致的，因此volatile不能代替synchronized。此外volatile会组织编译器对代码优化，因此能不使用它就不适用它吧。它的原理是每次要线程要访问volatile修饰的变量时都是从内存中读取，而不是存缓存当中读取，因此每个线程访问到的变量值都是一样的。这样就保证了同步。

4）使用重入锁实现线程同步

在JavaSE5.0中新增了一个java.util.concurrent包来支持同步。ReentrantLock类是可重入、互斥、实现了Lock接口的锁，它与使用synchronized方法和快具有相同的基本行为和语义，并且扩展了其能力。

ReenreantLock类的常用方法有：

  ReentrantLock() : 创建一个ReentrantLock实例 

  lock() : 获得锁 

  unlock() : 释放锁 

注：ReentrantLock()还有一个可以创建公平锁的构造方法，但由于能大幅度降低程序运行效率，不推荐使用。

注：关于Lock对象和synchronized关键字的选择：

a.最好两个都不用，使用一种java.util.concurrent包提供的机制，能够帮助用户处理所有与锁相关的代码。

b.如果synchronized关键字能满足用户的需求，就用synchronized，因为它能简化代码。

c.如果需要更高级的功能，就用ReentrantLock类，此时要注意及时释放锁，否则会出现死锁，通常在finally代码释放锁。

5）使用局部变量实现线程同步

如果使用ThreadLocal管理变量，则每一个使用该变量的线程都获得该变量的副本，副本之间相互独立，这样每一个线程都可以随意修改自己的变量副本，而不会对其他线程产生影响。现在明白了吧，原来每个线程运行的都是一个副本，也就是说存钱和取钱是两个账户，知识名字相同而已。所以就会发生上面的效果。

 

**ThreadLocal类的常用方法**

ThreadLocal() : 创建一个线程本地变量 

get() : 返回此线程局部变量的当前线程副本中的值 

initialValue() : 返回此线程局部变量的当前线程的"初始值" 

set(T value) : 将此线程局部变量的当前线程副本中的值设置为value

注：ThreadLocal与同步机制

a.ThreadLocal与同步机制都是为了解决多线程中相同变量的访问冲突问题。

b.前者采用以"空间换时间"的方法，后者采用以"时间换空间"的方式

 

## 15、什么是原子操作，Java中的原子操作是什么？

原子操作是不可分割的操作，一个原子操作中间是不会被其他线程打断的，所以不需要同步一个原子操作。

多个原子操作合并起来后就不是一个原子操作了，就需要同步了。

i++不是一个原子操作，它包含 读取-修改-写入 操作，在多线程状态下是不安全的。

另外，java内存模型允许将64位的读操作或写操作分解为2个32位的操作，所以对long和double类型的单次读写操作并不是原子的，注意使用volatile使他们成为原子操作。

 

## 16、什么是竞争条件(race condition)？你怎样发现和解决的？

竞争条件，在《java并发编程实战》叫做竞态条件：**指设备或系统出现不恰当的执行时序，而得到不正确的结果。**

 

在上述例子中，表现一种很常见的竞态条件类型:“先检查后执行”。根据某个检查结果来执行进一步的操作，但很有可能这个检查结果是失效的！还有很常见的竞态条件“**读取-修改-写入**”三连，在多线程条件下，三个小操作并不一定会放在一起执行的。

如何对待竞态条件？

首先，警惕复合操作，当多个原子操作合在一起的时候，并不一定仍然是一个原子操作，此时需要用**同步**的手段来保证原子性。

另外，使用本身是线程安全的类，这样在很大程度上避免了未知的风险。

 

 

## 17、java线程的生命周期

 

**新建状态（New）**：用new语句创建的线程处于新建状态，此时它和其他Java对象一样，仅仅在堆区中被分配了内存。

**就绪状态（Runnable）**：当一个线程对象创建后，其他线程调用它的start()方法，该线程就进入就绪状态，Java虚拟机会为它创建方法调用栈和程序计数器。处于这个状态的线程位于可运行池中，等待获得CPU的使用权。

**运行状态（Running）**：处于这个状态的线程占用CPU，执行程序代码。只有处于就绪状态的线程才有机会转到运行状态。

**阻塞状态（Blocked）**：阻塞状态是指线程因为某些原因放弃CPU，暂时停止运行。当线程处于阻塞状态时，Java虚拟机不会给线程分配CPU。直到线程重新进入就绪状态，它才有机会转到运行状态。

阻塞状态可分为以下3种： 

1）位于对象等待池中的阻塞状态（Blocked in object’s wait pool）：当线程处于运行状态时，如果执行了某个对象的wait()方法，Java虚拟机就会把线程放到这个对象的等待池中，这涉及到“线程通信”的内容。

2）位于对象锁池中的阻塞状态（Blocked in object’s lock pool）：当线程处于运行状态时，试图获得某个对象的同步锁时，如果该对象的同步锁已经被其他线程占用，Java虚拟机就会把这个线程放到这个对象的锁池中，这涉及到“线程同步”的内容。

3）其他阻塞状态（Otherwise Blocked）：当前线程执行了sleep()方法，或者调用了其他线程的join()方法，或者发出了I/O请求时，就会进入这个状态。

**死亡状态（Dead）**：当线程退出run()方法时，就进入死亡状态，该线程结束生命周期。

https://blog.csdn.net/justloveyou_/article/details/54347954

 

## 19、Java中你怎样唤醒一个阻塞的线程？

如果线程遇到了IO阻塞，我并且不认为有一种方法可以中止线程。如果线程因为调用wait()、sleep()、或者join()方法而导致的阻塞，你可以中断线程，并且通过抛出InterruptedException来唤醒它。

 

这个我们先简单粗暴地对某些阻塞方法进行分类： 

\- 会抛出InterruptedException的方法：wait、sleep、join、Lock.lockInterruptibly等，针对这类方法，我们在线程内部处理好异常(要不完全内部处理，要不把这个异常抛出去)，然后就可以实现唤醒。 

\- 不会抛InterruptedException的方法：Socket的I/O,同步I/O，Lock.lock等。对于I/O类型，我们可以关闭他们底层的通道，比如Socket的I/O，关闭底层套接字，然后抛出异常处理就好了;比如同步I/O，关闭底层Channel然后处理异常。对于Lock.lock方法，我们可以改造成Lock.lockInterruptibly方法去实现。

 

## 20、为什么wait(), notify()和notifyAll()必须在同步方法或者同步块中被调用？

wait/notify机制是依赖于Java中Synchronized同步机制的，其目的在于确保等待线程从Wait()返回时能够感知通知线程对共享变量所作出的修改。如果不在同步范围内使用，就会抛出java.lang.IllegalMonitorStateException的异常。

 

## 21、并发三准则

  异常不会导致死锁现象：当线程出现异常且没有捕获处理时，JVM会自动释放当前线程占用的锁，因此不会由于异常导致出现死锁现象，同时还会释放CPU；

  锁的是对象而非引用；

  有wait必有notify；

## 22、（Join、CountDownLatch、Sleep）主线程等待子线程运行完毕再运行的方法

(1)Join

  Thread提供了让一个线程等待另一个线程完成的方法 — join()方法。当在某个程序执行流程中调用其它线程的join()方法时，调用线程将被阻塞，直到被join()方法加入的join线程执行完毕为止，在继续运行。join()方法的实现原理是不停检查join线程是否存活，如果join线程存活则让当前线程永远等待。直到join线程完成后，线程的this.notifyAll()方法会被调用。

(2)CountDownLatch

  Countdown Latch允许一个或多个线程等待其他线程完成操作。CountDownLatch的构造函数接收一个int类型的参数作为计数器，如果你想等待N个点完成，这里就传入N。当我们调用countDown方法时，N就会减1，await方法会阻塞当前线程，直到N变成0。这里说的N个点，可以使用N个线程，也可以是1个线程里的N个执行步骤。

(3)Sleep

  用sleep方法，让主线程睡眠一段时间，当然这个睡眠时间是主观的时间，是我们自己定的，这个方法不推荐，但是在这里还是写一下，毕竟是解决方法。

## 23、什么是不可变对象，它对写并发应用有什么帮助？

另一个多线程经典面试问题，并不直接跟线程有关，但间接帮助很多。这个java面试问题可以变的非常棘手，如果他要求你写一个不可变对象，或者问你为什么String是不可变的。

 

immutable Objects(不可变对象)就是那些一旦被创建，它们的状态就不能被改变的Objects，每次对他们的改变都是产生了新的immutable的对象，而mutable Objects(可变对象)就是那些创建后，状态可以被改变的Objects.

 

如何在Java中写出Immutable的类？

\1. immutable对象的状态在创建之后就不能发生改变，任何对它的改变都应该产生一个新的对象。

\2. immutable类的所有的属性都应该是final的。 

\3. 对象必须被正确的创建，比如：对象引用在对象创建过程中不能泄露(leak)。 

\4. 对象应该是final的，以此来限制子类继承父类，以避免子类改变了父类的immutable特性。 

\5. 如果类中包含mutable类对象，那么返回给客户端的时候，返回该对象的一个拷贝，而不是该对象本身（该条可以归为第一条中的一个特例）

 

使用Immutable类的好处： 

\1. Immutable对象是**线程安全**的，可以不用被synchronize就在并发环境中共享

2.Immutable对象简化了程序开发，因为它**无需使用额外的锁机制**就可以在线程间共享

\3. Immutable对象提高了程序的性能，因为它减少了synchroinzed的使用 

\4. Immutable对象是可以被重复使用的，你可以将它们缓存起来重复使用，就像字符串字面量和整型数字一样。你可以使用静态工厂方法来提供类似于valueOf（）这样的方法，它可以从缓存中返回一个已经存在的Immutable对象，而不是重新创建一个。

 

## 24、ThreadLocal 内存泄漏

ThreadLocal是Java中的一种线程绑定机制，可以为每一个使用该变量的线程都提供一个变量值的副本，并且每一个线程都可以独立地改变自己的副本，而不会与其它线程的副本发生冲突。

每个线程内部有一个 ThreadLocal.ThreadLocalMap 类型的成员变量 threadLocals，这个 threadLocals 存储了与该线程相关的所有 ThreadLocal 变量及其对应的值，也就是说，ThreadLocal 变量及其对应的值就是该Map中的一个 Entry，更直白地，threadLocals中每个Entry的Key是ThreadLocal 变量本身，而Value是该ThreadLocal变量对应的值。

 

ThreadLocal可能引起的内存泄露，如ThreadLocalMap里面对Key的引用是弱引用。那么，就存在这样的情况：当释放掉对threadlocal对象的强引用后，map里面的value没有被回收，但却永远不会被访问到了，因此ThreadLocal存在着内存泄露问题。

看下面的图示， 实线代表强引用，虚线代表弱引用。每个thread中都存在一个map，map的类型是上文提到的ThreadLocal.ThreadLocalMap，该map中的key为一个ThreadLocal实例。这个Map的确使用了弱引用，不过弱引用只是针对key，每个key都弱引用指向ThreadLocal对象。一旦把threadlocal实例置为null以后，那么将没有任何强引用指向ThreadLocal对象，因此ThreadLocal对象将会被 Java GC 回收。但是，与之关联的value却不能回收，因为存在一条从current thread连接过来的强引用。 只有当前thread结束以后， current thread就不会存在栈中，强引用断开，Current Thread、Map及value将全部被Java GC回收。

 

## 25、死锁查看Java

  分析死锁，我们需要查看Java应用程序的线程转储。我们需要找出那些状态为BLOCKED的线程和他们等待的资源。每个资源都有一个唯一的id，用这个id我们可以找出哪些线程已经拥有了它的对象锁。下面列举了一些JDK自带的死锁检测工具：

(1)Jconsole：JDK自带的图形化界面工具，主要用于对 Java 应用程序做性能分析和调优。

(2)Jstack：JDK自带的命令行工具，主要用于线程Dump分析。

(3)VisualVM：JDK自带的图形化界面工具，主要用于对 Java 应用程序做性能分析和调优。

## 26、如何避免死锁？（JAVA）

\- 从死锁的四个必要条件来看，破坏其中的任意一个条件就可以避免死锁。但互斥条件是由资源本身决定的，不剥夺条件一般无法破坏，要实现的话得自己写更多的逻辑。

\- 避免无限期的等待：用Lock.tryLock(),wait/notify等方法写出请求一定时间后，放弃已经拥有的锁的程序。

\- 注意锁的顺序：以固定的顺序获取锁，可以避免死锁。

\- 开放调用：即只对有请求的进行封锁。你应当只想你要运行的资源获取封锁，比如在上述程序中我在封锁的完全的对象资源。但是如果我们只对它所属领域中的一个感兴趣，那我们应当封锁住那个特殊的领域而并非完全的对象。

\- 最后，如果能避免使用多个锁，甚至写出无锁的线程安全程序是再好不过了。

 

## 27、什么是Java内存模型？

Java内存模型描述了在多线程代码中哪些行为是合法的，以及线程如何通过内存进行交互。它描述了“程序中的变量” 和 “从内存或者寄存器获取或存储它们的底层细节”之间的关系。Java内存模型通过使用各种各样的硬件和编译器的优化来正确实现以上事情。

Java包含了几个语言级别的关键字，包括：volatile, final以及synchronized，目的是为了帮助程序员向编译器描述一个程序的并发需求。Java内存模型定义了volatile和synchronized的行为，更重要的是保证了同步的java程序在所有的处理器架构下面都能正确的运行。

“一个线程的写操作对其他线程可见”这个问题是因为编译器对代码进行重排序导致的。例如，只要代码移动不会改变程序的语义，当编译器认为程序中移动一个写操作到后面会更有效的时候，编译器就会对代码进行移动。如果编译器推迟执行一个操作，其他线程可能在这个操作执行完之前都不会看到该操作的结果，这反映了缓存的影响。

此外，写入内存的操作能够被移动到程序里更前的时候。在这种情况下，其他的线程在程序中可能看到一个比它实际发生更早的写操作。所有的这些灵活性的设计是为了通过给编译器，运行时或硬件灵活性使其能在最佳顺序的情况下来执行操作。在内存模型的限定之内，我们能够获取到更高的性能。

 

 

 

 

## 28、什么是同步容器和并发容器的实现？

一、同步容器（强一致性）

主要代表有Vector和Hashtable，以及Collections.synchronizedXxx等。锁的粒度为当前对象整体。迭代器是及时失败的，即在迭代的过程中发现被修改，就会抛出ConcurrentModificationException。

二、并发容器(弱一致性)

主要代表有ConcurrentHashMap、CopyOnWriteArrayList、ConcurrentSkipListMap、ConcurrentSkipListSet。锁的粒度是分散的、细粒度的，即读和写是使用不同的锁。迭代器具有弱一致性，即可以容忍并发修改，不会抛出ConcurrentModificationException。

JDK 7 ConcurrentHashMap

采用分离锁技术，同步容器中，是一个容器一个锁，但在ConcurrentHashMap中，会将hash表的数组部分分成若干段，每段维护一个锁，以达到高效的并发访问；

JDK 8 ConcurrentHashMap

采用分离锁技术，同步容器中，是一个容器一个锁，但在ConcurrentHashMap中，会将hash表的数组部分分成若干段，每段维护一个锁，以达到高效的并发访问；

三、阻塞队列

主要代表有LinkedBlockingQueue、ArrayBlockingQueue、PriorityBlockingQueue(Comparable,Comparator)、SynchronousQueue。提供了可阻塞的put和take方法，以及支持定时的offer和poll方法。适用于生产者、消费者模式（线程池和工作队列-Executor），同时也是同步容器

四、双端队列

主要代表有ArrayDeque和LinkedBlockingDeque。意义：正如阻塞队列适用于生产者消费者模式，双端队列同样适用与另一种模式，即工作密取。在生产者-消费者设计中，所有消费者共享一个工作队列，而在工作密取中，每个消费者都有各自的双端队列。如果一个消费者完成了自己双端队列中的全部工作，那么他就可以从其他消费者的双端队列末尾秘密的获取工作。具有更好的可伸缩性，这是因为工作者线程不会在单个共享的任务队列上发生竞争。在大多数时候，他们都只是访问自己的双端队列，从而极大的减少了竞争。当工作者线程需要访问另一个队列时，它会从队列的尾部而不是头部获取工作，因此进一步降低了队列上的竞争。适用于：网页爬虫等任务中

五、比较及适用场景

如果不需要阻塞队列，优先选择ConcurrentLinkedQueue；如果需要阻塞队列，队列大小固定优先选择ArrayBlockingQueue，队列大小不固定优先选择LinkedBlockingQueue；如果需要对队列进行排序，选择PriorityBlockingQueue；如果需要一个快速交换的队列，选择SynchronousQueue；如果需要对队列中的元素进行延时操作，则选择DelayQueue。

 

 

## 29、锁优化技术

锁优化技术的目的在于线程之间更高效的共享数据，解决竞争问题，更好提高程序执行效率。

 

自旋锁(上下文切换代价大)：互斥锁 -> 阻塞 –> 释放CPU，线程上下文切换代价较大 + 共享变量的锁定时间较短 == 让线程通过自旋等一会儿，自旋锁

 

锁粗化(一个大锁优于若干小锁)：一系列连续操作对同一对象的反复频繁加锁/解锁会导致不必要的性能损耗，建议粗化锁 

一般而言，同步范围越小越好，这样便于其他线程尽快拿到锁，但仍然存在特例。

 

偏向锁(有锁但当前情形不存在竞争)：消除数据在无竞争情况下的同步原语，提高带有同步但无竞争的程序性能。

 

锁消除(有锁但不存在竞争，锁多余)：JVM编译优化，将不存在数据竞争的锁消除

## 30、Java中使用什么线程调度算法？

抢占式。一个线程用完CPU之后，操作系统会根据线程优先级、线程饥饿情况等数据算出一个总的优先级并分配下一个时间片给某个线程执行。

## 31、Java中线程调度是什么？

计算机通常只有一个CPU,在任意时刻只能执行一条机器指令，每个线程只有获得CPU的使用权才能执行指令。所谓多线程的并发运行，其实是从宏观上看，各个线程轮流获得CPU的使用权才能执行指令，分别执行各自的任务。在可运行池中，会有多个处于就绪态的线程在等待CPU，Java虚拟机的一项任务就是负责线程的调度。线程的调度是指按照特定的机制为多个线程分配CPU的使用权。有两种调度模型：分时调度模型和抢占式调度模型

分时调度模型是指让所有线程轮流获得CPU的使用权，并且平均分配每个线程占用CPU的时间片。

Java虚拟机采用抢占式调度模型，是指优先让可运行池中处于就绪态的线程中优先级高的占用CPU,如果可运行池中线程的优先级相同，那么就随机选择一个线程，使其占用CPU，处于运行状态的线程会一直执行，直至它不得不放弃CPU，一个线程会因为以下原因放弃CPU:

(1)Java虚拟机让当前线程暂时放弃CPU，转到就绪态，使其他线程获得运行机会

(2)当前线程因为某些原因而处于阻塞状态

(3)线程运行结束

值得注意的是，线程的调度不是跨平台的，它不仅取决于Java虚拟机，还依赖于操作系统。在某些操作系统中，即使运行中的线程没有遇到阻塞，也会在运行一段时间后放弃CPU，给其他线程运行的机会。

java线程的调度不是分时的，同时启动多个线程后，不能保证各个线程轮流获得均等的时间片

 

1.调整各个线程的优先级

所有处于就绪状态的线程根据优先级存放在可运行池中，优先级低的线程获得较少的运行机会，优先级高的获得较多的运行机会。Thread类的setPriority(int)和getPriority()方法用于设置和读取优先级。优先级用整数表示，取值范围时1-10，Thread类有以下三个静态常量。

MAX_PRIORITY:取值是10，表示最高优先级

MIN_PRIORITY:取值是1，表示最低优先级

DEFAULT_PRIORITY:取值是5，表示默认优先级

每个线程都有其优先级。主线程的默认优先级是Thread.DEFAULT_PRIORITY。如果线程A创建了线程B，那么线程B就和线程A具有同样的优先级

***值得注意的是，尽管Java提供了10个优先级，但它与多数操作系统都不能很好的映射。比如windows2000有7个优先级，并且不是固定的，而sun公司的Solaris操作系统有2^31个优先级。如果希望程序能移植到各个操作系统中，应该确保在设置线程的优先级时，只使用MIN_PRIORITY,DEAULT_PRIORITY,MAX_PRIORITY这三个优先级。这样才能保证在不同的操作系统中，对同样优先级的线程采用同样的调度方式

2.线程睡眠:Thread.sleep()方法

当一个线程在运行中sleep()方法，它就会放弃cpu，转到阻塞状态。Thread类的sleep(longmillis)方法是静态的，millis参数设置睡眠的时间，单位是毫秒。

**假如线程1线程进入睡眠，线程2获得cpu，当线程1结束睡眠后，后先进入就绪状态，假如线程2正在运行，线程1并不一定会立即执行，而是在可运行池中等待获取CPU

3.线程让步：Thread.yield()方法

当线程在运行中执行了Thread类的yield()静态方法时，如果此时具有相同优先级的其他线程处于就绪状态，那么yield()方法将把当前运行的线程放到可运行池中并使另一个线程运行。如果没有相同优先级的可运行进程，则yield()方法什么也不做

sleep()方法和yield()方法都是Thread类的静态方法，都会使当前处于运行状态的线程放弃CPU,把运行机会让给别的线程。两者的区别在于:

(1)sleep()方法会给其他线程运行的机会，而不考虑其他线程的优先级，因此会给较低优先级线程一个运行的机会；yield()方法只会给相同优先级或者更高优先级的线程一个运行的机会

(2)当线程执行sleep(longmillis)方法后，将转到阻塞状态，参数millis制定睡眠时间;当线程执行yield()方法后，将转到就绪状态

(3)sleep()方法声明抛出InterruptedException异常，而yield()方法没有声明抛出任何异常

(4)sleep()方法比yield()方法具有更好的可移植性。不能依靠yield()方法来提高程序的并发性能。对于大多数程序员来说，yield()方法的唯一用途是在测试期间人为地提高程序的并发性能，以帮助发现一些隐藏的错误。

4.等待其他线程结束:join()

当前运行的线程可以调用另一个线程的join()方法,当前运行的线程将转到阻塞状态，直至另一个线程运行结束，它才会恢复运行(阻塞恢复到就绪)

 

## 32、什么是线程组？为什么Java中不建议使用线程组？

**线程组**：线程组存在的意义，首要原因是安全。java默认创建的线程都是属于系统线程组，而同一个线程组的线程是可以相互修改对方的数据的。但如果在不同的线程组中，那么就不能“跨线程组”修改数据，可以从一定程度上保证数据安全。

 

**线程池**：线程池存在的意义，首要作用是效率。线程的创建和结束都需要耗费一定的系统时间（特别是创建），不停创建和删除线程会浪费大量的时间。所以，在创建出一条线程并使其在执行完任务后不结束，而是使其进入休眠状态，在需要用时再唤醒，那么 就可以节省一定的时间。如果这样的线程比较多，那么就可以使用线程池来进行管理。保证效率。

 

**线程组和线程池共有的特点**：1,都是管理一定数量的线程2,都可以对线程进行控制---包括休眠，唤醒，结束，创建，中断（暂停）--但并不一定包含全部这些操作。

 

Java为什么不推荐使用线程组？

线程组里的stop, resume, suspend方法，会直接调用thread的这三个方法，而这三个方法存在死锁的问题。因此，这些管理类方法，基本无法使用。

线程组ThreadGroup不是线程安全的，在使用过程中不能及时获取安全的信息。

## 33、线程中如何处理某个未处理异常？

线程异常处理流程

ThreadGrop类实现了Thread.UncaughtExceptionHandler接口，所以每个线程所属的线程组将会作为默认异常处理器

当一个线程抛出一个未处理异常时： 

JVM会首先查找该异常对应的异常处理器，如果找到，则调用异常处理器处理异常；否则,JVM会调用该线程所属的线程组对象的uncaughtException()来处理该异常。

线程组异常处理流程

（1）如果该线程组有父线程组，则调用父线程组的uncaughtException()来处理异常 

（2）如果该线程对象所属线程类有有默认异常处理器，南无就调用该异常处理器来处理该异常

（3）如果该异常对象是ThreadDeath的对象，则不做任何处理；否则，将异常跟踪栈的信息打印到System.err错误输出流，并结束该线程

 

## 34、为什么使用Executor框架比直接创建线程要好？

Executor框架是基于线程池的，可以实现线程的总量控制和重用。直接使用线程有可能会耗尽系统的线程资源，因为Java的线程一般都是直接对应操作系统的基础设施的。

 

## 35、Java中Executor和Executors的区别？

https://www.cnblogs.com/love-Stefanie/p/6728228.html

 

## 36、你将如何使用thread dump？你将如何分析Thread dump

在UNIX中你可以使用kill -3，然后thread dump将会打印日志，在windows中你可以使用”CTRL+Break”。

SIGQUIT（kill -3 pid）用来打印Java进程trace，并不会影响程序运行，不用担心他把程序杀死了；SIGUSR1（kill -10 pid）可触发进程进行一次强制GC。

 

## 37、synchronized和ReentrantLock 

java在编写多线程程序时，为了保证线程安全，需要对数据同步，经常用到两种同步方式就是Synchronized和重入锁ReentrantLock。

 

基础知识

可重入锁。可重入锁是指同一个线程可以多次获取同一把锁。ReentrantLock和synchronized都是可重入锁。

可中断锁。可中断锁是指线程尝试获取锁的过程中，是否可以响应中断。synchronized是不可中断锁，而ReentrantLock则提供了中断功能。

公平锁与非公平锁。公平锁是指多个线程同时尝试获取同一把锁时，获取锁的顺序按照线程达到的顺序，而非公平锁则允许线程“插队”。synchronized是非公平锁，而ReentrantLock的默认实现是非公平锁，但是也可以设置为公平锁。

CAS操作(CompareAndSwap)。CAS操作简单的说就是比较并交换。CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。如果内存位置的值与预期原值相匹配，那么处理器会自动将该位置值更新为新值。否则，处理器不做任何操作。无论哪种情况，它都会在 CAS 指令之前返回该位置的值。CAS 有效地说明了“我认为位置 V 应该包含值 A；如果包含该值，则将 B 放到这个位置；否则，不要更改该位置，只告诉我这个位置现在的值即可。”

 

Synchronized

synchronized是java内置的关键字，它提供了一种独占的加锁方式。synchronized的获取和释放锁由JVM实现，用户不需要显示的释放锁，非常方便。然而synchronized也有一定的局限性

例如：

当线程尝试获取锁的时候，如果获取不到锁会一直阻塞。

如果获取锁的线程进入休眠或者阻塞，除非当前线程异常，否则其他线程尝试获取锁必须一直等待。

 

ReentrantLock

ReentrantLock它是JDK 1.5之后提供的API层面的互斥锁，需要lock()和unlock()方法配合try/finally语句块来完成。

 

ReenTrantLock实现的原理：

简单来说，ReenTrantLock的实现是一种自旋锁，通过循环调用CAS操作来实现加锁。它的性能比较好也是因为避免了使线程进入内核态的阻塞状态。想尽办法避免线程进入内核的阻塞状态是我们去分析和理解锁设计的关键钥匙。

 

 

## 38、ConcurrentHashMap的并发度是什么？

ConcurrentHashMap的并发度就是segment的大小，默认为16，这意味着最多同时可以有16条线程操作ConcurrentHashMap，这也是ConcurrentHashMap对Hashtable的最大优势

 

## 39、ReentrantReadWriteLock读写锁的使用

Lock比传统线程模型中的synchronized方式更加面向对象，与生活中的锁类似，锁本身也应该是一个对象。两个线程执行的代码片段要实现同步互斥的效果，它们必须用同一个Lock对象。

读写锁：分为读锁和写锁，多个读锁不互斥，读锁与写锁互斥，这是由jvm自己控制的，你只要上好相应的锁即可。如果你的代码只读数据，可以很多人同时读，但不能同时写，那就上读锁；

如果你的代码修改数据，只能有一个人在写，且不能同时读取，那就上写锁。总之，读的时候上读锁，写的时候上写锁！

 

ReentrantReadWriteLock会使用两把锁来解决问题，一个读锁，一个写锁

 

线程进入读锁的前提条件：

 

没有其他线程的写锁

没有写请求或者有写请求，但调用线程和持有锁的线程是同一个

线程进入写锁的前提条件：

 

没有其他线程的读锁

没有其他线程的写锁

读锁的重入是允许多个申请读操作的线程的，而写锁同时只允许单个线程占有，该线程的写操作可以重入。

如果一个线程占有了写锁，在不释放写锁的情况下，它还能占有读锁，即写锁降级为读锁。

对于同时占有读锁和写锁的线程，如果完全释放了写锁，那么它就完全转换成了读锁，以后的写操作无法重入，在写锁未完全释放时写操作是可以重入的。

公平模式下无论读锁还是写锁的申请都必须按照AQS锁等待队列先进先出的顺序。非公平模式下读操作插队的条件是锁等待队列head节点后的下一个节点是SHARED型节点，写锁则无条件插队。

读锁不允许newConditon获取Condition接口，而写锁的newCondition接口实现方法同ReentrantLock。

 

其它问题：

https://blog.csdn.net/cmyperson/article/details/79610870

 

 

 

 

 

 

## 40、CycliBarriar和CountdownLatch

这个线程问题主要用来检测你是否熟悉JDK5中的并发包。这两个的区别是CyclicBarrier**可以重复使用已经通过的障碍**，而CountdownLatch不能重复使用。

 

还要注意一点的区别： 

CountDownLatch : 一个线程(或者多个)， 等待另外N个线程完成某个事情之后才能执行。

CyclicBarrier : N个线程相互等待，任何一个线程完成之前，所有的线程都必须等待。

这样应该就清楚一点了，对于CountDownLatch来说，重点是那个“一个线程”,是它在等待，而另外那N的线程在把“某个事情”做完之后可以继续等待，可以终止。而对于CyclicBarrier来说，重点是那N个线程，他们之间任何一个没有完成，所有的线程都必须等待。

从api上理解就是CountdownLatch有主要配合使用两个方法countDown()和await()，countDown()是做事的线程用的方法，await()是等待事情完成的线程用个方法，这两种线程是可以分开的(下面例子:CountdownLatchTest2)，当然也可以是同一组线程(下面例子:CountdownLatchTest);CyclicBarrier只有一个方法await(),指的是做事线程必须大家同时等待，必须是同一组线程的工作。

 

## 41、在Windows和Linux系统上分别如何找到占用CPU最多的线程？

 

 

## 42、Java中绿色线程和本地线程的区别？

Java绿色线程（Green Thread）是一个相对于操作系统线程（Native Thread）的概念 。

操作系统线程（Native Thread）的意思就是，程序里面的线程会真正映射到操作系统的线程，线程的运行和调度都是由操作系统控制的

Java绿色线程（Green Thread）的意思是，程序里面的线程不会真正映射到操作系统的线程，而是由语言运行平台自身来调度 。

当前版本的Python语言的线程就可以映射到操作系统线程 。当前版本的Ruby语言的线程就属于绿色线程，无法映射到操作系统的线程，因此Ruby语言的线程的运行速度比较慢。

## 43、Hashtable的size()方法中明明只有一条语句”return count”，为什么还要做同步？

同一时间只能有一条线程执行固定类的同步方法，但是对于类的非同步方法，可以多条线程同时访问。所以，这样就有问题了，可能线程A在执行Hashtable的put方法添加数据，线程B则可以正常调用size()方法读取Hashtable中当前元素的个数，那读取到的值可能不是最新的，可能线程A添加了完了数据，但是没有对size++，线程B就已经读取size了，那么对于线程B来说读取到的size一定是不准确的。

而给size()方法加了同步之后，意味着线程B调用size()方法只有在线程A调用put方法完毕之后才可以调用，这样就保证了线程安全性

 

## 44、你在多线程环境中遇到的常见的问题是什么？你是怎么解决它的？

多线程和并发程序中常遇到的有Memory-interface、竞争条件、死锁、活锁和饥饿。问题是没有止境的，如果你弄错了，将很难发现和调试。这是大多数基于面试的，而不是基于实际应用的Java线程问题。

## 45、现在有线程 T1、T2 和 T3。你如何确保 T2 线程在 T1 之后执行，并且 T3 线程在 T2 之后执行？（JOIN）

这个线程面试题通常在第一轮面试或电话面试时被问到，这道多线程问题为了测试面试者是否熟悉 join 方法的概念。答案也非常简单——可以用 Thread 类的 join 方法实现这一效果。

 

Thread类中的join方法的主要作用就是同步，它可以使得线程之间的并行执行变为串行执行。

 

Join方法实现是通过wait（小提示：Object 提供的方法）。当main线程调用t.join时候，main线程会获得线程对象t的锁（wait 意味着拿到该对象的锁),调用该对象的wait(等待时间)，直到该对象唤醒main线程，比如退出后。这就意味着main 线程调用t.join时，必须能够拿到线程t对象的锁。

# 算法

## 1.  搜索算法

DFS BFS

https://blog.csdn.net/zt_xcyk/article/details/72809865

 

## 2.  排序算法

七大排序（学会希尔和堆排序）：https://visualgo.net/zh

 

## 3.  最短路径算法

 

 

## 4.  A*启发式搜索算法

 

## 5.  最长公共子序列（LCS）与最长公共子串（DP）

 

 

 

## 6、最小生成树（Kruskal和Prim）

https://blog.csdn.net/lxt_lucia/article/details/80543002

 

# 海量数据

## Bitmap

介绍

位图的基本概念是用一个位（bit）来标记某个数据的存放状态，由于采用了位为单位来存放数据，所以节省了大量的空间。举个具体的例子，在Java中一般一个int数字要占用32位，如果能用一位就表示这个数，就可以缩减大量的存储空间。一般把这种方法称为位图法，即Bitmap。

 

BitSet：正因为位图运算在空间方面的优越性，很多语言都有直接对它的支持。如在C++的STL库中就有一个bitset容器。而在Java中，在java.util包下也有一个BitSet类用来实现位图运算。此类实现了一个按需增长的位向量。BitSet的每一位都由一个boolean值来表示。用非负的整数将BitSet的位编入索引，可以对每个编入索引的位进行测试、设置或者清除。通过逻辑与、逻辑或和逻辑异或操作，可以使用一个BitSet修改另一个BitSet的内容。

 

需要注意的是BitSet底层实现是通过一个long数组来保存数据的，也就是说它增长的最小单位是一个long所占的逻辑位，即64位。但如果不是对存储区空间有极致的要求，而且对自己的基本功非常有信心，不建议自己去实现一个跟BitSet类似的类来实现相关的功能。

 

Bitmap适用于数据规模大，但数据状态少的情况。同时Bitmap在存在以下一些不足：

存储离散数据利用率低：Bitmap申请空间时要根据最大的数来决定申请的空间大小，如果数据是离散的，那空间的利用率就会非常低。

不适合多状态：一个bit只能表示两种状态，如果要表示更多的状态，就需要更多的状态位来实现。如果一个数字需要多个状态位来表示的话，Bitmap的优越性也会大打折扣，而且复杂度却在增加。

可读性差：将数据抽象为bit不利于理解，尤其是用多个bit位来表示一个数时。

性能一般：需要维护额外的逻辑，计算速度会受到一定的影响。

 

典型应用

### 海量数据排序

从最简单的情况说起，如果要对90个小于100的不重复的正整数排序。用位图的思想就是先申请一块100bit的空间，第一遍遍历所有的数，将出现的数字在位图中对应的位置置为1；第二遍遍历位图，依次输出值为1的位对应的数字。先且不说这种情况出现的频率不是很高，就仅这种情况，还是有很多其他的排序算法有它们自己的优势（不用额外占用空间之类）。但更进一步，如果我们把数字范围放大，对1000,000,000中的900,000,000个不重复的正整数排序，由于需要的内存非常大，其他算法在不分治的情况下就很难再处理这个问题。而用位图法只需要1000000000/(8*1024*104)=119.2MB空间，对现在的计算机来说没有任何问题。

 

### 海量数据去重（在2.5亿个整数中找出不重复的整数）

看一个比较常见的面试题：在2.5亿个整数中找出不重复的整数，内存不足以放下算有的数。我们可以采用两位的位图法，为每个数分配两位，00表示没有出现，01表示出现一次，10表示出现多次，11没有意义。这样下来总共需要232∗2=1232∗2=1GB(这里没有限定整数的范围，所有把所有32位整数都考虑进去)的内存。接下去扫描着2.5亿个整数，查看位图中相对应的位，如果是00就变为01，如果是01就变为10，其他情况保持不变。扫描完成后仍为01的整数就是需要查找的数。

 

### 数据压缩

假设有这样一份数据，记录了全国1990-1999年出生的人的姓名和出生年月的键值对。假设正好有一千万人，那就要存储一千万个姓名和年份。如何运用Bitmap的思想来压缩数据呢。下面提供几种思路。

 

从人的角度来看，由于一共就只有10个年份，可以用4个bit将它们区分开。如0000表示1990年，1001表示1999年。那一个人的出生年份就可以用4个bit位来表示，进而一千万个年份就可以压缩为一千万个4位的bit组；从另一个角度来看这个问题，我们有10个年份，每个人要么是要么不是在这个年份出生。每个人对于年份来说就可以抽象为一个bit位，所以我们可以把一千万的年龄压缩为10个一千万位的bit组。这样压缩的力度不如按人的角度压缩的大，但从年份出发的问题会有一定的优势，如有哪些人是1990年出生的，只需遍历1990年对应的那个bit组就可以了。

 

可以看出来不管从哪个角度，bitmap的压缩都是建立在数据中存在大量的冗余数据的基础上的，如年份。而在上面的问题中，年份的分布是散乱的，那假如我们事先把数据进行了排序，把相同的出生年份的人排在一起，那数据就可以进一步压缩。这样一来就只要记录每个年份的人数，就可以根据下标来判断每个人的出生年份。

 

## 10亿个数中找出最大的10000个数（top K问题）

先拿10000个数建堆，然后一次添加剩余元素，如果大于堆顶的数（10000中最小的），将这个数替换堆顶，并调整结构使之仍然是一个最小堆，这样，遍历完后，堆中的10000个数就是所需的最大的10000个。建堆时间复杂度是O（mlogm），算法的时间复杂度为O（nmlogm）（n为10亿，m为10000）。

 

优化的方法：可以把所有10亿个数据分组存放，比如分别放在1000个文件中。这样处理就可以分别在每个文件的10^6个数据中找出最大的10000个数，合并到一起在再找出最终的结果。

 

 

## 有1亿个浮点数，如果找出期中最大的10000个？

最容易想到的方法是将数据全部排序，然后在排序后的集合中进行查找，最快的排序算法的时间复杂度一般为O（nlogn），如快速排序。但是在32位的机器上，每个float类型占4个字节，1亿个浮点数就要占用400MB的存储空间，对于一些可用内存小于400M的计算机而言，很显然是不能一次将全部数据读入内存进行排序的。其实即使内存能够满足要求（我机器内存都是8GB），该方法也并不高效，因为题目的目的是寻找出最大的10000个数即可，而排序却是将所有的元素都排序了，做了很多的无用功。

 

第二种方法为局部淘汰法，该方法与排序方法类似，用一个容器保存前10000个数，然后将剩余的所有数字——与容器内的最小数字相比，如果所有后续的元素都比容器内的10000个数还小，那么容器内这个10000个数就是最大10000个数。如果某一后续元素比容器内最小数字大，则删掉容器内最小元素，并将该元素插入容器，最后遍历完这1亿个数，得到的结果容器中保存的数即为最终结果了。此时的时间复杂度为O（n+m^2），其中m为容器的大小，即10000。

 

第三种方法是分治法，将1亿个数据分成100份，每份100万个数据，找到每份数据中最大的10000个，最后在剩下的100*10000个数据里面找出最大的10000个。如果100万数据选择足够理想，那么可以过滤掉1亿数据里面99%的数据。100万个数据里面查找最大的10000个数据的方法如下：用快速排序的方法，将数据分为2堆，如果大的那堆个数N大于10000个，继续对大堆快速排序一次分成2堆，如果大的那堆个数N大于10000个，继续对大堆快速排序一次分成2堆，如果大堆个数N小于10000个，就在小的那堆里面快速排序一次，找第10000-n大的数字；递归以上过程，就可以找到第1w大的数。参考上面的找出第1w大数字，就可以类似的方法找到前10000大数字了。此种方法需要每次的内存空间为10^6*4=4MB，一共需要101次这样的比较。

 

第四种方法是Hash法。如果这1亿个书里面有很多重复的数，先通过Hash法，把这1亿个数字去重复，这样如果重复率很高的话，会减少很大的内存用量，从而缩小运算空间，然后通过分治法或最小堆法查找最大的10000个数。

 

第五种方法采用最小堆。首先读入前10000个数来创建大小为10000的最小堆，建堆的时间复杂度为O（mlogm）（m为数组的大小即为10000），然后遍历后续的数字，并于堆顶（最小）数字进行比较。如果比最小的数小，则继续读取后续数字；如果比堆顶数字大，则替换堆顶元素并重新调整堆为最小堆。整个过程直至1亿个数全部遍历完为止。然后按照中序遍历的方式输出当前堆中的所有10000个数字。该算法的时间复杂度为O（nmlogm），空间复杂度是10000（常数）。

 

实际运行：

实际上，最优的解决方案应该是最符合实际设计需求的方案，在时间应用中，可能有足够大的内存，那么直接将数据扔到内存中一次性处理即可，也可能机器有多个核，这样可以采用多线程处理整个数据集。

 

下面针对不容的应用场景，分析了适合相应应用场景的解决方案。

（1）单机+单核+足够大内存

  如果需要查找10亿个查询次（每个占8B）中出现频率最高的10个，考虑到每个查询词占8B，则10亿个查询次所需的内存大约是10^9 * 8B=8GB内存。如果有这么大内存，直接在内存中对查询次进行排序，顺序遍历找出10个出现频率最大的即可。这种方法简单快速，使用。然后，也可以先用HashMap求出每个词出现的频率，然后求出频率最大的10个词。

（2）单机+多核+足够大内存

  这时可以直接在内存总使用Hash方法将数据划分成n个partition，每个partition交给一个线程处理，线程的处理逻辑同（1）类似，最后一个线程将结果归并。

  该方法存在一个瓶颈会明显影响效率，即数据倾斜。每个线程的处理速度可能不同，快的线程需要等待慢的线程，最终的处理速度取决于慢的线程。而针对此问题，解决的方法是，将数据划分成c×n个partition（c>1），每个线程处理完当前partition后主动取下一个partition继续处理，知道所有数据处理完毕，最后由一个线程进行归并。

（3）单机+单核+受限内存

  这种情况下，需要将原数据文件切割成一个一个小文件，如次啊用hash(x)%M，将原文件中的数据切割成M小文件，如果小文件仍大于内存大小，继续采用Hash的方法对数据文件进行分割，知道每个小文件小于内存大小，这样每个文件可放到内存中处理。采用（1）的方法依次处理每个小文件。

（4）多机+受限内存

  这种情况，为了合理利用多台机器的资源，可将数据分发到多台机器上，每台机器采用（3）中的策略解决本地的数据。可采用hash+socket方法进行数据分发。

  从实际应用的角度考虑，（1）（2）（3）（4）方案并不可行，因为在大规模数据处理环境下，作业效率并不是首要考虑的问题，算法的扩展性和容错性才是首要考虑的。算法应该具有良好的扩展性，以便数据量进一步加大（随着业务的发展，数据量加大是必然的）时，在不修改算法框架的前提下，可达到近似的线性比；算法应该具有容错性，即当前某个文件处理失败后，能自动将其交给另外一个线程继续处理，而不是从头开始处理。

 

top K问题很适合采用MapReduce框架解决，用户只需编写一个Map函数和两个Reduce 函数，然后提交到Hadoop（采用Mapchain和Reducechain）上即可解决该问题。具体而言，就是首先根据数据值或者把数据hash(MD5)后的值按照范围划分到不同的机器上，最好可以让数据划分后一次读入内存，这样不同的机器负责处理不同的数值范围，实际上就是Map。得到结果后，各个机器只需拿出各自出现次数最多的前N个数据，然后汇总，选出所有的数据中出现次数最多的前N个数据，这实际上就是Reduce过程。对于Map函数，采用Hash算法，将Hash值相同的数据交给同一个Reduce task；对于第一个Reduce函数，采用HashMap统计出每个词出现的频率，对于第二个Reduce 函数，统计所有Reduce task，输出数据中的top K即可。

 

直接将数据均分到不同的机器上进行处理是无法得到正确的结果的。因为一个数据可能被均分到不同的机器上，而另一个则可能完全聚集到一个机器上，同时还可能存在具有相同数目的数据。

 

 

 

 

## top K问题

  在大规模数据处理中，经常会遇到的一类问题：在海量数据中找出出现频率最好的前k个数，或者从海量数据中找出最大的前k个数，这类问题通常被称为top K问题。例如，在搜索引擎中，统计搜索最热门的10个查询词；在歌曲库中统计下载最高的前10首歌等。

  针对top K类问题，通常比较好的方案是分治+Trie树/hash+小顶堆（就是上面提到的最小堆），即先将数据集按照Hash方法分解成多个小数据集，然后使用Trie树活着Hash统计每个小数据集中的query词频，之后用小顶堆求出每个数据集中出现频率最高的前K个数，最后在所有top K中求出最终的top K。

 

### 提取某日访问网站次数最多的那个IP。

给一个超过100G大小的 log file，log中存着IP地址，设计算法找出出现次数最多的IP地址？ 

由于超过100G，那必须对文件进行切分。 

(1)切分，可以切成100份，每份有1G，那哈希表的大小就是100，利用字符串哈希算法将字符串IP转换成整型

(2)哈希切分，同一个ip就会分割到同一个文件。

(3)是依次将这100个文件读入内存中，统计ip出现的次数，依次进行比较，找出出现次数最多的ip. 

用到哈希切分，就有可能出现冲突，若某个文件冲突太多，可以将这个文件在再进行哈希切分。

### 与上题条件相同，如何找到 top K的IP？ 

(1)哈希切分后，同一个ip被分割到一个文件，依次统计次数。这里要求它的top k，很直接就想到用堆（key/value)来实现。

(2)需要建一个大小为k(key/value)的小堆。建小堆。堆顶是最小的，每次取一个数与堆顶比较，比堆顶小就不交换，大交换，然后进行依次向小调整又成小堆，就这样重复。完成后，这个堆就是top k。

 

 

## 10亿个整数找出重复次数最多的100个整数。

要解答这个问题，首先要弄清楚下面几个条件。 

（1）有内存限制吗？

（2）整数的范围是多少？有符号，无符号，32位还是64位？ 

（3）整数集的内容大吗？（即出现的整数空间的大小大吗？） 

（4）如果只需要求模糊解，怎么解？ 

（5）求数组中的第k大元素？

（6）相关问题：求一个整数列中出现次数最多的整数

（7）相关问题：有一个整数数组，请求出两两之差绝对值最小的值,记住，只要得出最小值即可，不需要求出是哪两个数。

 

（1）如果没有内存限制，且假设是32位无符号的整数。最方便的办法就是建立一个整形数组，int hash[2^32]（暂不考虑程序的虚地址空间上限），然后对这10亿个数进行一次遍历，这样，可以得到这2^32个数各自出现的次数，再对这个hash数组进行取第k大元素，100次后，就可以取出这出现次数最多的前100个数。遍历10亿个数的时间复杂度是O(n)，n=10^10，求第k大元素的时间复杂度是O(m)，m=2^32(=4294967296)，那么本算法的时间复杂度是O(n)，空间复杂度是O(s)，s=2^32。内存要2^32*4=16G (每个整型占4byte)

（2）如果有内存限制，或者必须满足程序虚地址空间上限。那么可以对整数空间进行分段处理，比如只提供512M内存，则将2^32个整数划分成32个空间0~2^(27)-1，2^(27)~2^(28)-1，...，31*2^(27)~2^(32)-1。对原来的10亿个数遍历32次，每次遍历，得到每个空间的整数的出现次数，并求出此空间中，出现次数最多的前100个整数，保存下来。这样32次之后，就得到了出现次数前3200的整数，再对这3200个整数取第k大元素，得到出现次数最多的前100个整数。这个算法的时间复杂度也是O(n)，空间复杂度降低多少不知道，但是内存使用降低不少。

（3）如果整数空间比较小，也就是说这10亿个数中有很多重复的数，最方便的办法估计就是维护一个HashTable对象ht，key就是整数值，value就是该整数值出现的次数。遍历这10亿个元素，得到ht后再对这个ht求第k大元素。那么这个算法的时间复杂度就是O(n)，n=10^10，空间复杂度是O(m)，m为整数空间大小。

（4）随机采样（或者将原来的顺序打乱，然后再顺序采样）。对样本中的整数进行出现次数的统计，这个时候采用HashTable的办法最好，时间复杂度是O(n)。如果对使用的空间有所限制，那么只能对该样本进行排序，再对排序后的样本进行100次遍历得到出现次数最多的前100个整数，则时间复杂度是O(nlogn)，空间复杂度是O(1)。 

（5）好像有两种算法。假设要求数组a[1...n]中第k大元素。

  （a）递归快排算法。若n<44（经验值）则直接排序返回第k大元素，否则，将1到n分成n/5个组，每个组5个元素，然后求这n/5个组的每组的中项元素，再求这n/5个中项元素的中项元素mm（注意，这里也可以用递归调用自身的方法）。然后对数组a根据mm分成三组，a1中的所有元素小于mm，a2中的所有元素等于mm，a3中的所有元素大于mm，如果|a1|>=k，则第k大元素在a1中，如果|a1|+|a2|>=k|a1|,则第k大元素就是mm，如果k>|a1|+|a2|，则第k大元素在a3中，再继续递归调用。这个算法的时间复杂度是O(n)。（注意，这里的中项mm也可以随机选择a中的元素，其时间复杂度也近似于O(n)，而且系数也比较小）。 

  （b）基于位查找（仅对于无符号整数的查找）。将32位整数的二进制位分为4段，每段8位，先比较a中所有元素高8位，找出第k大元素高8位的范围，再对应这高8位的范围在次高八位中找第k大元素的范围，...这样4次之后就可以找到第k大元素的。可以举个例子便于理解，在10个3位整数中找第k大元素，将3位分成3段，每段1位，每位之可能是0，1。如果这10个数的最高位0的个数m大于等于k，则第k大元素的最高位为0，再在最高位为0的元素中找次高位为第k大元素；如果10个数中最高位0的个数m大于k，则在最高位为1的元素中找此高位为第m-k大元素。... 

  （6）这个问题是前面那个问题的特例。有没有特殊的解法使效率又提高一些呢？我觉得没有，因为1和100本来就是常数级，和n比它们的差别是忽略不计的。 

  （7）简单的解法是对这个数组排序，然后再对排好序的数组进行一次遍历就可得到两两绝对值最差的最小值，时间复杂度是O(nlogn)。网上说求a的min，max和长度n，如果Dmax = (max-min+1)/n = 0，那么就说明数组a中有重复的元素，直接返回0。但是如果Dmax = (max-min+1)/n > 0,那么就以Dmax为箱的长度装入a的元素，再在箱内和箱间比较。我不懂为什么，但是这个空间复杂度是O(max)，而且好像如果a是1, 2, 3...100，那么Dmax就是1了，那么a不是没有动吗？还有人说够找数组b，b[i] = a[i] - a[i+1]，则a[i]-a[j]=b[i]+b[i+1]+...+b[j-1]也不知下文了，看来这个题比较搞啊。

 

## 有10个文件，每个文件1GB，每个文件的每一行存放的都是用户的query，每个文件的query都可能重复。按照query的频度排序。

将所有查询进行hash(query)%10，映射成新的10个文件，大约每个1GB。对每个文件使用hash_map统计频率并排序，然后对10个结果再归并排序。

 

方案1：

1)顺序读取10个文件，按照hash(query)的结果将query写入到另外10个文件中。这样新生成的文件每个的大小大约也1G（假设hash函数是随机的）。

2)找一台内存在2G左右的机器，依次对 用hash_map(query, query_count)来统计每个query出现的次数。利用快速/堆/归并排序按照出现次数进行排序。将排序好的query和对应的query_cout输出到文件中。这样得到了10个排好序的文件。

3)对这10个文件进行归并排序（内排序与外排序相结合）。

 

方案2：

一般query的总量是有限的，只是重复的次数比较多而已，可能对于所有的query，一次性就可以加入到内存了。这样，我们就可以采用trie树/hash_map等直接来统计每个query出现的次数，然后按出现次数做快速/堆/归并排序就可以了。

 

方案3：

与方案1类似，但在做完hash，分成多个文件后，可以交给多个文件来处理，采用分布式的架构来处理（比如MapReduce），最后再进行合并。

 

## 有一个1GB大小的文件，里面的每一行是一个词，词的大小不超过16个字节，内存限制大小是1MB。返回频数最高的100个词。

首先，我们看到这个题目应该做一下计算，大概的计算，因为大家都清楚的知道1G的文件不可能用1M的内存空间处理。所以我们要按照1M的上线来计算，假设每个单词都为16个字节，那么1M的内存可以处理多少个单词呢？ 1M = 1024 KB = 1024 * 1024 B 。然后1M / 16B = 2^16个单词，那么1G大概有多少个单词呢？ 有2^26个单词，但是实际中远远不止这些，因为我们是按照最大单词长度算的。我们需要把这1G的单词分批处理，根据上面的计算，可以分成大于2^10个文件。索性就分成2000个文件吧，怎么分呢，不能随便分，不能简单的按照单词的顺序然后模2000划分，因为这样有可能相同的单词被划分到不同的文件中去了。这样在统计个数的时候被当成的不同的单词，因为我们没有能力把在不同文件中相同单词出现的次数跨越文件的相加，这就迫使我们要把不同序号的同一个单词划分到同一个文件中：应用hash统计吧。稍后代码会给出方法。然后呢，我们队每个文件进行分别处理。按照key-value的方法处理每个单词，最终得出每个文件中包含每个单词和单词出现的次数。然后再建立大小为100的小根堆。一次遍历文件进行处理。

 

## 搜索的输入信息是一个字符串，统计300万条输入信息中最热门的前10条，每次输入的一个字符串为不超过255B，内存使用只有1GB。

此题是可以全部存放入内存中的情况。

 

256B=0.25KB=1KB/4；100万=1M，10亿=1G。

300万个字符串最多（假设没有重复，都是最大长度）占用内存3M*1K/4=0.75G。所以可以将所有字符串都存放在内存中进行处理。 

可以使用key为字符串（事实上是字符串的hash值），值为字符串出现次数的hash来统计每个每个字符串出现的次数。并用一个长度为10的数组/链表来存储目前出现次数最多的10个字符串。

 

 

 

## 重复问题

  在海量数据中查找出重复出现的元素或者去除重复出现的元素也是常考的问题。针对此类问题，一般可以通过位图法实现。例如，已知某个文件内包含一些电话号码，每个号码为8位数字，统计不同号码的个数。

  本题最好的解决方法是通过使用位图法来实现。8位整数可以表示的最大十进制数值为99999999。如果每个数字对应于位图中一个bit位，那么存储8位整数大约需要99MB。因为1B=8bit，所以99Mbit折合成内存为99/8=12.375MB的内存，即可以只用12.375MB的内存表示所有的8位数电话号码的内容。

（有10000000个记录，这些查询串的重复度比较高，如果除去重复后，不超过3000000个。一个查询串的重复度越高，说明查询它的用户越多，也就是越热门。请统计最热门的10个查询串，要求使用的内存不能超过1GB。）

 

 

## 给两个文件，分别有100亿个整数，我们只有1G内存，如何找到两个文件交集？（哈希切分）

(1)将每一个文件进行哈希切分，分成1000份，每个文件40M。将每个整数都出来%1000，相同的数会进入同一个文件。

(2)编号相同的文件一定会产生交集，经A,B的第一个文件加载到内存进行比较，找出相同的保存下来，同样把后面的文件也这样比较。

## 给两个文件，分别有100亿个query，我们只有1G内存，如何找到两个文件的交集，分别给出近似算法和精确算法。

近似算法：布隆过滤器，利用哈希算法将字符串转换成整型，在利用位图实现，一个query映射3个位，当判断时，必须三个位都有效，但是每一个位都重叠映射，不存在可以准确判断，判断存在就不准确了。

精确算法：哈希切分 

(1)100亿个query4g*2.5*32=320G,哈希切分，将每个文件切分成1000份，每份320M,每个文件相同的query会进入相同编号的文件（字符串哈希算法将每个query转换成整型，对应的下标index=query%1000） 

(2)依次将相同编号的小文件加载到内存进行比较。将一个文件的小文件放入哈希表，用另一个文件相同编号的小文件去查找是否存在，依次比较，找出交集。

 

# 海量数据的相关方法

## 1、Bloom filter 

 

适用范围：可以用来实现数据字典，进行数据的判重，或者集合求交集

 

基本原理及要点：

对于原理来说很简单,位数组+k个独立hash函数。将hash函数对应的值的位数组置1，查找时如果发现所有hash函数对应位都是1说明存在，很明显这个过程并不保证查找的结果是100%正确的。同时也不支持删除一个已经插入的关键字，因为该关键字对应的位会牵动到其他的关键字。所以一个简单的改进就是 counting Bloom filter，用一个counter数组代替位数组，就可以支持删除了。

还有一个比较重要的问题，如 何根据输入元素个数n，确定位数组m的大小及hash函数个数。当hash函数个数k=(ln2)*(m/n)时错误率最小。在错误率不大于E的情况 下，m至少要等于n*lg(1/E)才能表示任意n个元素的集合。但m还应该更大些，因为还要保证bit数组里至少一半为0，则m应 该>=nlg(1/E)*lge 大概就是nlg(1/E)1.44倍(lg表示以2为底的对数)。

举个例子我们假设错误率为0.01，则此时m应大概是n的13倍。这样k大概是8个。

注意这里m与n的单位不同，m是bit为单位，而n则是以元素个数为单位(准确的说是不同元素的个数)。通常单个元素的长度都是有很多bit的。所以使用bloom filter内存上通常都是节省的。

扩展： Bloom filter将集合中的元素映射到位数组中，用k（k为哈希函数个数）个映射位是否全1表示元素在不在这个集合中。Countingbloom filter（CBF）将位数组中的每一位扩展为一个counter，从而支持了元素的删除操作。Spectral Bloom Filter（SBF）将其与集合元素的出现次数关联。SBF采用counter中的最小值来近似表示元素的出现频率。

 

问题实例：给你A、B两个文件，各存放50亿条URL，每条URL占用64字节，内存限制是4G，让你找出A,B文件共同的URL。如果是三个乃至n个文件呢？ 

根据这个问题我们来计算下内存的占用，4G=2^32大概是40亿*8大概是340亿，n=50亿，如果按出错率0.01算需要的大概是650亿个bit。现在可用的是340亿，相差并不多，这样可能会使出错率上升些。另外如果这些urlip是一一对应的，就可以转换成ip，则大大简单了。

 

 

 

## 2、Hashing

适用范围：快速查找，删除的基本数据结构，通常需要总数据量可以放入内存。

 

基本原理及要点：

 

hash函数选择，针对字符串，整数，排列，具体相应的hash方法。

 

碰撞处理，一种是open hashing，也称为拉链法；另一种就是closedhashing，也称开地址法，opened addressing。

 

扩展：d-lefthashing中的d是多个的意思，我们先简化这个问题，看一看2-left hashing。2-left hashing指的是将一个哈希表分成长度相等的两半，分别叫做T1和T2，给T1和T2分别配备一个哈希函数，h1和h2。在存储一个新的key时，同 时用两个哈希函数进行计算，得出两个地址h1[key]和h2[key]。这时需要检查T1中的h1[key]位置和T2中的h2[key]位置，哪一个位置已经存储的（有碰撞的）key比较多，然后将新key存储在负载少的位置。如果两边一样多，比如两个位置都为空或者都存储了一个key，就把新key 存储在左边的T1子表中，2-left也由此而来。在查找一个key时，必须进行两次hash，同时查找两个位置。

 

问题实例：

 

1)、海量日志数据，提取出某日访问百度次数最多的那个IP。

 

IP的数目还是有限的，最多2^32个，所以可以考虑使用hash将ip直接存入内存，然后进行统计。

 

 

 

## 3、bit-map 

适用范围：可进行数据的快速查找，判重，删除，一般来说数据范围是int的10倍以下

 

基本原理及要点：使用bit数组来表示某些元素是否存在，比如8位电话号码

 

扩展：bloom filter可以看做是对bit-map的扩展 

 

问题实例：

 

1)已知某个文件内包含一些电话号码，每个号码为8位数字，统计不同号码的个数。 

 

8位最多99 999 999，大概需要99m个bit，大概10几m字节的内存即可。

 

2)2.5亿个整数中找出不重复的整数的个数，内存空间不足以容纳这2.5亿个整数。 

 

将bit-map扩展一下，用2bit表示一个数即可，0表示未出现，1表示出现一次，2表示出现2次及以上。或者我们不用2bit来进行表示，我们用两个bit-map即可模拟实现这个2bit-map。

 

 

 

## 4、堆 

适用范围：海量数据前n大，并且n比较小，堆可以放入内存

基本原理及要点：最大堆求前n小，最小堆求前n大。方法，比如求前n小，我们比较当前元素与最大堆里的最大元素，如果它小于最大元素，则应该替换那个最大元素。这样最后得到的n个元素就是最小的n个。适合大数据量，求前n小，n的大小比较小的情况，这样可以扫描一遍即可得到所有的前n元素，效率很高。

 

扩展：双堆，一个最大堆与一个最小堆结合，可以用来维护中位数。 

 

问题实例： 

 

1)100w个数中找最大的前100个数。

 

用一个100个元素大小的最小堆即可。

 

 

 

## 5、双层桶划分 （第k大，中位数）

适用范围：第k大，中位数，不重复或重复的数字

 

基本原理及要点：因为元素范围很大，不能利用直接寻址表，所以通过多次划分，逐步确定范围，然后最后在一个可以接受的范围内进行。可以通过多次缩小，双层只是一个例子。

 

问题实例： 

 

1) 2.5亿个整数中找出不重复的整数的个数，内存空间不足以容纳这2.5亿个整数。

有点像鸽巢原理，整数个数为2^32,也就是，我们可以将这2^32个数，划分为2^8个区域(比如用单个文件代表一个区域)，然后将数据分离到不同的区域，然后不同的区域在利用bitmap就可以直接解决了。也就是说只要有足够的磁盘空间，就可以很方便的解决。

 

2) 5亿个int找它们的中位数。

这个例子比上面那个更明显。首先我们将int划分为2^16个区域，然后读取数据统计落到各个区域里的数的个数，之后我们根据统计结果就可以判断中位数落到那个区域，同时知道这个区域中的第几大数刚好是中位数。然后第二次扫描我们只统计落在这个区域中的那些数就可以了。

 

实 际上，如果不是int是int64，我们可以经过3次这样的划分即可降低到可以接受的程度。即可以先将int64分成2^24个区域，然后确定区域的第几大数，在将该区域分成2^20个子区域，然后确定是子区域的第几大数，然后子区域里的数的个数只有2^20，就可以直接利用direct addr table进行统计了。

 

 

 

## 6、数据库索引 

 

适用范围：大数据量的增删改查

 

基本原理及要点：利用数据的设计实现方法，对海量数据的增删改查进行处理。

 

 

## 7、倒排索引(Inverted index) 

 

适用范围：搜索引擎，关键字查询

 

基本原理及要点：为何叫倒排索引？一种索引方法，被用来存储在全文搜索下某个单词在一个文档或者一组文档中的存储位置的映射。

 

以英文为例，下面是要被索引的文本：

 

T0 = "it is what it is" 

 

T1 = "what is it" 

 

T2 = "it is a banana" 

 

我们就能得到下面的反向文件索引：

 

"a":    {2}

 

"banana": {2} 

 

"is":   {0, 1, 2} 

 

"it":   {0, 1, 2} 

 

"what":  {0, 1} 

 

检索的条件"what","is" 和 "it" 将对应集合的交集。

 

正向索引开发出来用来存储每个文档的单词的列表。正向索引的查询往往满足每个文档有序频繁的全文查询和每个单词在校验文档中的验证这样的查询。在正向索引 中，文档占据了中心的位置，每个文档指向了一个它所包含的索引项的序列。也就是说文档指向了它包含的那些单词，而反向索引则是单词指向了包含它的文档，很 容易看到这个反向的关系。

 

问题实例：文档检索系统，查询那些文件包含了某单词，比如常见的学术论文的关键字搜索。 

 

 

 

## 8、外排序

 

适用范围：大数据的排序，去重。

 

基本原理及要点：外排序的归并方法，置换选择 败者树原理，最优归并树 。

 

问题实例：有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16个字节，内存限制大小是1M。返回频数最高的100个词。 

 

这个数据具有很明显的特点，词的大小为16个字节，但是内存只有1m做hash有些不够，所以可以用来排序。内存可以当输入缓冲区使用。

 

 

 

## 9、trie树（数据量大，重复多，但是数据种类小可以放入内存）[字典树]

适用范围：数据量大，重复多，但是数据种类小可以放入内存

 

基本原理及要点：实现方式，节点孩子的表示方式

 

扩展：压缩实现。

 

问题实例：

 

1)、有10个文件，每个文件1G， 每个文件的每一行都存放的是用户的query，每个文件的query都可能重复。要你按照query的频度排序 。

 

2)、1000万字符串，其中有些是相同的(重复),需要把重复的全部去掉，保留没有重复的字符串。请问怎么设计和实现？

 

3)、寻找热门查询：查询串的重复度比较高，虽然总数是1千万，但如果除去重复后，不超过3百万个，每个不超过255字节。 

 

 

 

## 10、分布式处理 mapreduce 

 

适用范围：数据量大，但是数据种类小可以放入内存 

 

基本原理及要点：将数据交给不同的机器去处理，数据划分，结果归约。 

 

## 经典问题分析

### 上千万or亿数据（有重复），统计其中出现次数最多的前N个数据,分两种情况：可一次读入内存，不可一次读入。

可用思路：trie树+堆，数据库索引，划分子集分别统计，hash，分布式计算，近似统计，外排序 

 

所谓的是否能一次读入内存，实际上应该指去除重复后的数据量。如果去重后数据可以放入内存，我们可以为数据建立字典，比如通过 map，hashmap，trie，然后直接进行统计即可。当然在更新每条数据的出现次数的时候，我们可以利用一个堆来维护出现次数最多的前N个数据，当然这样导致维护次数增加，不如完全统计后在求前N大效率高。

 

如果数据无法放入内存。一方面我们可以考虑上面的字典方法能否被改进以适应这种情形，可以做的改变就是将字典存放到硬盘上，而不是内存，这可以参考数据库的存储方法。

 

当然还有更好的方法，就是可以采用分布式计算，基本上就是map-reduce过程，首先可以根据数据值或者把数据hash(md5)后的值，将数据按照范围划分到不同的机子，最好可以让数据划分后可以一次读入内存，这样不同的机子负责处理各种的数值范围，实际上就是map。得到结果后，各个机子只需拿出各自的出现次数最多的前N个数据，然后汇总，选出所有的数据中出现次数最多的前N个数据，这实际上就是reduce过程。

 

实际上可能想直接将数据均分到不同的机子上进行处理，这样是无法得到正确的解的。因为一个数据可能被均分到不同的机子上，而另一个则可能完全聚集到一个机子上，同时还可能存在具有相同数目的数据。比如我们要找出现次数最多的前100个，我们将1000万的数据分布到10台机器上，找到每台出现次数最多的前 100个，归并之后这样不能保证找到真正的第100个，因为比如出现次数最多的第100个可能有1万个，但是它被分到了10台机子，这样在每台上只有1千 个，假设这些机子排名在1000个之前的那些都是单独分布在一台机子上的，比如有1001个，这样本来具有1万个的这个就会被淘汰，即使我们让每台机子选 出出现次数最多的1000个再归并，仍然会出错，因为可能存在大量个数为1001个的发生聚集。因此不能将数据随便均分到不同机子上，而是要根据hash 后的值将它们映射到不同的机子上处理，让不同的机器处理一个数值范围。

 

而外排序的方法会消耗大量的IO，效率不会很高。而上面的分布式方法，也可以用于单机版本，也就是将总的数据根据值的范围，划分成多个不同的子文件，然后逐个处理。处理完毕之后再对这些单词的及其出现频率进行一个归并。实际上就可以利用一个外排序的归并过程。

 

另外还可以考虑近似计算，也就是我们可以通过结合自然语言属性，只将那些真正实际中出现最多的那些词作为一个字典，使得这个规模可以放入内存。

 

 

### 从海量数据中找出中位数

 

题目：在一个文件中有 10G 个整数，乱序排列，要求找出中位数。内存限制为 2G。只写出思路即可（内存限制为2G的意思就是，可以使用2G的空间来运行程序，而不考虑这台机器上的其他软件的占用内存）。

 

  关于中位数：数据排序后，位置在最中间的数值。即将数据分成两部分，一部分大于该数值，一部分小于该数值。中位数的位置：当样本数为奇数时，中位数=(N+1)/2 ; 当样本数为偶数时，中位数为N/2与1+N/2的均值（那么10G个数的中位数，就第5G大的数与第5G+1大的数的均值了）。

 

分析：明显是一道工程性很强的题目，和一般的查找中位数的题目有几点不同。

 

1、原数据不能读进内存，不然可以用快速选择，如果数的范围合适的话还可以考虑桶排序或者计数排序，但这里假设是32位整数，仍有4G种取值，需要一个16G大小的数组来计数。

 

2、若看成从N个数中找出第K大的数，如果K个数可以读进内存，可以利用最小或最大堆，但这里K=N/2，有5G个数，仍然不能读进内存。

 

3、接上，对于N个数和K个数都不能一次读进内存的情况，《编程之美》里给出一个方案：解法：首先假设k是32位无符号整数。

 

1)读一遍10G个整数，把整数映射到256M个区段中，用一个64位无符号整数给每个相应区段记数。说明：整数范围是0 - 2^32 - 1，一共有4G种取值，映射到256M个区段，则每个区段有16（4 G/256M =16）种值，每16个值算一段， 0~15是第1段，16~31是第2段，……2^32-16~2^32-1是第256M段。一个64位无符号整数最大值是0~8G-1，这里先不考虑溢出的情况。总共占用内存256M×8B=2GB。

 

2)从前到后对每一段的计数累加，当累加的和超过5G时停止，找出这个区段（即累加停止时达到的区段，也是中位数所在的区段）的数值范围，设为[a，a+15]，同时记录累加到前一个区段的总数，设为m。然后，释放除这个区段占用的内存。

 

3)再读一遍10G个整数，把在[a，a+15]内的每个值计数，即有16个计数。

 

4)对新的计数依次累加，每次的和设为n，当m+n的值超过5G时停止，此时的这个计数所对应的数就是中位数。

 

 

 

 

### 有一篇英文文章(也就是说每个单词之间由空格分隔)，请找出“csdn”这个单词出现的次数，要求效率最高，并写出算法的时间级。

可以把单词看成一个N进制数，CSDN相当于('c'-'a')*N^3+('s'-'a')*N^2+('d'-'a')*N+('n'-'a'),然后查找这个数出现的次数就是答案,也可以建立一颗字典树，然后去计数！

 

 

 

## 腾讯海量数据面试题

### 1、在一个文件中有10G个整数，乱序排列，要求找出中位数。内存限制为2G。只写出思路即可。

  海量数据处理的问题。10G个数，中位数就是第5G、第5G+1个数。回想一下，一般情况下求中位数的做法：类似于快排的partition，找到一个数，使比它小的数的个数占到总数的一半就行。所以，可以把数值空间分段，然后统计每一段中数据的个数，这样就可以很容易的确定中位数在那一段。找个该段后，数据量已经急剧减小了，剩下的问题就好处理了。这种方法可以说是桶排序的思想，也可以说是hash的思想。下面具体分析一下：

  因为要统计每一段中数据的个数，所以可以用一个unsigned int型。unsignedint一般占4个字节，可以计数到2^32-1，大约是4G。题目中有10G个数，如果有很多数落在同一个段中，unsigned int肯定不够用。所以，这里的计数用要8字节的long long。即，相当于有一个数组，数组是long long性，数组的每一个元素，代表了一个数据段内的数据个数。这个数组有多大？为了充分利用2G内存，数组大小2G/8= 256M。即，有数组long long cnt[256M].

  假设题目中的10G个数都是4字节的int。如何把这10G个整数，映射到cnt[256M]的数组中。可以使用计算机中的虚拟地址到物理地址的转换。取int的高28位作为数组下标的索引值，这样就可以完成映射。

 

整个算法的流程：

扫描10G个整数，对每个整数，取高28位，映射到数组的某个元素上

给数组的这个元素加1，表示找到一个属于该数据段的元素

扫描完10G个整数后，数组cnt中就记录了每段中元素的个数

从第一段开始，将元素个数累计，直到值刚好小于5G，则中位数就在该段

这时对10G个整数再扫描一遍，记录该段中每个元素的个数。直至累计到5G即可。

 

### 2、一个文件中有40亿个整数，每个整数为四个字节，内存为1GB，写出一个算法：求出这个文件里的整数里不包含的一个整数。

方法一：

使用位图。4字节的int，有4G个不同的值。每个值，对应1bit，则共需 4G/8 =512M 内存。初始状态，对512M的位图清零。然后，对这40亿个整数进行统计。如果某个值出现了，那么就把这个值对应的bit置位。最后，扫描位图，找到一个没有被置位的bit即可。

方法二：

分段统计。Long long cnt[512M/8=64M]对应数值空间的64M个数据段。每个数据段包含64个不同值，用一个longlong作为这个数据段内的位图，位图占64M*8=512M。

这样扫描一遍40亿个整数后，从数组中找到一个计数小于64的元素，然后查看它的位图，找出未出现的元素。

 

方法二平均性能应该比方法一快，但它占的内存很恐怖。其实，这两种方法都不是很实际，总共1G的内存，算法就消耗512M甚至1G，那剩下的系统程序怎么办？OS都跑不起来了吧。

 

### 3、腾讯服务器每秒有2w个QQ号同时上线，找出5min内重新登入的qq号并打印出来。

 

  这应该是道面试题，面试官随口问了一下。主要是看思路吧。

 

  最简单的想法：直接用STL的set。从某一时刻开始计时，每登陆一个QQ，把它放入set，如果已存则直接打印。直到5min后，就可以over了。下面来简单分析一下算法的复杂度：

 

  空间复杂度：用str存储每个QQ号，假设QQ号有20位，理想情况下每个QQ占20Byte。则5min内的QQ：2w * 60 * 5 = 600w个，需要的存储空间600w * 20byte = 12000w byte = 120M，这样的存储应该可以忍受吧。

  时间复杂度：STL的set是用二叉树（更确切的说是：红黑树）实现的，查找效率是O( lgn )，应该还是挺快的吧。

  呃，有人说不让用STL。那就自己设计一个数据结构呗。该用什么数据结构呢？想了想，还是继续用树，这里用一个trie tree吧。节点内容包括QQ号、指向子节点的指针（这里有10个，认为QQ由0---9的数字组成）。登陆时间要不要？考虑这样一个问题：是否需要把所有的QQ都保存在内存中？随着时间的增加，登陆的QQ会越来越多，比较好的方法是把长时间不登陆的QQ释放掉。所以需要记录登陆时间，以便于释放长期不登陆的QQ。

 

 

 

 

 

# JVM

 

## GC

## 类加载机制

[https://blog.csdn.net/noaman_wgs/article/details/74489549](qq://txfile/)

 

 

 

# c++

## 容器之间的差异与联系

 

 

 

## C++之deque

deque(包含头文件#include<deque>)由若干段连续空间串接而成，一旦有必要在deque的头部或尾端增加新的空间，便配置一段定量连续的空间，串接在deque的头部或尾端。deque的最大任务，就是在这些分段连续的空间上维护其整体连续的假象，并提供随机存取的接口。

 

实际上。deque内部会维护一个map（注意！不是STL中的map容器）即一小块连续的空间，该空间中每个元素都是指针，指向另一段（较大的）区域，这个区域称为缓冲区，缓冲区用来保存deque中的数据。因此deque在随机访问和遍历数据会比vector慢。它首次插入一个元素，默认会动态分配512字节空间，当这512字节空间用完后，它会再动态分配自己另外的512字节空间，然后虚拟地连在一起。deque的这种设计使得它具有比vector复杂得多的架构、算法和迭代器设计。它的随机访问和遍历性能比vector差。

 

deque是一种优化了的对序列两端元素进行添加和删除操作的基本序列容器。通常由一些独立的区块组成，第一区块朝某方向扩展，最后一个区块朝另一方向扩展。它允许较为快速地随机访问但它不像vector一样把所有对象保存在一个连续的内存块，而是多个连续的内存块。并且在一个映射结构中保存对这些块以及顺序的跟踪

## 内存对齐

 

 

 

 

 

## [C++中的inline用法](https://www.cnblogs.com/fnlingnzb-learner/p/6423917.html)

**1.** **引入****inline****关键字的原因**

在c/c++中，**为了解决**一些频繁调用的小函数大量消耗栈空间（栈内存）的问题，特别的引入了inline修饰符，表示为内联函数。

**栈空间**就是指放置程序的局部数据（也就是函数内数据）的内存空间。

在系统下，栈空间是有限的，假如频繁大量的使用就会造成因栈空间不足而导致程序出错的问题，如，函数的死循环递归调用的最终结果就是导致栈内存空间枯竭。

下面我们来看一个例子：

\#include <stdio.h>

//函数定义为inline即:内联函数

inline char* dbtest(int a) {

  return (i % 2 > 0) ? "奇" : "偶";

} 

 

int main()

{

  int i = 0;

  for (i=1; i < 100; i++) {

​    printf("i:%d  奇偶性:%s /n", i, dbtest(i));  

  }

}

上面的例子就是标准的内联函数的用法，使用inline修饰带来的好处我们表面看不出来，其实，在内部的工作就是在每个for循环的内部任何调用***dbtest(i)\***的地方都换成了***(i%2>0)?”\******奇\******”:”\******偶\******”\***，这样就避免了频繁调用函数对栈内存重复开辟所带来的消耗。

 

**2. inline****使用限制**

inline的使用是**有所限制的**，inline只适合涵数体内代码简单的涵数使用，不能包含复杂的结构控制语句例如while、switch，并且不能内联函数本身不能是直接递归函数（即，自己内部还调用自己的函数）。

 

**3. inline****仅是一个对编译器的建议**

inline函数仅仅是一个**对编译器的建议**，所以**最后能否真正内联，看编译器的意思**，它如果认为函数不复杂，能在调用点展开，就会真正内联，并不是说声明了内联就会内联，声明内联只是一个建议而已。

 

**4.** **建议：****inline****函数的定义放在头文件中**

其次，因为内联函数要在调用点展开，所以**编译器必须随处可见内联函数的定义**，要不然就成了非内联函数的调用了。所以，这要求每个调用了内联函数的文件都出现了该**内联函数的定义**。

因此，将**内联函数的定义**放在**头文件**里实现是合适的，省却你为每个文件实现一次的麻烦。

**声明跟定义要一致**：如果在每个文件里都实现一次该内联函数的话，那么，最好保证每个定义都是一样的，否则，将会引起未定义的行为。如果不是每个文件里的定义都一样，那么，编译器展开的是哪一个，那要看具体的编译器而定。所以，最好将**内联函数定义**放在**头文件**中。

 

**5.** **类中的成员函数与****inline**

**定义**在类中的**成员函数**缺省都是**内联的**，如果在类定义时就在类内给出函数定义，那当然最好。如果在类中未给出成员函数定义，而又想内联该函数的话，那在类外要加上inline，否则就认为不是内联的。

例如，

class A

{

  public:void Foo(int x, int y) { } // 自动地成为内联函数

}

将成员函数的定义体放在类声明之中虽然能带来书写上的方便，但不是一种良好的编程风格，上例应该改成：

// 头文件

class A

{

  public:

  void Foo(int x, int y);

}

 

// 定义文件

inline void A::Foo(int x, int y){} 

 

**6. inline** **是一种****“****用于实现的关键字****”**

关键字inline 必须与**函数定义体**放在一起才能使函数成为内联，仅将inline 放在函数声明前面**不起任何作用**。

如下风格的函数Foo 不能成为内联函数：

inline void Foo(int x, int y); // inline 仅与函数声明放在一起

 

void Foo(int x, int y){}

 

而如下风格的函数Foo 则成为内联函数：

void Foo(int x, int y);

 

inline void Foo(int x, int y) {} // inline 与函数定义体放在一起

 

所以说，inline 是一种“**用于实现的关键字**”，而不是一种“用于声明的关键字”。一般地，用户可以阅读函数的声明，但是看不到函数的定义。尽管在大多数教科书中内联函数的声明、定义体前面都加了inline 关键字，但我认为**inline****不应该出现在函数的声明中**。这个细节虽然不会影响函数的功能，但是体现了高质量C++/C 程序设计风格的一个基本原则：**声明与定义不可混为一谈，用户没有必要、也不应该知道函数是否需要内联。**

**7.** **慎用****inline**

内联能提高函数的执行效率，为什么不把所有的函数都定义成内联函数？如果所有的函数都是内联函数，还用得着“内联”这个关键字吗？
 内联是以**代码膨胀（复制）**为代价，仅仅省去了函数调用的开销，从而提高函数的执行效率。
 如果执行函数体内代码的时间，相比于函数调用的开销较大，那么效率的收获会很少。另一方面，每一处内联函数的调用都要复制代码，将使程序的总代码量增大，消耗更多的内存空间。

**以下情况不宜使用内联：** 
 （1）如果函数体内的代码**比较长**，使用内联将导致**内存消耗代价较高**。 
 （2）如果函数体内出现**循环**，那么执行函数体内代码的时间要比函数调用的开销大。类的构造函数和析构函数容易让人误解成使用内联更有效。要当心**构造函数和析构函数可能会隐藏一些行为**，如“偷偷地”执行了**基类或成员对象**的构造函数和析构函数。所以**不要随便地将构造函数和析构函数的定义体放在类声明中**。一个好的编译器将会根据函数的定义体，自动地取消不值得的内联（这进一步说明了 inline 不应该出现在函数的声明中）。

**8.****总结**

内联函数并不是一个增强性能的灵丹妙药。只有当**函数非常短小**的时候它才能得到我们想要的效果；但是，如果函数并不是很短而且在很多地方都被调用的话，那么将会使得可执行体的体积增大。
 **最令人烦恼的**还是当**编译器拒绝内联**的时候。在老的实现中，结果很不尽人意，虽然在新的实现中有很大的改善，但是仍然还是不那么完善的。一些编译器能够足够的聪明来指出哪些函数可以内联哪些不能，但是大多数编译器就不那么聪明了，因此这就需要我们的经验来判断。**如果内联函数不能增强性能，就避免使用它！**

 

## 内存分配模式 堆栈的区别

 

 

 

 

 

## map是用红黑树实现的。

## 虚函数表

 

 

 

 

 

## main函数执行以前，还会执行什么代码？

全局对象的构造函数会在main函数之前执行。

## 全局变量和局部变量有什么区别？是怎么实现的？操作系统和编译器是怎么知道的？

1）生命周期不同：全局变量随主程序创建和创建，随主程序销毁而销毁；局部变量在局部函数内部，甚至局部循环体等内部存在，退出就不存在；

2）使用方式不同：通过声明后全局变量程序的各个部分都可以用到；局部变量只能在局部使用；分配在栈区。

操作系统和编译器通过**内存分配的位置**来知道的，全局变量分配在全局数据段并且在程序开始运行的时候被加载。局部变量则分配在堆栈里面。

 

## 引用

### 1 引用与指针有什么区别？

1)引用必须被初始化，指针不必。

2)引用初始化以后不能被改变，指针可以改变所指的对象。

3)不存在指向空值的引用，但是存在指向空值的指针。

 

### 2 什么是“引用”？申明和使用“引用”要注意哪些问题？

答：引用就是某个目标变量的**“别名”**(alias)，对应用的操作与对变量直接操作效果完全相同。

申明一个引用的时候，切记要对其进行**初始化**。引用声明完毕后，相当于目标变量名有两个名称，即该目标原名称和引用名，**不能再把该引用名作为其他变量名的别名**。声明一个引用，不是新定义了一个变量，它只表示该引用名是目标变量名的一个别名，它本身不是一种数据类型，因此引用本身不占存储单元，系统也不给引用分配存储单元。**不能建立数组的引用**。

 

### 3 将“引用”作为函数参数有哪些特点？

（1）传递引用给函数与传递指针的效果是一样的。这时，被调函数的形参就成为原来主调函数中的实参变量或对象的一个别名来使用，所以在被调函数中对形参变量的操作就是对其相应的目标对象（在主调函数中）的操作。

（2）使用引用传递函数的参数，在内存中并没有产生实参的副本，它是直接对实参操作；而使用一般变量传递函数的参数，当发生函数调用时，需要给形参分配存储单元，形参变量是实参变量的副本；如果传递的是对象，还将调用拷贝构造函数。因此，当参数传递的数据较大时，用引用比用一般变量传递参数的效率和所占空间都好。

（3）使用指针作为函数的参数虽然也能达到与使用引用的效果，但是，在被调函数中同样要给形参分配存储单元，且需要重复使用"*指针变量名"的形式进行运算，这很容易产生错误且程序的阅读性较差；另一方面，在主调函数的调用点处，必须用变量的地址作为实参。而引用更容易使用，更清晰。

 

### 4 在什么时候需要使用“常引用”？

如果既要利用引用提高程序的效率，又要保护传递给函数的数据不在函数中被改变，就应使用常引用。常引用声明方式：const 类型标识符 &引用名=目标变量名。

格式：类型标识符 &函数名（形参列表及类型说明）{ //函数体 }

好处：在内存中不产生被返回值的副本；（注意：正是因为这点原因，所以返回一个局部变量的引用是不可取的。因为随着该局部变量生存期的结束，相应的引用也会失效，产生runtime error! 

注意事项：

（1）不能返回局部变量的引用。这条可以参照Effective C++[1]的Item 31。主要原因是局部变量会在函数返回后被销毁，因此被返回的引用就成为了"无所指"的引用，程序会进入未知状态。

（2）不能返回函数内部new分配的内存的引用。这条可以参照Effective C++[1]的Item 31。虽然不存在局部变量的被动销毁问题，可对于这种情况（返回函数内部new分配内存的引用），又面临其它尴尬局面。例如，被函数返回的引用只是作为一个临时变量出现，而没有被赋予一个实际的变量，那么这个引用所指向的空间（由new分配）就无法释放，造成memory leak。

（3）可以返回类成员的引用，但最好是const。这条原则可以参照Effective C++[1]的Item 30。主要原因是当对象的属性是与某种业务规则（business rule）相关联的时候，其赋值常常与某些其它属性或者对象的状态有关，因此有必要将赋值操作封装在一个业务规则当中。如果其它对象可以获得该属性的非常量引用（或指针），那么对该属性的单纯赋值就会破坏业务规则的完整性。

（4）流操作符重载返回值申明为“引用”的作用：

流操作符<<和>>，这两个操作符常常希望被连续使用，例如：cout << "hello" << endl;　因此这两个操作符的返回值应该是一个仍然支持这两个操作符的流引用。可选的其它方案包括：返回一个流对象和返回一个流对象指针。但是对于返回一个流对象，程序必须重新（拷贝）构造一个新的流对象，也就是说，连续的两个<<操作符实际上是针对不同对象的！这无法让人接受。对于返回一个流指针则不能连续使用<<操作符。因此，返回一个流对象引用是惟一选择。这个唯一选择很关键，它说明了引用的重要性以及无可替代性，也许这就是C++语言中引入引用这个概念的原因吧。 

赋值操作符=。这个操作符象流操作符一样，是可以连续使用的，例如：x = j = 10;或者(x=10)=100;赋值操作符的返回值必须是一个左值，以便可以被继续赋值。因此引用成了这个操作符的惟一返回值选择。

（5）在另外的一些操作符中，却千万不能返回引用：+-*/ 四则运算符。它们不能返回引用，Effective C++[1]的Item23详细的讨论了这个问题。主要原因是这四个操作符没有side effect，因此，它们必须构造一个对象作为返回值，可选的方案包括：返回一个对象、返回一个局部变量的引用，返回一个new分配的对象的引用、返回一个静态对象引用。根据前面提到的引用作为返回值的三个规则，2、3两个方案都被否决了。静态对象的引用又因为((a+b) == (c+d))会永远为true而导致错误。所以可选的只剩下返回一个对象了。

 

## 请说出const与#define相比，有何优点？

const作用：定义常量、修饰函数参数、修饰函数返回值三个作用。被Const修饰的东西都受到强制保护，可以预防意外的变动，能提高程序的健壮性。

1）const常量有数据类型，**而宏常量没有数据类型**。编译器可以对前者进行类型安全检查。而对后者只进行字符替换，没有类型安全检查，并且在字符替换可能会产生意料不到的错误。

2）有些集成化的调试工具可以对const常量进行调试，但是不能对宏常量进行调试。

## new、delete、malloc、free关系

delete会调用对象的析构函数,和new对应free只会释放内存，new调用构造函数。malloc与free是C++/C语言的标准库函数，new/delete是C++的运算符。它们都可用于申请动态内存和释放内存。对于非内部数据类型的对象而言，光用maloc/free无法满足动态对象的要求。对象在创建的同时要自动执行构造函数，对象在消亡之前要自动执行析构函数。由于malloc/free是库函数而不是运算符，不在编译器控制权限之内，不能够把执行构造函数和析构函数的任务强加于malloc/free。因此C++语言需要一个能完成动态内存分配和初始化工作的运算符new，以及一个能完成清理与释放内存工作的运算符delete。注意new/delete不是库函数。

## delete与delete[]区别

delete只会调用一次析构函数，而delete[]会调用每一个成员的析构函数。在More Effective C++中有更为详细的解释：“当delete操作符用于数组时，它为每个数组元素调用析构函数，然后调用operator delete来释放内存。”delete与new配套，delete[]与new[]配套

对于内建简单数据类型，delete和delete[]功能是相同的。对于自定义的复杂数据类型，delete和delete[]不能互用。delete[]删除一个数组，delete删除一个指针。简单来说，用new分配的内存用delete删除；用new[]分配的内存用delete[]删除。delete[]会调用数组元素的析构函数。内部数据类型没有析构函数，所以问题不大。如果你在用delete时没用括号，delete就会认为指向的是单个对象，否则，它就会认为指向的是一个数组。

## 子类析构时要调用父类的析构函数吗？

析构函数调用的次序是先派生类的析构后基类的析构，也就是说在基类的的析构调用的时候,派生类的信息已经全部销毁了。定义一个对象时先调用基类的构造函数、然后调用派生类的构造函数；析构的时候恰好相反：先调用派生类的析构函数、然后调用基类的析构函数。

## vector与list的区别

 

## 面向对象语言的三大特性：封装、继承、多态

继承：继承（动物与猫的关系）与组合（B有B1和B2方法，组合）；

多态：重载（基于传入参数不同判断、返回值可以不同；）、重写（取代父类的方法）与重定义

 

## 多态：虚函数，纯虚函数

多态：是对于不同对象接收相同消息时产生不同的动作。C++的多态性具体体现在运行和编译两个方面：在程序运行时的多态性通过**继承和虚函数**来体现；

在程序编译时多态性体现在函数和运算符的重载上；

虚函数：在基类中冠以关键字virtual的成员函数。它提供了一种接口界面。允许在**派生类中对基类的虚函数重新定义**。

纯虚函数的作用：在基类中为其派生类保留一个函数的名字，以便派生类根据需要对它进行定义。作为接口而存在纯虚函数不具备函数的功能，一般不能直接被调用。

从基类继承来的纯虚函数，在派生类中仍是虚函数。如果一个类中至少有一个纯虚函数，那么这个类被称为抽象类（abstract class）。

抽象类中不仅包括纯虚函数，也可包括虚函数。抽象类必须用作派生其他类的基类，而不能用于直接创建对象实例。但仍可使用指向抽象类的指针支持运行时多态性。

## 重载、重写、重定义的区别

 

## 基类的析构函数不是虚函数，会带来什么问题？

派生类的析构函数用不上，会造成资源的泄漏。

 

## 构造函数（执行过程？基类？）和析构函数

构造函数可以私有，不能为虚函数

 

## 简述数组与指针的区别？

数组要么在静态存储区被创建（如全局数组），要么在栈上被创建。指针可以随时指向任意类型的内存块。

## C++是不是类型安全的？

答案：不是。两个不同类型的指针之间可以强制转换（用reinterpret cast)。C#是类型安全的。

## C++中的拷贝构造函数和拷贝赋值操作符+const成员变量初始化

https://blog.csdn.net/u014038273/article/details/75268400

## 内存拷贝：memcpy(y,x,sizeof(x));

 

## 描述内存分配方式以及它们的区别?

1）从静态存储区域分配。内存在程序编译的时候就已经分配好，这块内存在程序的整个运行期间都存在。例如全局变量，static 变量。

2）在栈上创建。在执行函数时，函数内局部变量的存储单元都可以在栈上创建，函数执行结束时这些存储单元自动被释放。栈内存分配运算内置于处理器的指令集。

3）从堆上分配，亦称动态内存分配。程序在运行的时候用malloc 或new 申请任意多少的内存，程序员自己负责在何时用free 或delete 释放内存。动态内存的生存期由程序员决定，使用非常灵活，但问题也最多。

 

 

## 不重要

### 结构与联合有和区别？

(1).结构和联合都是由多个不同的数据类型成员组成,但在任何同一时刻,联合中只存放了一个被选中的成员（所有成员共用一块地址空间）,而结构的所有成员都存在（不同成员的存放地址不同）。

(2).对于联合的不同成员赋值,将会对其它成员重写,原来成员的值就不存在了, 而对于结构的不同成员赋值是互不影响的。

### 有哪几种情况只能用intialization list而不能用assignment?

当类中含有const、reference 成员变量；基类的构造函数都需要初始化表。

### 将程序跳转到指定内存地址

要对绝对地址0x100000赋值，我们可以用(unsigned int*)0x100000 = 1234;那么要是想让程序跳转到绝对地址是0x100000去执行，应该怎么做？

*((void (*)( ))0x100000 ) ( );

首先要将0x100000强制转换成函数指针,即:

(void (*)())0x100000

然后再调用它:

*((void (*)())0x100000)();

用typedef可以看得更直观些:

typedef void(*)() voidFuncPtr;

*((voidFuncPtr)0x100000)();

 

### int id[sizeof(unsigned long)];这个对吗？为什么？

正确，这个**sizeof是编译时运算符，编译时就确定了**,可以看成和机器有关的常量。

 

### 分别写出BOOL,int,float,指针类型的变量a与“零”的比较语句。

BOOL : if ( !a ) or if(a)

int : if ( a == 0)

float : const EXPRESSION EXP = 0.000001

if ( a < EXP && a >-EXP)

pointer : if ( a != NULL) or if(a == NULL)

 

 

 

### gcc 如何生成.so

 

 

# Linux操作

Awk\grep\cut\uniq\sort\正则

http://www.runoob.com/linux/linux-command-manual.html

http://url.cn/52eAYKf（微信）

## Linux VFS

虚拟文件系统 VFS(Virtual Filesystem Switch) 

### VFS 概述

VFS 是一种软件机制，也许称它为 Linux 的文件系统管理者更确切点，与它相关的数据结构只存在于物理内存当中。所以在每次系统初始化期间，Linux 都首先要在内存当中构造一棵 VFS 的目录树(在 Linux 的源代码里称之为 namespace)，实际上便是在内存中建立相应的数据结构。VFS 中的各目录其主要用途是用来提供实际文件系统的挂载点，当然在 VFS 中也会涉及到文件级的操作。图 1 是一种可能的目录树在内存中的影像：

 

### 文件系统的注册

这里的文件系统是指可能会被挂载到目录树中的各个实际文件系统，所谓实际文件系统，即是指VFS 中的实际操作最终要通过它们来完成而已，并不意味着它们一定要存在于某种特定的存储设备上。比如在笔者的 Linux 机器下就注册有 "rootfs"、"proc"、"ext2"、"sockfs" 等十几种文件系统。

#### 数据结构

在 Linux 源代码中，每种实际的文件系统用以下的数据结构表示：

| 1  2  3  4  5  6  7  8 | struct file_system_type {    const char *name;    int fs_flags;    struct super_block  *(*read_super) (struct super_block *, void *, int);    struct module *owner;    struct file_system_type *  next;    struct list_head fs_supers;  }; |
| ---------------------- | ------------------------------------------------------------ |
|                        |                                                              |

注册过程实际上将表示各实际文件系统的 struct file_system_type 数据结构的实例化，然后形成一个链表，内核中用一个名为 file_systems 的全局变量来指向该链表的表头。

#### 注册 rootfs 文件系统

在众多的实际文件系统中，之所以单独介绍 rootfs 文件系统的注册过程，实在是因为该文件系统 VFS 的关系太过密切，如果说 ext2/ext3 是 Linux 的本土文件系统，那么 rootfs 文件系统则是 VFS 存在的基础。一般文件系统的注册都是通过 module_init 宏以及 do_initcalls() 函数来完成(读者可通过阅读module_init 宏的声明及 arch\i386\vmlinux.lds 文件来理解这一过程)，但是 rootfs 的注册却是通过 init_rootfs() 这一初始化函数来完成，这意味着 rootfs 的注册过程是 Linux 内核初始化阶段不可分割的一部分。

init_rootfs() 通过调用 register_filesystem(&rootfs_fs_type) 函数来完成 rootfs 文件系统注册的，其中rootfs_fs_type 定义如下：

| 1  2  3  4  5  6 | struct file_system_type rootfs_fs_type = { \    name:     "rootfs", \    read_super: ramfs_read_super, \    fs_flags:   FS_NOMOUNT\|FS_LITTER, \    owner:     THIS_MODULE, \  } |
| ---------------- | ------------------------------------------------------------ |
|                  |                                                              |

注册之后的 file_systems 链表结构如下图所示：

 

### VFS 目录树的建立

既然是树，所以根是其赖以存在的基础， Linux 在初始化阶段是如何建立根结点的，即 "/"目录。这其中会包括挂载 rootfs 文件系统到根目录 "/" 的具体过程。构造根目录的代码是在 init_mount_tree（） 函数 （fs\namespace.c） 中。

首先，init_mount_tree() 函数会调用 do_kern_mount("rootfs", 0, "rootfs", NULL) 来挂载前面已经注册了的 rootfs 文件系统。这看起来似乎有点奇怪，因为根据前面的说法，似乎是应该先有挂载目录，然后再在其上挂载相应的文件系统，然而此时 VFS 似乎并没有建立其根目录。没关系，这是因为这里我们调用的是 do_kern_mount()，这个函数内部自然会创建我们最关心也是最关键的根目录(在 Linux 中，目录对应的数据结构是 struct dentry)。

在这个场景里，do_kern_mount() 做的工作主要是：

1）调用 alloc_vfsmnt() 函数在内存里申请了一块该类型的内存空间（struct vfsmount *mnt），并初始化其部分成员变量。

2) 调用 get_sb_nodev（） 函数在内存中分配一个超级块结构 (struct super_block) sb，并初始化其部分成员变量，将成员 s_instances 插入到 rootfs 文件系统类型结构中的 fs_supers 指向的双向链表中。

3) 通过 rootfs 文件系统中的 read_super 函数指针调用 ramfs_read_super() 函数。还记得当初注册rootfs 文件系统时，其成员 read_super 指针指向了 ramfs_read_super() 函数，参见图2.

4) ramfs_read_super() 函数调用 ramfs_get_inode() 在内存中分配了一个 inode 结构 (struct inode) inode，并初始化其部分成员变量，其中比较重要的有 i_op、i_fop 和 i_sb：

| 1  2  3 | inode->i_op = &ramfs_dir_inode_operations;  inode->i_fop = &dcache_dir_ops;  inode->i_sb = sb; |
| ------- | ------------------------------------------------------------ |
|         |                                                              |

这使得将来通过文件系统调用对 VFS 发起的文件操作等指令将被 rootfs 文件系统中相应的函数接口所接管。

 

5) ramfs_read_super() 函数在分配和初始化了 inode 结构之后，会调用 d_alloc_root() 函数来为 VFS的目录树建立起关键的根目录 (struct dentry)dentry，并将 dentry 中的 d_sb 指针指向 sb，d_inode 指针指向 inode。

6) 将 mnt 中的 mnt_sb 指针指向 sb，mnt_root 和 mnt_mountpoint 指针指向 dentry，而 mnt_parent指针则指向自身。

这样，当 do_kern_mount() 函数返回时，以上分配出来的各数据结构和 rootfs 文件系统的关系将如上图 3 所示。图中 mnt、sb、inode、dentry 结构块下方的数字表示它们在内存里被分配的先后顺序。限于篇幅的原因，各结构中只给出了部分成员变量，读者可以对照源代码根据图中所示按图索骥，以加深理解。

最后，init_mount_tree() 函数会为系统最开始的进程(即 init_task 进程)准备它的进程数据块中的namespace 域，主要目的是将 do_kern_mount() 函数中建立的 mnt 和 dentry 信息记录在了 init_task 进程的进程数据块中，这样所有以后从 init_task 进程 fork 出来的进程也都先天地继承了这一信息，在后面用sys_mkdir 在 VFS 中创建一个目录的过程中，我们可以看到这里为什么要这样做。为进程建立 namespace 的主要代码如下：

| 1  2  3  4  5  6  7  8  9  10 | namespace = kmalloc(sizeof(*namespace), GFP_KERNEL);  list_add(&mnt->mnt_list,  &namespace->list); //mnt is returned by do_kern_mount()   namespace->root = mnt;   init_task.namespace = namespace;   for_each_task(p) {     get_namespace(namespace);     p->namespace =  namespace;   }   set_fs_pwd(current->fs, namespace->root,  namespace->root->mnt_root);   set_fs_root(current->fs,  namespace->root, namespace->root->mnt_root); |
| ----------------------------- | ------------------------------------------------------------ |
|                               |                                                              |

该段代码的最后两行便是将 do_kern_mount() 函数中建立的 mnt 和 dentry 信息记录在了当前进程的 fs结构中。

以上讲了一大堆数据结构的来历，其实最终目的不过是要在内存中建立一颗 VFS 目录树而已，更确切地说， init_mount_tree() 这个函数为 VFS 建立了根目录 "/"，而一旦有了根，那么这棵数就可以发展壮大，比如可以通过系统调用 sys_mkdir 在这棵树上建立新的叶子节点等，所以系统设计者又将 rootfs 文件系统挂载到了这棵树的根目录上。关于 rootfs 这个文件系统，读者如果看一下前面图 2 中它的file_system_type 结构，会发现它的一个成员函数指针 read_super 指向的是 ramfs_read_super，单从这个函数名称中的 ramfs，读者大概能猜测出这个文件所涉及的文件操作都是针对内存中的数据对象，事实上也的确如此。从另一个角度而言，因为 VFS 本身就是内存中的一个数据对象，所以在其上的操作仅限于内存，那也是非常合乎逻辑的事。在接下来的章节中，我们会用一个具体的例子来讨论如何利用 rootfs所提供的函树为 VFS 增加一个新的目录节点。

VFS 中各目录的主要用途是为以后挂载文件系统提供挂载点。所以真正的文件操作还是要通过挂载后的文件系统提供的功能接口来进行。

### 在 VFS 树中挂载文件系统

在本节中，将描述在 VFS 的目录树中向其中某个目录(安装点 mount point)上挂载(mount)一个文件系统的过程。

这一过程可简单描述为：将某一设备(dev_name)上某一文件系统(file_system_type)安装到VFS目录树上的某一安装点(dir_name)。它要解决的问题是：将对 VFS 目录树中某一目录的操作转化为具体安装到其上的实际文件系统的对应操作。比如说，如果将 hda2 上的根文件系统(假设文件系统类型为 ext2)安装到了前一节中新建立的 "/dev" 目录上(此时，"/dev" 目录就成为了安装点)，那么安装成功之后应达到这样的目的，即：对 VFS 文件系统的 "/dev" 目录执行 "ls" 指令，该条指令应能列出 hda2 上 ext2 文件系统的根目录下所有的目录和文件。很显然，这里的关键是如何将对 VFS 树中 "/dev" 的目录操作指令转化为安装在其上的 ext2 这一实际文件系统中的相应指令。所以，接下来的叙述将抓住如何转化这一核心问题。在叙述之前，读者不妨自己设想一下 Linux 系统会如何解决这一问题。记住：对目录或文件的操作将最终由目录或文件所对应的 inode 结构中的 i_op 和 i_fop 所指向的函数表中对应的函数来执行。所以，不管最终解决方案如何，都可以设想必然要通过将对 "/dev" 目录所对应的 inode 中 i_op 和 i_fop 的调用转换到 hda2 上根文件系统 ext2 中根目录所对应的 inode 中 i_op 和 i_fop 的操作。

初始过程由 sys_mount() 系统调用函数发起，该函数原型声明如下：

| 1  2 | asmlinkage long sys_mount(char * dev_name, char *  dir_name, char * type,  unsigned long flags, void * data); |
| ---- | ------------------------------------------------------------ |
|      |                                                              |

其中，参数 char *type 为标识将要安装的文件系统类型字符串，对于 ext2 文件系统而言，就是"ext2"。参数 flags 为安装时的模式标识数，和接下来的 data 参数一样，本文不将其做为重点。

为了帮助读者更好地理解这一过程，笔者用一个具体的例子来说明：我们准备将来自主硬盘第 2 分区(hda2)上的 ext2 文件系统安装到前面创建的 "/dev" 目录中。那么对于 sys_mount() 函数的调用便具体为：

| 1    | sys_mount("hda2","/dev  ","ext2",…)； |
| ---- | ------------------------------------- |
|      |                                       |

该函数在将这些来自用户内存空间(user space)的参数拷贝到内核空间后，便调用 do_mount() 函数开始真正的安装文件系统的工作。同样，为了便于叙述和讲清楚主流程，接下来的说明将不严格按照具体的函数调用细节来进行。

do_mount() 函数会首先调用 path_lookup() 函数来得到安装点的相关信息，如同创建目录过程中叙述的那样，该安装点的信息最终记录在 struct nameidata 类型的一个变量当中，为叙述方便，记该变量为nd。在本例中当 path_lookup() 函数返回时，nd 中记录的信息如下：nd.entry = new_entry; nd.mnt = mnt; 这里的变量如图 3 和 4 中所示。

然后，do_mount() 函数会根据调用参数 flags 来决定调用以下四个函数之一：do_remount()、 do_loopback()、do_move_mount()、do_add_mount()。

在我们当前的例子中，系统会调用 do_add_mount() 函数来向 VFS 树中安装点 "/dev " 安装一个实际的文件系统。在 do_add_mount() 中，主要完成了两件重要事情：一是获得一个新的安装区域块，二是将该新的安装区域块加入了安装系统链表。它们分别是调用 do_kern_mount() 函数和 graft_tree() 函数来完成的。这里的描述可能有点抽象，诸如安装区域块、安装系统链表等，不过不用着急，因为它们都是笔者自己定义出来的概念，等一下到后面会有专门的图表解释，到时便会清楚。

do_kern_mount() 函数要做的事情，便是建立一新的安装区域块，具体的内容在前面的章节 VFS 目录树的建立中已经叙述过，这里不再赘述。

graft_tree() 函数要做的事情便是将 do_kern_mount() 函数返回的一 struct vfsmount 类型的变量加入到安装系统链表中，同时 graft_tree() 还要将新分配的 struct vfsmount 类型的变量加入到一个hash表中，其目的我们将会在以后看到。

这样，当 do_kern_mount() 函数返回时，在图 4 的基础上，新的数据结构间的关系将如图 5 所示。其中，红圈区域里面的数据结构便是被称做安装区域块的东西，其中不妨称 e2_mnt 为安装区域块的指针，蓝色箭头曲线即构成了所谓的安装系统链表。

在把这些函数调用后形成的数据结构关系理清楚之后，让我们回到本章节开始提到的问题，即将 ext2 文件系统安装到了 "/dev " 上之后，对该目录上的操作如何转化为对 ext2 文件系统相应的操作。从图 5上看到，对 sys_mount() 函数的调用并没有直接改变 "/dev " 目录所对应的 inode (即图中的 new_inode变量)结构中的 i_op 和 i_fop 指针，而且 "/dev " 所对应的 dentry(即图中的 new_dentry 变量)结构仍然在 VFS 的目录树中，并没有被从其中隐藏起来，相应地，来自 hda2 上的 ext2 文件系统的根目录所对应的 e2_entry 也不是如当初笔者所想象地那样将 VFS 目录树中的 new_dentry 取而代之，那么这之间的转化到底是如何实现的呢？

请读者注意下面的这段代码：

| 1    | while (d_mountpoint(dentry) &&  __follow_down(&nd->mnt, &dentry)); |
| ---- | ------------------------------------------------------------ |
|      |                                                              |

这段代码在 link_path_walk() 函数中被调用，而 link_path_walk() 最终又会被 path_lookup() 函数调用，如果读者阅读过 Linux 关于文件系统部分的代码，应该知道 path_lookup() 函数在整个 Linux 繁琐的文件系统代码中属于一个重要的基础性的函数。简单说来，这个函数用于解析文件路径名，这里的文件路径名和我们平时在应用程序中所涉及到的概念相同，比如在 Linux 的应用程序中 open 或 read 一个文件 /home/windfly.cs 时，这里的 /home/windfly.cs 就是文件路径名，path_lookup() 函数的责任就是对文件路径名中进行搜索，直到找到目标文件所属目录所对应的 dentry 或者目标直接就是一个目录，笔者不想在有限的篇幅里详细解释这个函数，读者只要记住 path_lookup() 会返回一个目标目录即可。

上面的代码非常地不起眼，以至于初次阅读文件系统的代码时经常会忽略掉它，但是前文所提到从 VFS 的操作到实际文件系统操作的转化却是由它完成的，对 VFS 中实现的文件系统的安装可谓功不可没。现在让我们仔细剖析一下该段代码： d_mountpoint(dentry) 的作用很简单，它只是返回 dentry 中 d_mounted 成员变量的值。这里的dentry 仍然还是 VFS 目录树上的东西。如果 VFS 目录树上某个目录被安装过一次，那么该值为 1。对VFS 中的一个目录可进行多次安装，后面会有例子说明这种情况。在我们的例子中，"/dev" 所对应的new_dentry 中 d_mounted=1，所以 while 循环中第一个条件满足。下面再来看__follow_down(&nd->mnt, &dentry)代

 

码做了什么？到此我们应该记住，这里 nd 中的 dentry 成员就是图 5 中的 new_dentry，nd 中的 mnt成员就是图 5 中的 mnt，所以我们现在可以把 __follow_down(&nd->mnt, &dentry) 改写成__follow_down(&mnt, &new_dentry)，接下来我们将 __follow_down() 函数的代码改写(只是去处掉一些不太相关的代码，并且为了便于说明，在部分代码行前加上了序号)如下：

| 1  2  3  4  5  6  7  8  9  10  11 | static inline int __follow_down(struct vfsmount  **mnt, struct dentry **dentry)  {    struct vfsmount *mounted;  [1] mounted = lookup_mnt(*mnt, *dentry);    if (mounted) {  [2]   *mnt = mounted;  [3]   *dentry =  mounted->mnt_root;      return  1;    }    return 0;  } |
| --------------------------------- | ------------------------------------------------------------ |
|                                   |                                                              |

代码行[1]中的 lookup_mnt() 函数用于查找一个 VFS 目录树下某一目录最近一次被 mount 时的安装区域块的指针，在本例中最终会返回图 5 中的 e2_mnt。至于查找的原理，这里粗略地描述一下。记得当我们在安装 ext2 文件系统到 "/dev" 时，在后期会调用 graft_tree() 函数，在这个函数里会把图 5 中的安装区域块指针 e2_mnt 挂到一 hash 表(Linux 2.4.20源代码中称之为 mount_hashtable)中的某一项，而该项的键值就是由被安装点所对应的 dentry(本例中为 new_dentry)和 mount(本例中为 mnt)所共同产生，所以自然地，当我们知道 VFS 树中某一 dentry 被安装过(该 dentry 变成为一安装点)，而要去查找其最近一次被安装的安装区域块指针时，同样由该安装点所对应的 dentry 和 mount 来产生一键值，以此值去索引 mount_hashtable，自然可找到该安装点对应的安装区域块指针形成的链表的头指针，然后遍历该链表，当发现某一安装区域块指针，记为 p，满足以下条件时：

| 1    | (p->mnt_parent == mnt &&  p->mnt_mountpoint == dentry) |
| ---- | ------------------------------------------------------ |
|      |                                                        |

P 便为该安装点所对应的安装区域块指针。当找到该指针后，便将 nd 中的 mnt 成员换成该安装区域块指针，同时将 nd 中的 dentry 成员换成安装区域块中的 dentry 指针。在我们的例子中，e2_mnt->mnt_root成员指向 e2_dentry，也就是 ext2 文件系统的 "/" 目录。这样，当 path_lookup() 函数搜索到 "/dev"时，nd 中的 dentry 成员为 e2_dentry，而不再是原来的 new_dentry，同时 mnt 成员被换成 e2_mnt，转化便在不知不觉中完成了。

现在考虑一下对某一安装点多次安装的情况，同样作为例子，我们假设在 "/dev" 上安装完一个 ext2文件系统后，再在其上安装一个 ntfs 文件系统。在安装之前，同样会对安装点所在的路径调用path_lookup() 函数进行搜索，但是这次由于在 "/dev" 目录上已经安装过了 ext2 文件系统，所以搜索到最后，由 nd 返回的信息是：nd.dentry = e2_dentry, nd.mnt = e2_mnt。由此可见，在第二次安装时，安装点已经由 dentry 变成了 e2_dentry。接下来，同样地，系统会再分配一个安装区域块，假设该安装区域块的指针为 ntfs_mnt，区域块中的 dentry 为 ntfs_dentry。ntfs_mnt 的父指针指向了e2_mnt，mnfs_mnt 中的 mnt_root 指向了代表 ntfs 文件系统根目录的 ntfs_dentry。然后，系统通过 e2_dentry和 e2_mnt 来生成一个新的 hash 键值，利用该值作为索引，将 ntfs_mnt 加入到 mount_hashtable 中，同时将 e2_dentry 中的成员 d_mounted 值设定为 1。这样，安装过程便告结束。

读者可能已经知道，对同一安装点上的最近一次安装会隐藏起前面的若干次安装，下面我们通过上述的例子解释一下该过程：

在先后将 ext2 和 ntfs 文件系统安装到 "/dev" 目录之后，我们再调用 path_lookup() 函数来对"/dev" 进行搜索，函数首先找到 VFS 目录树下的安装点 "/dev" 所对应的 dentry 和 mnt，此时它发现dentry 成员中的 d_mounted 为 1，于是它知道已经有文件系统安装到了该 dentry 上，于是它通过 dentry 和 mnt 来生成一个 hash 值，通过该值来对 mount_hashtable 进行搜索，根据安装过程，它应该能找到 e2_mnt 指针并返回之，同时原先的 dentry 也已经被替换成 e2_dentry。回头再看一下前面已经提到的下列代码： while (d_mountpoint(dentry) && __follow_down(&nd->mnt, &dentry)); 当第一次循环结束后, nd->mnt 已经是 e2_mnt，而 dentry 则变成 e2_dentry。此时由于 e2_dentry 中的成员 d_mounted 值为 1，所以 while 循环的第一个条件满足，要继续调用 __follow_down() 函数，这个函数前面已经剖析过，当它返回后 nd->mnt 变成了 ntfs_mnt，dentry 则变成了 ntfs_dentry。由于此时 ntfs_dentry 没有被安装过其他文件，所以它的成员 d_mounted 应该为 0，循环结束。对 "/dev" 发起的 path_lookup() 函数最终返回了 ntfs 文件系统根目录所对应的 dentry。这就是为什么 "/dev" 本身和安装在其上的 ext2 都被隐藏的原因。如果此时对 "/dev" 目录进行一个 ls 命令，将返回安装上去的 ntfs 文件系统根目录下所有的文件和目录。

### 安装根文件系统

不管怎么样，安装一个文件系统到 VFS 中某一安装点的过程原理毕竟都是一样的。

这个过程大致是：首先要确定待安装的 ext2 文件系统的来源，其次是确定 ext2 文件系统在 VFS中的安装点，然后便是具体的安装过程。

关于第一问题，Linux 2.4.20 的内核另有一大堆的代码去解决，限于篇幅，笔者不想在这里去具体说明这个过程，大概记住它是要解决到哪里去找要安装的文件系统的就可以了，这里我们不妨就认为要安装的根文件系统就来自于主硬盘的第一分区 hda1.

关于第二个问题，Linux 2.4.20 的内核把来自于 hda1 上 ext2 文件系统安装到了 VFS 目录树中的"/root" 目录上。其实，把 ext2 文件系统安装到 VFS 目录树下的哪个安装点并不重要(VFS 的根目录除外)，只要是这个安装点在 VFS 树中是存在的，并且内核对它没有另外的用途。如果读者喜欢，尽可以自己在 VFS 中创建一个 "/Windows" 目录，然后将 ext2 文件系统安装上去作为将来用户进程的根目录，没有什么不可以的。问题的关键是要将进程的根目录和当前工作目录设定好，因为毕竟只用用户进程才去关心现实的文件系统，要知道笔者的这篇稿子可是要存到硬盘上去的。

在 Linux 下，设定一个进程的当前工作目录是通过系统调用 sys_chdir() 进行的。初始化期间，Linux 在将 hda1 上的 ext2 文件系统安装到了 "/root" 上后，通过调用 sys_chdir("/root") 将当前进程，也就是 init_task 进程的当前工作目录(pwd)设定为 ext2 文件系统的根目录。记住此时 init_task进程的根目录仍然是图 3 中的 dentry，也就是 VFS 树的根目录，这显然是不行的，因为以后 Linux 世界中的所有进程都由这个 init_task 进程派生出来，无一例外地要继承该进程的根目录，如果是这样，意味着用户进程从根目录搜索某一目录时，实际上是从 VFS 的根目录开始的，而事实上却是从 ext2 的根文件开始搜索的。这个矛盾的解决是靠了在调用完 mount_root() 函数后，系统调用的下面两个函数：

| 1  2 | sys_mount(".", "/", NULL,  MS_MOVE, NULL);  sys_chroot("."); |
| ---- | ------------------------------------------------------------ |
|      |                                                              |

其主要作用便是将 init_task 进程的根目录转化成安装上去的 ext2 文件系统的根目录。有兴趣的读者可以自行去研究这一过程。

所以在用户空间下，更多地情况是只能见到 VFS 这棵大树的一叶，而且还是被安装过文件系统了的，实际上对用户空间来说还是不可见。我想，VFS 更多地被内核用来实现自己的功能，并以系统调用的方式提供过用户进程使用，至于在其上实现的不同文件系统的安装，也只是其中的一个功能罢了。

 

 

 

# c

## calloc()与malloc()

前一个会初始化 后一个不会

## i++和++i的区别

i++ ：先引用后增加

++i ：先增加后引用

i++ ：先在i所在的表达式中使用i的当前值，后让i加1 

++i ：让i先加1，然后在i所在的表达式中使用i的新值 

++是i先不自加，在语句完后自加，++i先自加；例如a=1+i++；i本来为1的话，这里a=1+1；语句完后i才加1为2；

## Typedef

 

 

## Time() srand() rand()

time()是关于时间的函数。当参数为NULL的时候，返回值是从1970年1月1日至今所经历的时间（以秒为单位），0就是NULL。当参数不是NULL时，参数必须是一个指向time_t类型的实体的一个指针，此时函数time()的返回值仍然是从1970年1月1日至今所经历的时间（以秒为单位），不同的是这次返回值同时也赋给作为参数的指针所指向的实体。

 

 

# 安全

1)DDOS：CC攻击（异常报文）、Memcache（放大攻击UDP）（关闭端口、升级系统）

 

 

2)一句话木马：（PHP：eval()函数可以执行里面的代码）

 

<html>

<body>

<form action="abc.php" method="post">

<input type="text" name="nsfoucs" value="phpinfo();">

<input type="submit" value="submit">

</form>

</body>

</html>

https://blog.csdn.net/lengyue1084/article/details/52064883

https://www.cnblogs.com/milantgh/p/3629199.html

3)burpsuite、nslookup（检测DNS的生存时间）、fiddler（抓包工具）、hydra（暴力破解工具）、charles（HTTP代理服务器）

 

4)apache struts rce漏洞

 